{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FNO embedded in a recurrent neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook adapts the FNO for its use in a recurrent neural network. The idea is to use the FNO to learn the dynamics of a system, and then use the FNO as a layer in a recurrent neural network to learn the dynamics of the system over time. This is a reimplementation of https://github.com/julian-parker/DAFX22_FNO in Jax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp models.fno_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from physmodjax.models.fno import SpectralLayers1d\n",
    "from flax import linen as nn\n",
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_platform_name\", \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class FNOCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Parker's ARMA without input\n",
    "    \"\"\"\n",
    "\n",
    "    hidden_channels: int\n",
    "    grid_size: int\n",
    "    layers: int = 4\n",
    "    out_channels: int = 1\n",
    "    activation: nn.Module = nn.relu\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(\n",
    "        self,\n",
    "        h,  # hidden state (grid_size, hidden_channels)\n",
    "        x,  # input (grid_size, 1)\n",
    "    ):\n",
    "        down_lifting = nn.Dense(features=self.out_channels)\n",
    "        spectral_layers = SpectralLayers1d(\n",
    "            n_channels=self.hidden_channels,\n",
    "            n_modes=self.grid_size,\n",
    "            linear_conv=True,\n",
    "            n_layers=self.layers,\n",
    "            activation=self.activation,\n",
    "        )\n",
    "\n",
    "        h = spectral_layers(h)\n",
    "\n",
    "        # the output is the down lifted hidden state\n",
    "        # (grid_size, hidden_channels) -> (grid_size, 1)\n",
    "        y = down_lifting(h)\n",
    "\n",
    "        return h, y\n",
    "\n",
    "\n",
    "class FNORNN(nn.Module):\n",
    "    hidden_channels: int  # number of hidden channels\n",
    "    grid_size: int  # number of grid points\n",
    "    n_spectral_layers: int = 4  # number of spectral layers\n",
    "    out_channels: int = 1\n",
    "    length: int = (\n",
    "        None  # length of the sequence. If None, the length is inferred from the input\n",
    "    )\n",
    "    activation: nn.Module = nn.relu\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(\n",
    "        self,\n",
    "        h0: jnp.ndarray,  # initial hidden state (grid_size, statevars)\n",
    "        x: jnp.ndarray = None,  # input sequence (timesteps, grid_size, 1)\n",
    "    ) -> jnp.ndarray:\n",
    "        ScanFNOCell = nn.scan(\n",
    "            FNOCell,\n",
    "            variable_broadcast=\"params\",\n",
    "            split_rngs={\"params\": False},\n",
    "            length=self.length,\n",
    "        )\n",
    "\n",
    "        scan = ScanFNOCell(\n",
    "            hidden_channels=self.hidden_channels,\n",
    "            grid_size=self.grid_size,\n",
    "            layers=self.n_spectral_layers,\n",
    "            out_channels=self.out_channels,\n",
    "            activation=self.activation,\n",
    "        )\n",
    "\n",
    "        up_lifting = nn.Dense(features=self.hidden_channels)\n",
    "\n",
    "        # We up lift the initial condition from (grid_size, 1) -> (grid_size, hidden_channels)\n",
    "        h0 = up_lifting(h0)\n",
    "        h, y = scan(h0, x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1705516485.179141  406942 tfrt_cpu_pjrt_client.cc:349] TfrtCpuClient created.\n"
     ]
    }
   ],
   "source": [
    "# | test\n",
    "\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")\n",
    "hidden_channels = 6\n",
    "grid_size = 101\n",
    "time_steps = 10\n",
    "\n",
    "fno_rnn = FNORNN(\n",
    "    hidden_channels=hidden_channels,\n",
    "    grid_size=grid_size,\n",
    "    length=time_steps,\n",
    ")\n",
    "\n",
    "h0 = jnp.ones((grid_size, 1))\n",
    "x = jnp.ones((time_steps, grid_size, 1))\n",
    "\n",
    "params = fno_rnn.init(jax.random.PRNGKey(0), h0, x)\n",
    "y = fno_rnn.apply(params, h0, x)\n",
    "\n",
    "assert y.shape == x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class BatchFNORNN(nn.Module):\n",
    "    hidden_channels: int  # number of hidden channels\n",
    "    grid_size: int  # number of grid points\n",
    "    n_spectral_layers: int = 4  # number of spectral layers\n",
    "    out_channels: int = 1\n",
    "    length: int = (\n",
    "        None  # length of the sequence. If None, the length is inferred from the input\n",
    "    )\n",
    "    activation: nn.Module = nn.relu\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(\n",
    "        self,\n",
    "        h0: jnp.ndarray,  # initial hidden state (batch_size, grid_size, statevars)\n",
    "        x: jnp.ndarray = None,  # input sequence (batch_size, timesteps, grid_size, 1)\n",
    "    ) -> jnp.ndarray:\n",
    "        fnornn = nn.vmap(\n",
    "            FNORNN,\n",
    "            in_axes=0,\n",
    "            variable_axes={\"params\": None},\n",
    "            split_rngs={\"params\": False},\n",
    "        )\n",
    "        return fnornn(\n",
    "            hidden_channels=self.hidden_channels,\n",
    "            grid_size=self.grid_size,\n",
    "            n_spectral_layers=self.n_spectral_layers,\n",
    "            out_channels=self.out_channels,\n",
    "            length=self.length,\n",
    "            activation=self.activation,\n",
    "        )(h0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 10, 101, 1)\n"
     ]
    }
   ],
   "source": [
    "# | test\n",
    "\n",
    "batch_size = 3\n",
    "time_steps = 10\n",
    "x = jnp.ones((batch_size, time_steps, grid_size, 1))\n",
    "h0 = jnp.ones((batch_size, grid_size, 1))\n",
    "\n",
    "batch_fno_rnn = BatchFNORNN(\n",
    "    hidden_channels=hidden_channels,\n",
    "    grid_size=grid_size,\n",
    "    length=time_steps,\n",
    ")\n",
    "\n",
    "params = batch_fno_rnn.init(\n",
    "    jax.random.PRNGKey(0), h0, x\n",
    ")  # Why does it need to be initialised with the number of timesteps?\n",
    "y = batch_fno_rnn.apply(params, h0, x)\n",
    "# Print the shape of the output\n",
    "print(y.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
