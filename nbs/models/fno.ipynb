{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier Neural Operator in 1D and 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp models.fno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in learning the mapping between function spaces. In particular, we are interested in learning the mapping between the input space $\\Omega$ and the output space $\\Lambda$ of a function $u: \\Omega \\rightarrow \\Lambda$. We will assume that the input space is a subset of $\\mathbb{R}^d$ and the output space is a subset of $\\mathbb{R}^m$. We will also assume that the function $u$ is smooth, i.e., it has a finite number of derivatives. We will denote the derivatives of $u$ by $u_{x_i}$, $u_{x_i x_j}$, etc. We will also assume that the function $u$ satisfies a partial differential equation (PDE) $\\mathcal{L} u = 0$ for some linear differential operator $\\mathcal{L}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single layer of the neural operator is defined as follows:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{F} &:= \\sigma \\left(W +\\mathcal{K} + b \\right) \\\\\n",
    "\\mathcal{G}_\\theta &:=  \\mathcal{Q} \\circ \\mathcal{F}  \\circ \\mathcal{P}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "- $\\mathcal{P} : \\mathbb{R^{in}} \\to \\mathbb{R^{hidden}}$ is a *lifting* layer\n",
    "- $\\mathcal{Q} : \\mathbb{R^{hidden}} \\to  \\mathbb{R^{out}}$ is a *projection* layer\n",
    "- $\\mathcal{F} \\colon \\mathbb{R^{hidden}} \\to  \\mathbb{R^{hidden}}$ is the Neural Operator Layer with\n",
    "\t- $\\mathcal{K}$ is one of several Kernel Operators\n",
    "\t- ${W}$ is a matrix (local linear operator); a \"skip connection\" inspired by ResNet\n",
    "\t- $b$ is a \"function\" bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The \"Fourier\" Neural operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes the form of the linear transformation (convolution) of the Fourier coeffcients of the input function $v$, and the kernel $R_\\phi$. The result is then transformed back using the inverse Fourier transform.\n",
    "\n",
    "$$\n",
    "\\mathcal{K} = \\mathcal{F}^{-1} (R_\\phi \\cdot \\mathcal{F} (v))\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import flax.linen as nn\n",
    "from flax.linen.initializers import uniform\n",
    "import jax.numpy as jnp\n",
    "from einops import rearrange\n",
    "from typing import Tuple\n",
    "import jax\n",
    "from physmodjax.utils.data import create_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SpectralConv1d(nn.Module):\n",
    "    \"\"\"Spectral Convolution Layer for 1D inputs.\n",
    "    The n_modes parameter should be set to the length of the output for now, as it is not clear that the truncation is done correctly\n",
    "    \"\"\"\n",
    "\n",
    "    in_channels: int  # number of input channels (last dimension of input)\n",
    "    d_vars: int  # number of output channels (last dimension of output)\n",
    "    n_modes: int  # number of fourier modes to use\n",
    "    linear_conv: bool = (\n",
    "        True  # whether to use linear convolution or circular convolution\n",
    "    )\n",
    "\n",
    "    def setup(self):\n",
    "        weight_shape = (self.in_channels, self.d_vars, self.n_modes)\n",
    "        scale = 1 / (self.in_channels * self.d_vars)\n",
    "\n",
    "        self.weight_real = self.param(\n",
    "            \"weight_real\", uniform(scale=scale), weight_shape  # cant use complex64\n",
    "        )\n",
    "        self.weight_imag = self.param(\n",
    "            \"weight_imag\", uniform(scale=scale), weight_shape  # cant use complex64\n",
    "        )\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        x: jnp.ndarray,  # (w, c)\n",
    "    ):\n",
    "        W, C = x.shape\n",
    "\n",
    "        # get the fourier coefficients along the spatial dimension\n",
    "        # we pad the inputs so that we perform a linear convolution\n",
    "        X = jnp.fft.rfft(x, n=W * 2 - 1, axis=-2, norm=\"ortho\")\n",
    "\n",
    "        # truncate to the first n_modes coefficients\n",
    "        X = X[: self.n_modes, :]\n",
    "\n",
    "        # multiply by the fourier coefficients of the kernel\n",
    "        complex_weight = self.weight_real + 1j * self.weight_imag\n",
    "        X = jnp.einsum(\"ki,iok->ko\", X, complex_weight)\n",
    "\n",
    "        # inverse fourier transform along dimension N and remove padding\n",
    "        x = jnp.fft.irfft(X, axis=-2, norm=\"ortho\")[:W]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | test\n",
    "\n",
    "batch_size = 1\n",
    "in_channels = 2\n",
    "d_vars = 2\n",
    "length = 10  # length of the input signal, also can be seen as the grid size\n",
    "n_modes = length\n",
    "\n",
    "conv = SpectralConv1d(\n",
    "    in_channels=in_channels,\n",
    "    d_vars=d_vars,\n",
    "    n_modes=n_modes,\n",
    "    linear_conv=True,\n",
    ")\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "x = jax.random.uniform(rng, shape=(length, in_channels))\n",
    "\n",
    "params = conv.init(jax.random.PRNGKey(0), x=x)\n",
    "\n",
    "y = conv.apply(params, x)\n",
    "\n",
    "assert y.shape == (length, d_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SpectralLayers1d(nn.Module):\n",
    "    \"\"\"Stack of 1D Spectral Convolution Layers\"\"\"\n",
    "\n",
    "    n_channels: int  # number of hidden channels\n",
    "    n_modes: int  # number of fourier modes to keep\n",
    "    linear_conv: bool = True  # whether to use linear convolution\n",
    "    n_layers: int = 4  # number of layers\n",
    "    activation: nn.Module = nn.relu  # activation function\n",
    "\n",
    "    def setup(self):\n",
    "        self.layers_conv = [\n",
    "            SpectralConv1d(\n",
    "                in_channels=self.n_channels,\n",
    "                d_vars=self.n_channels,\n",
    "                n_modes=self.n_modes,\n",
    "                linear_conv=self.linear_conv,\n",
    "            )\n",
    "            for _ in range(self.n_layers)\n",
    "        ]\n",
    "\n",
    "        self.layers_w = [\n",
    "            nn.Conv(features=self.n_channels, kernel_size=(1,))\n",
    "            for _ in range(self.n_layers)\n",
    "        ]\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        x,  # (grid_points, channels)\n",
    "    ) -> jnp.ndarray:  # (grid_points, channels)\n",
    "        for conv, w in zip(self.layers_conv, self.layers_w):\n",
    "            x1 = conv(x)\n",
    "            x2 = w(x)\n",
    "            x = self.activation(x1 + x2)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | test\n",
    "\n",
    "hidden_channels = 6\n",
    "grid_size = 101\n",
    "\n",
    "spectral_layers = SpectralLayers1d(\n",
    "    n_channels=hidden_channels,\n",
    "    n_modes=grid_size,\n",
    "    linear_conv=True,\n",
    "    n_layers=4,\n",
    "    activation=nn.relu,\n",
    ")\n",
    "params = spectral_layers.init(\n",
    "    jax.random.PRNGKey(0), jnp.ones((grid_size, hidden_channels))\n",
    ")\n",
    "\n",
    "x = jnp.ones((grid_size, hidden_channels))\n",
    "y = spectral_layers.apply(params, x)\n",
    "assert y.shape == x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier Neural Operator in 1 Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class FNO1D(nn.Module):\n",
    "    hidden_channels: int  # number of hidden channels\n",
    "    n_modes: int  # number of fourier modes to keep\n",
    "    d_vars: int = 1  # number of output channels\n",
    "    linear_conv: bool = True  # whether to use linear convolution\n",
    "    n_layers: int = 4  # number of layers\n",
    "    n_steps: int = None  # number of steps to output\n",
    "    activation: nn.Module = nn.gelu  # activation function\n",
    "    norm: str = (\"layer\",)  # normalization layer\n",
    "    training: bool = True  # whether to train the model\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(\n",
    "        self,\n",
    "        x,  # input (T, W, C)\n",
    "    ):\n",
    "        \"\"\"\n",
    "        The input to the FNO1D model is a 1D signal of shape (t, w, c)\n",
    "        where w is the spatial dimension and c is the number of channels.\n",
    "        The channel dimension is typically 1 for scalar fields. However, it can be\n",
    "        can also contain multiple time steps as channels or contain multiple scalar fields.\n",
    "        \"\"\"\n",
    "\n",
    "        # we need to make time as a channel dimension for the spectral layers\n",
    "        x = rearrange(x, \"t w c -> w (t c)\")\n",
    "\n",
    "        spectral_layers = SpectralLayers1d(\n",
    "            n_channels=self.hidden_channels,\n",
    "            n_modes=self.n_modes,\n",
    "            linear_conv=True,\n",
    "            n_layers=self.n_layers,\n",
    "            activation=self.activation,\n",
    "        )\n",
    "\n",
    "        h = nn.Dense(features=self.hidden_channels)(\n",
    "            x\n",
    "        )  # lift the input to the hidden state\n",
    "        h = spectral_layers(h)\n",
    "\n",
    "        # Down lift the hidden state to the output using a tiny mlp\n",
    "        y = nn.Sequential(\n",
    "            [\n",
    "                nn.Dense(features=128),\n",
    "                self.activation,\n",
    "                nn.Dense(features=self.d_vars * self.n_steps),\n",
    "            ]\n",
    "        )(h)\n",
    "\n",
    "        # rearrange the output to the original shape\n",
    "        y = rearrange(y, \"w (t c) -> t w c\", t=self.n_steps, c=self.d_vars)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "BatchedFNO1D = nn.vmap(\n",
    "    FNO1D,\n",
    "    in_axes=0,\n",
    "    out_axes=0,\n",
    "    variable_axes={\"params\": None},\n",
    "    split_rngs={\"params\": False},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Dense_0': {'bias': (6,), 'kernel': (1, 6)},\n",
       " 'Dense_1': {'bias': (128,), 'kernel': (6, 128)},\n",
       " 'Dense_2': {'bias': (5,), 'kernel': (128, 5)},\n",
       " 'SpectralLayers1d_0': {'layers_conv_0': {'weight_imag': (6, 6, 101),\n",
       "   'weight_real': (6, 6, 101)},\n",
       "  'layers_conv_1': {'weight_imag': (6, 6, 101), 'weight_real': (6, 6, 101)},\n",
       "  'layers_w_0': {'bias': (6,), 'kernel': (1, 6, 6)},\n",
       "  'layers_w_1': {'bias': (6,), 'kernel': (1, 6, 6)}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# | test\n",
    "\n",
    "time = 1\n",
    "hidden_channels = 6\n",
    "grid_size = 101\n",
    "in_channels = 1\n",
    "d_vars = 5\n",
    "n_layers = 2\n",
    "batch_size = 10\n",
    "\n",
    "batch_fno = BatchedFNO1D(\n",
    "    hidden_channels=hidden_channels,\n",
    "    n_modes=grid_size,\n",
    "    d_vars=d_vars,\n",
    "    n_layers=n_layers,\n",
    "    n_steps=1,\n",
    ")\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "x = jnp.ones((batch_size, time, grid_size, in_channels))\n",
    "\n",
    "params = batch_fno.init(jax.random.PRNGKey(0), x)\n",
    "y = batch_fno.apply(params, x)\n",
    "\n",
    "# assert y.shape == x.shape\n",
    "assert y.shape[-1] == d_vars\n",
    "assert y.shape == (batch_size, time, grid_size, d_vars)\n",
    "display(jax.tree_util.tree_map(jnp.shape, params[\"params\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier Neural Operator in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class SpectralConv2d(nn.Module):\n",
    "    in_channels: int\n",
    "    out_channels: int\n",
    "    n_modes1: int  # modes along the columns\n",
    "    n_modes2: int  # modes along the rows\n",
    "\n",
    "    def setup(self):\n",
    "\n",
    "        weight_shape = (\n",
    "            self.in_channels,\n",
    "            self.out_channels,\n",
    "            self.n_modes1,\n",
    "            self.n_modes2,\n",
    "        )\n",
    "\n",
    "        scale = 1 / (self.in_channels * self.out_channels)\n",
    "\n",
    "        self.weight_1_real = self.param(\n",
    "            \"weight_1_real\",\n",
    "            uniform(scale=scale),\n",
    "            weight_shape,\n",
    "        )\n",
    "\n",
    "        self.weight_1_imag = self.param(\n",
    "            \"weight_1_imag\",\n",
    "            uniform(scale=scale),\n",
    "            weight_shape,\n",
    "        )\n",
    "\n",
    "        self.weight_2_real = self.param(\n",
    "            \"weight_2_real\",\n",
    "            uniform(scale=scale),\n",
    "            weight_shape,\n",
    "        )\n",
    "\n",
    "        self.weight_2_imag = self.param(\n",
    "            \"weight_2_imag\",\n",
    "            uniform(scale=scale),\n",
    "            weight_shape,\n",
    "        )\n",
    "\n",
    "        self.complex_weight_1 = self.weight_1_real + 1j * self.weight_1_imag\n",
    "        self.complex_weight_2 = self.weight_2_real + 1j * self.weight_2_imag\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        x: jnp.ndarray,  # (H, W, C)\n",
    "    ):\n",
    "        \"\"\"\n",
    "        The input x is of shape (H, W, C), and we always perform a linear convolution\n",
    "        \"\"\"\n",
    "\n",
    "        H, W, C = x.shape\n",
    "        # get the fourier transform of the input\n",
    "        # along the first two dimensions\n",
    "        X = jnp.fft.rfft2(x, s=(H * 2 - 1, W * 2 - 1), axes=(0, 1), norm=\"ortho\")\n",
    "\n",
    "        # truncate the fourier transform\n",
    "        # to the first n_modes1, n_modes2 modes\n",
    "        # X -> (n_modes1, n_modes2, C)\n",
    "        # X = X[:self.n_modes1, :self.n_modes2, :]\n",
    "\n",
    "        # multiply the weights with the fourier transform\n",
    "        # This is a bit tricky. In the original implementation\n",
    "        # We multiply with two different weights\n",
    "        # along the first dimension from -n_modes1:n_modes1\n",
    "        # this is neccesary to cover the entire height\n",
    "        # this differs from parker's implementation\n",
    "        out_ft_up = jnp.einsum(\n",
    "            \"xyi,ioxy->xyo\",\n",
    "            X[: self.n_modes1, : self.n_modes2, :],\n",
    "            self.complex_weight_1,\n",
    "        )\n",
    "\n",
    "        out_ft_down = jnp.einsum(\n",
    "            \"xyi,ioxy->xyo\",\n",
    "            X[-self.n_modes1 :, : self.n_modes2, :],\n",
    "            self.complex_weight_2,\n",
    "        )\n",
    "\n",
    "        out_ft = jnp.concatenate((out_ft_up, out_ft_down), axis=0)\n",
    "\n",
    "        # inverse fourier transform\n",
    "        # along the first two dimensions\n",
    "        x = jnp.fft.irfft2(out_ft, s=(H, W), axes=(0, 1))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | test\n",
    "\n",
    "batch_size = 1\n",
    "in_channels = 2\n",
    "out_channels = 2\n",
    "height = 10\n",
    "width = 10\n",
    "n_modes = width // 2 + 1\n",
    "\n",
    "conv = SpectralConv2d(\n",
    "    in_channels=in_channels,\n",
    "    out_channels=out_channels,\n",
    "    n_modes1=n_modes,\n",
    "    n_modes2=n_modes,\n",
    ")\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "x = jax.random.uniform(rng, shape=(height, width, in_channels))\n",
    "\n",
    "params = conv.init(\n",
    "    rng,\n",
    "    x=x\n",
    ")\n",
    "y = conv.apply(params, x)\n",
    "\n",
    "assert y.shape == (height, width, out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class FNO2D(nn.Module):\n",
    "    hidden_channels: int  # number of hidden channels\n",
    "    n_modes: int  # number of fourier modes to keep\n",
    "    d_vars: int = 1  # number of output channels\n",
    "    linear_conv: bool = True  # whether to use linear convolution\n",
    "    n_layers: int = 4  # number of layers\n",
    "    n_steps: int = None  # number of steps to output\n",
    "    activation: nn.Module = nn.gelu  # activation function\n",
    "    d_model: Tuple[int, int] = (41, 37)  # (H, W) of the input for the grid\n",
    "    use_positions: bool = False  # whether to use positions in the input\n",
    "    norm: str = \"layer\"  # normalization layer\n",
    "    training: bool = True\n",
    "\n",
    "    def setup(self):\n",
    "        self.conv_layers = [\n",
    "            SpectralConv2d(\n",
    "                in_channels=self.hidden_channels,\n",
    "                out_channels=self.hidden_channels,\n",
    "                n_modes1=self.n_modes,\n",
    "                n_modes2=self.n_modes,\n",
    "            )\n",
    "            for _ in range(self.n_layers)\n",
    "        ]\n",
    "\n",
    "        # dense layers\n",
    "        # we use conv so that we don't have to shuffle the dimensions\n",
    "        self.w_layers = [\n",
    "            nn.Conv(features=self.hidden_channels, kernel_size=(1,))\n",
    "            for _ in range(self.n_layers)\n",
    "        ]\n",
    "\n",
    "        self.P = nn.Dense(\n",
    "            features=self.hidden_channels,\n",
    "        )\n",
    "\n",
    "        # TODO: in the original implementation this is a tiny mlp\n",
    "        # self.Q = nn.Dense(\n",
    "        #     features=self.out_channels,\n",
    "        # )\n",
    "        self.Q = nn.Sequential(\n",
    "            [\n",
    "                nn.Dense(features=128),\n",
    "                self.activation,\n",
    "                nn.Dense(features=self.d_vars * self.n_steps),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if self.use_positions:\n",
    "            self.grid = create_grid(self.d_model[1], self.d_model[0])\n",
    "\n",
    "    def advance(\n",
    "        self,\n",
    "        x: jnp.ndarray,  # (h, w, (t c))\n",
    "    ) -> jnp.ndarray:\n",
    "        \"\"\"\n",
    "        The input x is of shape (H, W, C), and we always perform a linear convolution\n",
    "        \"\"\"\n",
    "        if self.use_positions:\n",
    "            x = jnp.concatenate((x, self.grid), axis=-1)\n",
    "\n",
    "        # lifting layer works on the last dimension\n",
    "        x = self.P(x)\n",
    "\n",
    "        for conv, w in zip(self.conv_layers, self.w_layers):\n",
    "            x1 = conv(x)\n",
    "            x2 = w(x)\n",
    "            x = self.activation(x1 + x2)\n",
    "\n",
    "        x = self.Q(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        x,  # (t, h, w, c)\n",
    "    ) -> jnp.ndarray:\n",
    "        \"\"\"\n",
    "        The input x is of shape (T, H, W, C).\n",
    "        We always map from a single timestep to one or more timesteps.\n",
    "        The FNO2D can map from many-to-many timesteps, in which case these\n",
    "        are concatenated along the channel dimension.\n",
    "        \"\"\"\n",
    "        # we need to rearrange the dimensions\n",
    "        # will work only with 1 variable\n",
    "        # this is equivalent to the temporal bundling trick\n",
    "        x = rearrange(x, \"t h w c -> h w (t c)\")\n",
    "\n",
    "        x = self.advance(x)\n",
    "\n",
    "        x = rearrange(x, \"h w (t c) -> t h w c\", t=self.n_steps, c=self.d_vars)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "BatchedFNO2D = nn.vmap(\n",
    "    FNO2D,\n",
    "    in_axes=0,\n",
    "    out_axes=0,\n",
    "    variable_axes={\"params\": None},\n",
    "    split_rngs={\"params\": False},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 9, 32, 32, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'P': {'bias': (10,), 'kernel': (2, 10)},\n",
       " 'Q': {'layers_0': {'bias': (128,), 'kernel': (10, 128)},\n",
       "  'layers_2': {'bias': (18,), 'kernel': (128, 18)}},\n",
       " 'conv_layers_0': {'weight_1_imag': (10, 10, 16, 16),\n",
       "  'weight_1_real': (10, 10, 16, 16),\n",
       "  'weight_2_imag': (10, 10, 16, 16),\n",
       "  'weight_2_real': (10, 10, 16, 16)},\n",
       " 'conv_layers_1': {'weight_1_imag': (10, 10, 16, 16),\n",
       "  'weight_1_real': (10, 10, 16, 16),\n",
       "  'weight_2_imag': (10, 10, 16, 16),\n",
       "  'weight_2_real': (10, 10, 16, 16)},\n",
       " 'conv_layers_2': {'weight_1_imag': (10, 10, 16, 16),\n",
       "  'weight_1_real': (10, 10, 16, 16),\n",
       "  'weight_2_imag': (10, 10, 16, 16),\n",
       "  'weight_2_real': (10, 10, 16, 16)},\n",
       " 'conv_layers_3': {'weight_1_imag': (10, 10, 16, 16),\n",
       "  'weight_1_real': (10, 10, 16, 16),\n",
       "  'weight_2_imag': (10, 10, 16, 16),\n",
       "  'weight_2_real': (10, 10, 16, 16)},\n",
       " 'w_layers_0': {'bias': (10,), 'kernel': (1, 10, 10)},\n",
       " 'w_layers_1': {'bias': (10,), 'kernel': (1, 10, 10)},\n",
       " 'w_layers_2': {'bias': (10,), 'kernel': (1, 10, 10)},\n",
       " 'w_layers_3': {'bias': (10,), 'kernel': (1, 10, 10)}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# | test\n",
    "\n",
    "T_in = 1\n",
    "T_out = 9\n",
    "B, T, H, W, C = 10, T_in, 32, 32, 2\n",
    "hidden_channels = 10\n",
    "n_modes = 16\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "x = jax.random.uniform(rng, shape=(B, T, H, W, C))\n",
    "\n",
    "batched_fno = BatchedFNO2D(\n",
    "    hidden_channels=hidden_channels,\n",
    "    d_vars=C,\n",
    "    n_steps=T_out,\n",
    "    n_modes=n_modes,\n",
    "    use_positions=False,\n",
    "    d_model=(H, W),\n",
    ")\n",
    "params = batched_fno.init(rng, x)\n",
    "\n",
    "y = batched_fno.apply(params, x)\n",
    "print(y.shape)\n",
    "assert y.shape == (B, T_out, H, W, C)\n",
    "display(jax.tree_util.tree_map(jnp.shape, params[\"params\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
