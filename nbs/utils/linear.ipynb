{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp utils.linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import numpy as np\n",
    "from typing import List, Union, Tuple, Optional, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def sort_eigvals_eigvecs(\n",
    "    eigvals: np.ndarray,  # eigenvalues\n",
    "    eigvecs: np.ndarray,  # eigenvectors\n",
    ") -> Tuple[np.ndarray, np.ndarray]:  # (eigenvalues, eigenvectors)\n",
    "\n",
    "    idx = np.argsort(np.abs(eigvals))[::-1]\n",
    "    eigvals = eigvals[idx]\n",
    "    eigvecs = eigvecs[:, idx]\n",
    "    return eigvals, eigvecs\n",
    "\n",
    "\n",
    "def get_linear_model(\n",
    "    X: np.ndarray,  # data matrix (state_vars, time_steps)\n",
    "    X_prime: np.ndarray,  # shifted data matrix (state_vars, time_steps)\n",
    "    sorted: bool = True,  # sort eigenvalues and eigenvectors\n",
    ") -> Tuple[np.ndarray, np.ndarray]:  # (eigenvalues, eigenvectors)\n",
    "    \"\"\"\n",
    "    Returns the linear model A such that X' = AX\n",
    "    \"\"\"\n",
    "    A_lstsq = np.linalg.lstsq(X.T, X_prime.T, rcond=None)[0]\n",
    "    A_lstsq = A_lstsq.T\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(A_lstsq)\n",
    "\n",
    "    return (\n",
    "        sort_eigvals_eigvecs(eigenvalues, eigenvectors)\n",
    "        if sorted\n",
    "        else (eigenvalues, eigenvectors)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DMD Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from pydmd.utils import pseudo_hankel_matrix\n",
    "from pydmd import DMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def hankelize(\n",
    "    u: jnp.ndarray,\n",
    "    d: int = 2,\n",
    "):\n",
    "    # slice the data and hankelize\n",
    "    u_ref = u\n",
    "    u_ref = pseudo_hankel_matrix(u_ref.T, d=d).T\n",
    "    return u_ref\n",
    "\n",
    "\n",
    "def fit_dmd_to_sample(x: jnp.ndarray, r: int = 50) -> DMD:  # (timesteps, gridpoints)\n",
    "\n",
    "    dmd = DMD(svd_rank=r)\n",
    "    dmd.fit(x.squeeze().T)\n",
    "    return dmd\n",
    "\n",
    "\n",
    "def fast_predict(\n",
    "    y: jnp.ndarray,  # gridsize\n",
    "    inv_modes: jnp.ndarray,\n",
    "    fwd_modes: jnp.ndarray,\n",
    "    eigs: jnp.ndarray,\n",
    "    lenght: int = None,\n",
    "):\n",
    "    if lenght is None:\n",
    "        lenght = y.shape[0]\n",
    "\n",
    "    # we need to predict the next 3999 timesteps\n",
    "    lenght += 1\n",
    "\n",
    "    states = jnp.vander(eigs, lenght, increasing=True)\n",
    "    x_0 = inv_modes @ y\n",
    "    pred = fwd_modes @ (states * x_0[..., None])\n",
    "\n",
    "    # slice from the second timestep and convert to (time, gridsize)\n",
    "    return pred[:, 1:].T.real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities to replace weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from pydmd.utils import pseudo_hankel_matrix\n",
    "from pydmd import DMD, BOPDMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_linear_approximation(\n",
    "    y: jnp.ndarray,  # (time_steps, grid_size)\n",
    "    r: int = 50,\n",
    "    method: str = \"dmd\",  # \"dmd\", \"full\", \"analytical\"\n",
    ") -> Tuple[jnp.ndarray, jnp.ndarray]:\n",
    "\n",
    "    # fit the model parameters using DMD before training\n",
    "    if method in [\"dmd\"]:\n",
    "        dmd = DMD(svd_rank=r)\n",
    "        dmd.fit(y.T)\n",
    "        eigvals, eigvecs = sort_eigvals_eigvecs(dmd.eigs, dmd.modes)\n",
    "        eigvals = jnp.log(eigvals)  # make continuous\n",
    "\n",
    "    elif method in [\"analytical\"]:\n",
    "        dt = 1 / 4000\n",
    "        eigvals, eigvecs = stiff_string_eigendecomposition(n_max_modes=r)\n",
    "        eigvals = eigvals * dt\n",
    "        eigvecs = eigvecs.T\n",
    "    return eigvals, eigvecs\n",
    "\n",
    "\n",
    "def set_params_from_linear(\n",
    "    params: Dict,\n",
    "    single_eigvals: jnp.ndarray,\n",
    "    single_lstvecs: jnp.ndarray,\n",
    "    model: str,  # \"lru\" or \"koopman\"\n",
    ") -> Dict:\n",
    "\n",
    "    if model == \"lru\":\n",
    "        map_to_0_2pi = lambda x: jnp.where(x < 0, x + 2 * jnp.pi, x)\n",
    "\n",
    "        # nu_log = jnp.nan_to_num(jnp.log(-jnp.log(jnp.abs(single_eigvals))))\n",
    "        # theta_log = jnp.nan_to_num(jnp.log(map_to_0_2pi(jnp.angle(single_eigvals))))\n",
    "        nu_log = jnp.log(-single_eigvals.real)\n",
    "        theta_log = jnp.nan_to_num(jnp.log(map_to_0_2pi(single_eigvals.imag)))\n",
    "\n",
    "        params[\"first_layer\"][\"nu_log\"] = nu_log\n",
    "        params[\"first_layer\"][\"theta_log\"] = theta_log\n",
    "        # set eigenvectors\n",
    "        inv_lstvecs = jnp.linalg.pinv(single_lstvecs)\n",
    "\n",
    "        params[\"first_layer\"][\"B_re\"] = inv_lstvecs.real\n",
    "        params[\"first_layer\"][\"B_im\"] = inv_lstvecs.imag\n",
    "\n",
    "        params[\"first_layer\"][\"C_re\"] = single_lstvecs.real\n",
    "        params[\"first_layer\"][\"C_im\"] = single_lstvecs.imag\n",
    "\n",
    "    elif model == \"koopman\":\n",
    "        ################\n",
    "        # single_lstvecs = lstvecs[:, ::2]\n",
    "        # single_lstvecs = single_lstvecs[:single_lstvecs.shape[0] // 2, :single_lstvecs.shape[1] // 2]\n",
    "\n",
    "        conj_eigenvalues = jnp.concatenate(\n",
    "            [\n",
    "                single_eigvals.real + 1j * jnp.abs(single_eigvals.imag),\n",
    "                single_eigvals.real - 1j * jnp.abs(single_eigvals.imag),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        conj_eigenvecs = jnp.concatenate(\n",
    "            [\n",
    "                single_lstvecs.real + 1j * 0,\n",
    "                single_lstvecs.real - 1j * 0,\n",
    "            ],\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        inv_eigenvecs = jnp.linalg.pinv(conj_eigenvecs)\n",
    "        inv_eigenvecs_as_real = jnp.concatenate(\n",
    "            [inv_eigenvecs.real, inv_eigenvecs.imag], axis=0\n",
    "        ).T\n",
    "        fwd_eigenvecs_as_real = jnp.concatenate(\n",
    "            [conj_eigenvecs.real, conj_eigenvecs.imag], axis=1\n",
    "        ).T\n",
    "\n",
    "        params[\"params\"][\"batched_koopman\"][\"encoder\"][\"encoder\"][\n",
    "            \"kernel\"\n",
    "        ] = inv_eigenvecs_as_real\n",
    "        params[\"params\"][\"batched_koopman\"][\"decoder\"][\"decoder\"][\n",
    "            \"kernel\"\n",
    "        ] = fwd_eigenvecs_as_real\n",
    "\n",
    "        params[\"params\"][\"batched_koopman\"][\"weight_real\"] = conj_eigenvalues.real[\n",
    "            : conj_eigenvalues.shape[0] // 2\n",
    "        ]\n",
    "        params[\"params\"][\"batched_koopman\"][\"weight_imag\"] = conj_eigenvalues.imag[\n",
    "            : conj_eigenvalues.shape[0] // 2\n",
    "        ]\n",
    "\n",
    "    return params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
