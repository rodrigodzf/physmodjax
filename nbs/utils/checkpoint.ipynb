{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp utils.checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "from pathlib import Path\n",
    "from flax.training import train_state\n",
    "import orbax.checkpoint as obc\n",
    "import hydra\n",
    "import jax\n",
    "from physmodjax.scripts.train_rnn import create_train_state\n",
    "import flax.linen as nn\n",
    "from omegaconf import OmegaConf\n",
    "from typing import Tuple\n",
    "from wandb.apis import public\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def restore_experiment_state(\n",
    "    run_path: Path,  # Path to the run directory (e.g. \"outputs/2024-01-23/22-15-11\")\n",
    "    best: bool = True,  # If True, restore the best checkpoint instead of the latest\n",
    "    step_to_restore: int = None,  # If not None, restore the checkpoint at this step\n",
    "    x0_shape: Tuple[int] = (1, 101, 1),  # Shape of the initial condition\n",
    "    x_shape: Tuple[int] = (1, 1, 101, 1),  # Shape of the input data\n",
    "    kwargs: dict = {},  # Additional arguments to pass to the model\n",
    ") -> Tuple[train_state.TrainState, nn.Module, obc.CheckpointManager]:\n",
    "    \"\"\"\n",
    "    Restores the train state from a run.\n",
    "\n",
    "    Args:\n",
    "        run_path (Path): Path to the run directory (e.g. \"outputs/2024-01-23/22-15-11\")\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "        train_state.TrainState: The train state of the experiment\n",
    "        nn.Module: The model used in the experiment\n",
    "        CheckpointManager: The checkpoint manager\n",
    "    \"\"\"\n",
    "\n",
    "    # Make sure the path is a Path object\n",
    "    run_path = Path(run_path)\n",
    "\n",
    "    # These are hardcoded, do not change\n",
    "    ckpt_path = run_path / \"checkpoints\"\n",
    "    config_path = run_path / \".hydra\" / \"config.yaml\"\n",
    "\n",
    "    options = obc.CheckpointManagerOptions(\n",
    "        max_to_keep=1,\n",
    "        create=True,\n",
    "        best_fn=lambda x: float(x[\"val/mse\"]),\n",
    "        best_mode=\"min\",\n",
    "    )\n",
    "    with obc.CheckpointManager(\n",
    "        ckpt_path,\n",
    "        options=options,\n",
    "        item_handlers={\"state\": obc.PyTreeCheckpointHandler()},\n",
    "    ) as checkpoint_manager:\n",
    "\n",
    "        # Load the config\n",
    "        cfg = OmegaConf.load(config_path)\n",
    "\n",
    "        model_cls: nn.Module = hydra.utils.instantiate(cfg.model)\n",
    "        grad_clip = hydra.utils.instantiate(cfg.gradient_clip)\n",
    "\n",
    "        # initialise train state\n",
    "        # try to get this information from the config\n",
    "        if hasattr(cfg, \"data_info\"):\n",
    "            print(f\"Using data_info from config: {cfg.data_info}\")\n",
    "            x_shape = [1] + cfg.data_info\n",
    "        rng = jax.random.PRNGKey(cfg.seed)\n",
    "\n",
    "        empty_state = create_train_state(\n",
    "            model_cls(training=False, **kwargs),\n",
    "            rng=rng,\n",
    "            x_shape=x_shape,\n",
    "            num_steps=666,\n",
    "            learning_rate=cfg.optimiser.learning_rate,\n",
    "            grad_clip=grad_clip,\n",
    "            components_to_freeze=cfg.frozen,\n",
    "            norm=cfg.model.norm,\n",
    "            schedule_type=cfg.schedule_type,\n",
    "        )\n",
    "\n",
    "        step = (\n",
    "            checkpoint_manager.latest_step()\n",
    "            if not best\n",
    "            else checkpoint_manager.best_step()\n",
    "        )\n",
    "        step = step_to_restore if step_to_restore is not None else step\n",
    "        print(f\"Restoring checkpoint from step {step}...\")\n",
    "        state = checkpoint_manager.restore(\n",
    "            step=step,\n",
    "            args=obc.args.Composite(\n",
    "                state=obc.args.PyTreeRestore(empty_state),\n",
    "            ),\n",
    "        )['state']\n",
    "\n",
    "        return state, model_cls(training=False, **kwargs), checkpoint_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "def download_ckpt_single_run(\n",
    "    run_name: str,\n",
    "    project: str,\n",
    "    tmp_dir: Path = Path(\"/tmp/physmodjax\"),\n",
    "    overwrite: bool = False,\n",
    ") -> Tuple[Path, OmegaConf]:\n",
    "    filter_dict = {\n",
    "        \"display_name\": run_name,\n",
    "    }\n",
    "\n",
    "    if wandb.run is None:\n",
    "        wandb.init()\n",
    "        api: public.Api = wandb.Api()\n",
    "\n",
    "    runs: public.Runs = api.runs(project, filter_dict)\n",
    "\n",
    "    assert len(runs) > 0, f\"No runs found with name {run_name}\"\n",
    "    assert len(runs) == 1, f\"More than one run found with name {run_name}\"\n",
    "\n",
    "    run: public.Run = runs[0]\n",
    "    conf = OmegaConf.create(run.config)\n",
    "\n",
    "    artifacts: public.RunArtifacts = run.logged_artifacts()\n",
    "\n",
    "    artifact: wandb.Artifact\n",
    "\n",
    "    # check if no artifacts\n",
    "    if len(artifacts) == 0:\n",
    "        raise ValueError(f\"No artifacts found for run {run_name}\")\n",
    "\n",
    "    for artifact in artifacts:\n",
    "        if artifact.type == \"model\":\n",
    "            checkpoint_path = tmp_dir / artifact.name\n",
    "            if checkpoint_path.exists() and not overwrite:\n",
    "                print(f\"Checkpoint already exists at {checkpoint_path}, skipping\")\n",
    "                return checkpoint_path, conf\n",
    "            else:\n",
    "                artifact.download(checkpoint_path)\n",
    "\n",
    "    # save config next to checkpoint\n",
    "    conf_path = checkpoint_path / \".hydra\" / \"config.yaml\"\n",
    "    conf_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    OmegaConf.save(conf, conf_path)\n",
    "\n",
    "    print(f\"Downloaded checkpoint to {checkpoint_path}\")\n",
    "    return checkpoint_path, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import initialize, compose\n",
    "from hydra.core.hydra_config import HydraConfig\n",
    "from physmodjax.scripts.train_rnn import train_rnn\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Path /Users/diaz/projects/physmodjax/nbs/utils/outputs/2024-09-03/12-28-33/wandb/ wasn't writable, using system temp directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:\n",
      "  _target_: physmodjax.models.autoencoders.BatchedKoopmanAutoencoder1D\n",
      "  _partial_: true\n",
      "  d_vars: 1\n",
      "  d_model: 101\n",
      "  norm: layer\n",
      "  encoder_model:\n",
      "    _target_: physmodjax.models.mlp.MLP\n",
      "    _partial_: true\n",
      "    hidden_channels:\n",
      "    - 128\n",
      "    - 128\n",
      "    - 256\n",
      "    kernel_init:\n",
      "      _target_: flax.linen.initializers.orthogonal\n",
      "  decoder_model:\n",
      "    _target_: physmodjax.models.mlp.MLP\n",
      "    _partial_: true\n",
      "    hidden_channels:\n",
      "    - 128\n",
      "    - 128\n",
      "    - 101\n",
      "    kernel_init:\n",
      "      _target_: flax.linen.initializers.orthogonal\n",
      "  dynamics_model:\n",
      "    _target_: physmodjax.models.recurrent.LRUDynamics\n",
      "    _partial_: true\n",
      "    d_hidden: 128\n",
      "    r_min: 0.99\n",
      "    r_max: 0.999\n",
      "    max_phase: 6.28\n",
      "    clip_eigs: true\n",
      "datamodule:\n",
      "  _target_: physmodjax.utils.data.DirectoryDataModule\n",
      "  split:\n",
      "  - 0.01\n",
      "  - 0.01\n",
      "  - 0.01\n",
      "  batch_size: 1\n",
      "  extract_channels:\n",
      "  - 0\n",
      "  total_num_train: 4000\n",
      "  total_num_val: 4000\n",
      "  total_num_test: 4000\n",
      "  num_steps_train:\n",
      "  - 1\n",
      "  - 3999\n",
      "  num_steps_val:\n",
      "  - 1\n",
      "  - 3999\n",
      "  mode: split\n",
      "  standardize_dataset: true\n",
      "  windowed: false\n",
      "  cache: true\n",
      "  data_array: ../data/ftm_string_nonlin_1000_Noise_4000Hz_1.0s.npy\n",
      "jax:\n",
      "  platform_name: null\n",
      "  preallocate_gpu_memory: false\n",
      "optimiser:\n",
      "  _target_: optax.adamw\n",
      "  learning_rate: 0.0001\n",
      "gradient_clip:\n",
      "  _target_: optax.clip_by_global_norm\n",
      "  max_norm: 1.0\n",
      "loss:\n",
      "  _target_: physmodjax.utils.losses.lindyn_loss\n",
      "  _partial_: true\n",
      "  encdec_weight: 1.0\n",
      "  lindyn_weight: 0.01\n",
      "  pred_weight: 1.0\n",
      "seed: 3407\n",
      "epochs: 1\n",
      "epochs_val: 1\n",
      "frozen: []\n",
      "init_from_linear: false\n",
      "schedule_type: constant\n",
      "wandb:\n",
      "  group: 1d\n",
      "  project: physmodjax\n",
      "  entity: iir-modal\n",
      "\n",
      "version: 1.3.2\n",
      "version_base: '1.3'\n",
      "cwd: /Users/diaz/projects/physmodjax/nbs/utils\n",
      "config_sources:\n",
      "- path: hydra.conf\n",
      "  schema: pkg\n",
      "  provider: hydra\n",
      "- path: /Users/diaz/projects/physmodjax/conf\n",
      "  schema: file\n",
      "  provider: main\n",
      "- path: ''\n",
      "  schema: structured\n",
      "  provider: schema\n",
      "output_dir: ???\n",
      "choices:\n",
      "  experiment: 1d_koopman\n",
      "  loss: lindyn\n",
      "  gradient_clip: default.yaml\n",
      "  optimiser: default.yaml\n",
      "  jax: default.yaml\n",
      "  datamodule: string\n",
      "  model: 1d_koopman\n",
      "  hydra/env: default\n",
      "  hydra/callbacks: null\n",
      "  hydra/job_logging: default\n",
      "  hydra/hydra_logging: default\n",
      "  hydra/hydra_help: default\n",
      "  hydra/help: default\n",
      "  hydra/sweeper: basic\n",
      "  hydra/launcher: basic\n",
      "  hydra/output: default\n",
      "\n",
      "Output dir: /Users/diaz/projects/physmodjax/nbs/utils/outputs/2024-09-03/12-28-33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:bg96gmb3) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">chocolate-dream-1762</strong> at: <a href='https://wandb.ai/iir-modal/physmodjax/runs/bg96gmb3' target=\"_blank\">https://wandb.ai/iir-modal/physmodjax/runs/bg96gmb3</a><br/> View project at: <a href='https://wandb.ai/iir-modal/physmodjax' target=\"_blank\">https://wandb.ai/iir-modal/physmodjax</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/var/folders/f_/jbsvj3wx2gv9z_2s7ywlc8p00000gn/T/wandb/run-20240903_120018-bg96gmb3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:bg96gmb3). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/var/folders/f_/jbsvj3wx2gv9z_2s7ywlc8p00000gn/T/wandb/run-20240903_122833-4z5togcj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/iir-modal/physmodjax/runs/4z5togcj' target=\"_blank\">serene-butterfly-1763</a></strong> to <a href='https://wandb.ai/iir-modal/physmodjax' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/iir-modal/physmodjax' target=\"_blank\">https://wandb.ai/iir-modal/physmodjax</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/iir-modal/physmodjax/runs/4z5togcj' target=\"_blank\">https://wandb.ai/iir-modal/physmodjax/runs/4z5togcj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "InstantiationException",
     "evalue": "Error in call to target 'physmodjax.utils.data.DirectoryDataModule':\nAssertionError('The data array does not exist')\nfull_key: datamodule",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/mambaforge/envs/physmodjax/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:92\u001b[0m, in \u001b[0;36m_call_target\u001b[0;34m(_target_, _partial_, args, kwargs, full_key)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_target_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/projects/physmodjax/physmodjax/utils/data.py:407\u001b[0m, in \u001b[0;36mDirectoryDataModule.__init__\u001b[0;34m(self, data_array, split, batch_size, extract_channels, num_steps_train, num_steps_val, standardize_dataset, mean, std, mode, windowed, hankelize, shuffle_train, cache, rolling_windows, total_num_train, total_num_val, total_num_test)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_batch_size \u001b[38;5;241m=\u001b[39m batch_size\n\u001b[0;32m--> 407\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m Path(data_array)\u001b[38;5;241m.\u001b[39mexists() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    408\u001b[0m     [Path(d)\u001b[38;5;241m.\u001b[39mexists() \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data_array]\n\u001b[1;32m    409\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe data array does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;66;03m# if we have a list of directories, we will concatenate the data\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;66;03m# else we will assume that the directory contains the data\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: The data array does not exist",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInstantiationException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 41\u001b[0m\n\u001b[1;32m     37\u001b[0m HydraConfig\u001b[38;5;241m.\u001b[39minstance()\u001b[38;5;241m.\u001b[39mset_config(cfg)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput dir: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m \u001b[43mtrain_rnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/physmodjax/lib/python3.10/site-packages/hydra/main.py:83\u001b[0m, in \u001b[0;36mmain.<locals>.main_decorator.<locals>.decorated_main\u001b[0;34m(cfg_passthrough)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(task_function)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorated_main\u001b[39m(cfg_passthrough: Optional[DictConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cfg_passthrough \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg_passthrough\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     85\u001b[0m         args_parser \u001b[38;5;241m=\u001b[39m get_args_parser()\n",
      "File \u001b[0;32m~/projects/physmodjax/physmodjax/scripts/train_rnn.py:482\u001b[0m, in \u001b[0;36mtrain_rnn\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m    471\u001b[0m run \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39minit(\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m=\u001b[39moutput_dir,\n\u001b[1;32m    473\u001b[0m     config\u001b[38;5;241m=\u001b[39mOmegaConf\u001b[38;5;241m.\u001b[39mto_container(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcfg\u001b[38;5;241m.\u001b[39mwandb,\n\u001b[1;32m    479\u001b[0m )\n\u001b[1;32m    481\u001b[0m model_cls \u001b[38;5;241m=\u001b[39m hydra\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39minstantiate(cfg\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 482\u001b[0m datamodule \u001b[38;5;241m=\u001b[39m \u001b[43mhydra\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstantiate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# Log data info\u001b[39;00m\n\u001b[1;32m    485\u001b[0m wandb\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_dir})\n",
      "File \u001b[0;32m~/mambaforge/envs/physmodjax/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:226\u001b[0m, in \u001b[0;36minstantiate\u001b[0;34m(config, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m     _convert_ \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mpop(_Keys\u001b[38;5;241m.\u001b[39mCONVERT, ConvertMode\u001b[38;5;241m.\u001b[39mNONE)\n\u001b[1;32m    224\u001b[0m     _partial_ \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mpop(_Keys\u001b[38;5;241m.\u001b[39mPARTIAL, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstantiate_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_recursive_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_convert_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_partial_\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m OmegaConf\u001b[38;5;241m.\u001b[39mis_list(config):\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m# Finalize config (convert targets to strings, merge with kwargs)\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     config_copy \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(config)\n",
      "File \u001b[0;32m~/mambaforge/envs/physmodjax/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:347\u001b[0m, in \u001b[0;36minstantiate_node\u001b[0;34m(node, convert, recursive, partial, *args)\u001b[0m\n\u001b[1;32m    342\u001b[0m                 value \u001b[38;5;241m=\u001b[39m instantiate_node(\n\u001b[1;32m    343\u001b[0m                     value, convert\u001b[38;5;241m=\u001b[39mconvert, recursive\u001b[38;5;241m=\u001b[39mrecursive\n\u001b[1;32m    344\u001b[0m                 )\n\u001b[1;32m    345\u001b[0m             kwargs[key] \u001b[38;5;241m=\u001b[39m _convert_node(value, convert)\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_target_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;66;03m# If ALL or PARTIAL non structured or OBJECT non structured,\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;66;03m# instantiate in dict and resolve interpolations eagerly.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert \u001b[38;5;241m==\u001b[39m ConvertMode\u001b[38;5;241m.\u001b[39mALL \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    352\u001b[0m         convert \u001b[38;5;129;01min\u001b[39;00m (ConvertMode\u001b[38;5;241m.\u001b[39mPARTIAL, ConvertMode\u001b[38;5;241m.\u001b[39mOBJECT)\n\u001b[1;32m    353\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m node\u001b[38;5;241m.\u001b[39m_metadata\u001b[38;5;241m.\u001b[39mobject_type \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m    354\u001b[0m     ):\n",
      "File \u001b[0;32m~/mambaforge/envs/physmodjax/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:97\u001b[0m, in \u001b[0;36m_call_target\u001b[0;34m(_target_, _partial_, args, kwargs, full_key)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_key:\n\u001b[1;32m     96\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mfull_key: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InstantiationException(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mInstantiationException\u001b[0m: Error in call to target 'physmodjax.utils.data.DirectoryDataModule':\nAssertionError('The data array does not exist')\nfull_key: datamodule"
     ]
    }
   ],
   "source": [
    "# | eval: false\n",
    "\n",
    "data_array = \"../data/ftm_string_nonlin_1000_Noise_4000Hz_1.0s.npy\"\n",
    "batch_size = 1\n",
    "split = [0.01, 0.01, 0.01]\n",
    "extract_channels = [0]\n",
    "output_dir = \"\"\n",
    "\n",
    "with initialize(version_base=None, config_path=\"../../conf\"):\n",
    "    cfg = compose(\n",
    "        return_hydra_config=True,\n",
    "        config_name=\"train_rnn\",\n",
    "        overrides=[\n",
    "            \"+experiment=1d_koopman\",\n",
    "            f\"++datamodule.data_array={data_array}\",\n",
    "            f\"++datamodule.batch_size={batch_size}\",\n",
    "            f\"++datamodule.split={split}\",\n",
    "            f\"++datamodule.extract_channels={extract_channels}\",\n",
    "            \"++model.d_vars=1\",\n",
    "            \"++epochs=1\",\n",
    "            \"++epochs_val=1\",\n",
    "            \"++wandb.project=physmodjax\",\n",
    "            \"++wandb.entity=iir-modal\"\n",
    "        ],\n",
    "    )\n",
    "    OmegaConf.register_new_resolver(\"eval\", eval, replace=True)\n",
    "    OmegaConf.resolve(cfg)\n",
    "\n",
    "    cfg_no_hydra = {k:v for (k,v) in cfg.items() if \"hydra\" not in k} \n",
    "    print(OmegaConf.to_yaml(cfg_no_hydra))\n",
    "\n",
    "    HydraConfig.instance().set_config(cfg)\n",
    "    print(OmegaConf.to_yaml((HydraConfig.get().runtime)))\n",
    "\n",
    "    output_dir = Path(cfg.hydra.run.dir).absolute()\n",
    "    # HydraConfig.get().runtime[\"output_dir\"] = output_dir\n",
    "    HydraConfig.instance().set_config(cfg)\n",
    "\n",
    "    print(f\"Output dir: {output_dir}\")\n",
    "\n",
    "    train_rnn(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "\n",
    "# instantiate the datamodule\n",
    "\n",
    "datamodule = hydra.utils.instantiate(cfg.datamodule)\n",
    "train_dataloader = datamodule.train_dataloader\n",
    "val_dataloader = datamodule.val_dataloader\n",
    "test_dataloader = datamodule.test_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint already exists at /tmp/physmodjax/checkpoints_fiug7qv5:v0, skipping\n",
      "Using data_info from config: [1, 101, 1]\n",
      "Restoring checkpoint from step 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diaz/anaconda3/envs/physmodjax_private/lib/python3.10/site-packages/orbax/checkpoint/type_handlers.py:1552: UserWarning: Couldn't find sharding info under RestoreArgs. Populating sharding info from sharding file. Please note restoration time will be slightly increased due to reading from file instead of directly from RestoreArgs. Note also that this option is unsafe when restoring on a different topology than the checkpoint was saved with.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# | eval: false\n",
    "\n",
    "checkpoint_path, cfg = download_ckpt_single_run(\"eager-valley-1758\")\n",
    "kwargs = {\"n_steps\": datamodule.num_steps_target_val}\n",
    "state, model, ckpt_manager = restore_experiment_state(\n",
    "    checkpoint_path,\n",
    "    kwargs=kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "\n",
    "from functools import partial\n",
    "from physmodjax.utils.metrics import (\n",
    "    mse,\n",
    "    mae,\n",
    "    mse_relative,\n",
    "    mae_relative,\n",
    "    accumulate_metrics,\n",
    ")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | eval: false\n",
    "\n",
    "@partial(jax.jit, static_argnames=(\"model\", \"norm\"))\n",
    "def val_step(\n",
    "    state: train_state.TrainState,\n",
    "    x,\n",
    "    y,\n",
    "    model,\n",
    "    norm,\n",
    "):\n",
    "    if norm in [\"batch\"]:\n",
    "        pred = model.apply(\n",
    "            {\"params\": state.params, \"batch_stats\": state.batch_stats}, x\n",
    "        )\n",
    "    else:\n",
    "        pred = model.apply({\"params\": state.params}, x)\n",
    "\n",
    "    metrics = {\n",
    "        \"val/mse\": mse(y, pred),\n",
    "        \"val/mae\": mae(y, pred),\n",
    "        \"val/mse_rel\": mse_relative(y, pred),\n",
    "        \"val/mae_rel\": mae_relative(y, pred),\n",
    "    }\n",
    "    return metrics, pred\n",
    "\n",
    "\n",
    "val_batch_metrics = []\n",
    "for x, y in val_dataloader:\n",
    "\n",
    "    metrics, pred = val_step(\n",
    "        state,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        model=model,\n",
    "        norm=cfg.model.norm,\n",
    "    )\n",
    "    val_batch_metrics.append(metrics)\n",
    "val_batch_metrics = accumulate_metrics(val_batch_metrics)\n",
    "\n",
    "metrics = ckpt_manager.metrics(ckpt_manager.best_step())\n",
    "val_metrics = {k: v for k, v in metrics.items() if \"val\" in k}\n",
    "\n",
    "for key, value in val_metrics.items():\n",
    "    assert np.isclose(\n",
    "        value, val_batch_metrics[key], atol=1e-6\n",
    "    ), f\"Metric {key} does not match: {value} != {val_batch_metrics[key]}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
