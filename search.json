[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\nTowards Efficient Modelling of String Dynamics: A Comparison of State Space and Koopman based Deep Learning Methods\n",
    "section": "",
    "text": "This is the accompanying repository for the paper Towards Efficient Modelling of String Dynamics: A Comparison of State Space and Koopman Methods.\n\n\n\n\narXiv",
    "crumbs": [
      "Install"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "\nTowards Efficient Modelling of String Dynamics: A Comparison of State Space and Koopman based Deep Learning Methods\n",
    "section": "Install",
    "text": "Install\nCreate an enviroment with conda with at least python 3.10\nconda create -n physmodjax python=3.10\nInstall Jax first\npip install --upgrade \"jax[cuda12_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\nInstall the rest of the dependencies\npip install -e '.[dev]'",
    "crumbs": [
      "Install"
    ]
  },
  {
    "objectID": "index.html#generate-the-dataset",
    "href": "index.html#generate-the-dataset",
    "title": "\nTowards Efficient Modelling of String Dynamics: A Comparison of State Space and Koopman based Deep Learning Methods\n",
    "section": "Generate the dataset",
    "text": "Generate the dataset\nTo generate the dataset use the following command from the root of the repository, after installing the library:\ngenerate_dataset -m +dataset=ftm_string_linear\ngenerate_dataset -m +dataset=ftm_string_nonlinear\nEach command will create 4 folders with combinations of initial conditions and sampling rates for the linear and nonlinear string models.\nEach dataset folder must be converted to a single file .npy file using the following command, for example:\nconvert_to_single_file \\\ndata/ftm_linear/ftm_string_lin_1000_Gaussian_4000Hz \\\ndata/ftm_linear/ftm_string_lin_1000_Gaussian_4000Hz.npy\nWe do this to speed up the data loading process during training.\n\nData convention\nThe data has the following convention:\n\n(timesteps, gridpoints[x,y,z], state_variables[u,v])\n\nand for multiple trajectories (initial conditions):\n\n(initial_conditions, timesteps, gridpoints[x,y,z], state_variables[u,v])",
    "crumbs": [
      "Install"
    ]
  },
  {
    "objectID": "index.html#premade-datasets",
    "href": "index.html#premade-datasets",
    "title": "\nTowards Efficient Modelling of String Dynamics: A Comparison of State Space and Koopman based Deep Learning Methods\n",
    "section": "Premade Datasets",
    "text": "Premade Datasets\nThe location for storing datasets in apocrita is:\n/data/EECS-Sandler-Lab/physical_modelling",
    "crumbs": [
      "Install"
    ]
  },
  {
    "objectID": "index.html#train",
    "href": "index.html#train",
    "title": "\nTowards Efficient Modelling of String Dynamics: A Comparison of State Space and Koopman based Deep Learning Methods\n",
    "section": "Train",
    "text": "Train\nAll experiments need a path where the data is located. This has to be appended to the command:\n++datamodule.data_array=data.npy\n\nTrain 1d model (default whole truncated trajectory at 4000 steps)\n\n\n\n\n\n\n\nModel\nCommand\n\n\n\n\n1d Koopman\ntrain_rnn +experiment=1d_koopman ++epochs=1000 ++epochs_val=50 ++optimiser.learning_rate=0.001 ++model.d_vars=1\n\n\n1d Koopman time-varying\ntrain_rnn +experiment=1d_koopman_varying ++epochs=1000 ++epochs_val=50 ++optimiser.learning_rate=0.001 ++model.d_vars=1\n\n\n1d LRU\ntrain_rnn +experiment=1d_lru ++epochs=1000 ++epochs_val=50 ++optimiser.learning_rate=0.001 ++model.d_vars=1\n\n\n1d S5\ntrain_rnn +experiment=1d_s5 ++epochs=1000 ++epochs_val=50 ++optimiser.learning_rate=0.001 ++model.d_vars=1\n\n\n1d FNO\ntrain_rnn +experiment=1d_fno ++epochs=1000 ++epochs_val=50 ++optimiser.learning_rate=0.001 ++model.d_vars=1\n\n\n\n\n\nTrain 1d model with non-overlapping segments of 400 steps (for AR mode)\n\n\n\n\n\n\n\nModel\nCommand\n\n\n\n\n1d Koopman\ntrain_rnn +experiment=1d_koopman datamodule=string_windowed\n\n\n1d Koopman time-varying\ntrain_rnn +experiment=1d_koopman_varying datamodule=string_windowed\n\n\n1d LRU\ntrain_rnn +experiment=1d_lru datamodule=string_windowed\n\n\n1d S5\ntrain_rnn +experiment=1d_s5 datamodule=string_windowed\n\n\n1d FNO\ntrain_rnn +experiment=1d_fno datamodule=string_windowed\n\n\n\n\n\nTrain 1d model with random (overlapping) segments of 400 steps per trajectory (for AR mode)\nHere we can also test against FNO.\n\n\n\n\n\n\n\nModel\nCommand\n\n\n\n\n1d Koopman\ntrain_rnn +experiment=1d_koopman datamodule=string_tb ++epochs=200 ++epochs_val=20\n\n\n1d Koopman time-varying\ntrain_rnn +experiment=1d_koopman_varying datamodule=string_tb ++epochs=200 ++epochs_val=20\n\n\n1d LRU\ntrain_rnn +experiment=1d_lru datamodule=string_tb ++epochs=200 ++epochs_val=20\n\n\n1d S5\ntrain_rnn +experiment=1d_s5 datamodule=string_tb ++epochs=200 ++epochs_val=20\n\n\n1d FNO\ntrain_rnn +experiment=1d_s5 datamodule=string_tb +experiment=1d_fno_tb ++epochs=200 ++epochs_val=20",
    "crumbs": [
      "Install"
    ]
  },
  {
    "objectID": "index.html#testing-the-library",
    "href": "index.html#testing-the-library",
    "title": "\nTowards Efficient Modelling of String Dynamics: A Comparison of State Space and Koopman based Deep Learning Methods\n",
    "section": "Testing the library",
    "text": "Testing the library\nFor development purposes, you can use the following command to test the library:\nJAX_PLATFORMS=cpu nbdev_test\nUsing the JAX_PLATFORMS=cpu environment variable is important to avoid using the GPU, as the tests are not optimized for GPU usage.\nThe same should be done for exporting the readme:\nJAX_PLATFORMS=cpu nbdev_readme",
    "crumbs": [
      "Install"
    ]
  },
  {
    "objectID": "scripts/dataset_generation.html",
    "href": "scripts/dataset_generation.html",
    "title": "Dataset generation",
    "section": "",
    "text": "source",
    "crumbs": [
      "Scripts",
      "Dataset generation"
    ]
  },
  {
    "objectID": "scripts/dataset_generation.html#convert-to-single-file",
    "href": "scripts/dataset_generation.html#convert-to-single-file",
    "title": "Dataset generation",
    "section": "Convert to single file",
    "text": "Convert to single file\n\nsource\n\nconvert_to_single_file\n\n convert_to_single_file (data_dir:str, output_file:str,\n                         target_dtype:str='np.float32')\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata_dir\nstr\n\nthe directory where the files are\n\n\noutput_file\nstr\n\nthe output file\n\n\ntarget_dtype\nstr\nnp.float32\nthe dtype of the output file",
    "crumbs": [
      "Scripts",
      "Dataset generation"
    ]
  },
  {
    "objectID": "solver/wave2d_solver_tensionmodulated.html",
    "href": "solver/wave2d_solver_tensionmodulated.html",
    "title": "Tension modulated stiff membrane",
    "section": "",
    "text": "The tension is given by \\[\nT(u) = T_0 + T_{NL}(u)\n\\]\nWe consider, \\[\nT_{N L}(u)=C_{N L} \\frac{S(u)-S_0}{S_0} \\simeq \\frac{1}{2} \\frac{C_{N L}}{S_0} \\int_{\\mathcal{S}}\\|\\nabla u\\|^2 d \\mathbf{x}\n\\] For the rectangular plate, the Berger approximation is used for the tension \\[\n\\begin{aligned}\nT_{N L}(u) \\simeq & \\frac{Q h}{2 L_x L_y\\left(1-\\nu^2\\right)} \\\\\n& \\cdot \\int_0^{L_x} \\int_0^{L_y}\\left[\\left(\\frac{\\partial u}{\\partial x}\\right)^2+\\left(\\frac{\\partial u}{\\partial y}\\right)^2\\right] d x d y .\n\\end{aligned}\n\\] And therefore \\[\nC_{N L}=\\frac{Q h}{\\left(1-\\nu^2\\right)}\n\\]\n\\[\n\\boxed{\n\\begin{aligned}\n\\rho h \\ddot{\\bar{u}}_{n, m}(t) + \\left(d_3 \\lambda_{n, m}+d_1\\right) \\dot{\\bar{u}}_{n, m}( t) + \\left(\\lambda_{n, m} \\left(\\lambda_{n, m}D +T_0\\right)\\right) \\bar{u}_{n, m}(t)-\\bar{f}^{(tm)}_{n, m}(u, \\bar{u}) = 0\n\\end{aligned}\n}\n\\]\nWhere \\[\n\\begin{aligned}\nf^{(tm)}_{n, m}(u, \\bar{u}) & = -\\lambda_{n, m} T_{N L} (u) \\bar{u}_{n, m}(t) \\\\\n& = -\\lambda_{n, m} \\frac{1}{2}\\frac{C_{N L}}{S_0} \\left[\\sum_{\\tilde{n}, \\tilde{m}} \\frac{\\lambda_{\\tilde{n}, \\tilde{m}}\\bar{u}_{\\tilde{n}, \\tilde{m}}^2 (t)}{\\lVert K_{\\tilde{n}, \\tilde{m}} \\rVert_{2}^{2}} \\right] \\bar{u}_{n, m}(t)\n\\end{aligned}\n\\]\nFor a rectangular plate, the norm of the modes is given by \\[\\lVert K_{n, m} \\rVert_{2}^{2} = \\langle K_{n, m} , K_{n, m} \\rangle = \\int _0^{L_x}\\int _0^{L_y}\\sin ^2\\left(\\frac{n \\pi  x}{L_x}\\right) \\sin ^2\\left(\\frac{m \\pi  y}{L_y}\\right)dydx = \\frac{L_x L_y}{4} \\quad \\forall n, m \\in \\mathbb{Z} \\]\nWrite as a system of first order ODEs:\n\\[\n\\begin{aligned}\n\\dot{\\bar{u}}(\\mu, t) &= \\bar{v}(\\mu, t) \\\\\n\\dot{\\bar{v}}(\\mu, t) &= \\frac{-\\left(d_3 \\lambda_\\mu+d_1\\right)}{\\rho h} \\bar{v}(\\mu, t) - \\frac{\\beta_\\mu}{\\rho h} \\bar{u}(\\mu, t) + \\frac{f^{(tm)}_{\\mu}(u, \\bar{u})}{\\rho h}\n\\end{aligned}\n\\]\nWhere \\[\n\\begin{aligned}\n\\beta_\\mu &= \\lambda_\\mu \\left(\\lambda_\\mu D + T_0\\right) = \\lambda_\\mu^2 D + \\lambda_\\mu T_0 \\\\\n\\bar{b}(\\mu, u, \\bar{u}) &= \\frac{f^{(tm)}_{\\mu}(u, \\bar{u})}{\\rho h}  \\\\\n&= -\\frac{1}{\\rho h} \\lambda_{\\mu} \\frac{1}{2}\\frac{Q h}{\\left(1-\\nu^2\\right)}\\frac{1}{L_x L_y} \\frac{4}{L_x L_y}\\left[\\sum_{\\eta} \\lambda_{\\eta}\\bar{u}_{\\eta}^2 (t) \\right] \\bar{u}_{\\mu}(t) \\\\\n&= -\\lambda_{\\mu} \\frac{Q}{\\rho \\left(1-\\nu^2\\right)}\\frac{2}{L_x^2 L_y^2}\\left[\\sum_{\\eta} \\lambda_{\\eta}\\bar{u}_{\\eta}^2 (t) \\right] \\bar{u}_{\\mu}(t) \\\\\n\\end{aligned}\n\\]\n${u}{n, m}(t) = {u}{}(t) $ is a matrix, but to be able to feed it to solve_ivp, we will flatten it to a vector, and index it as $= n N_y + m $ where \\(N_y\\) is the number of modes in the y direction.\nThis is a system of first-order ODEs. In matrix form, we can write this as:\n\\[\n\\boxed{\n\\begin{aligned}\n\\mathbf{\\dot{\\bar{u}}} &= \\mathbf{\\bar{v}} \\\\\n\\mathbf{\\dot{\\bar{v}}} &= -\\mathbf{M_v} \\mathbf{\\bar{v}} - \\mathbf{M_u} \\mathbf{\\bar{u}} + \\mathbf{\\bar{b}}\n\\end{aligned}\n}\n\\]\nThe Matrices \\(\\mathbf{M_v}\\), \\(\\mathbf{M_y}\\) are diagonal matrices whose order is equal to the number of modes \\(M\\).\n\\[\n\\begin{aligned}\n\\mathbf{\\Lambda} &= \\text{diag}\\left(\\lambda_\\mu\\right) \\\\\n\\mathbf{M_v} &= \\text{diag}\\left(\\frac{d_3 \\lambda_\\mu + d_1}{\\rho h}\\right) \\\\\n\\mathbf{M_y} &= \\text{diag}\\left(\\frac{\\beta_\\mu}{\\rho h}\\right) \\\\\n\\mathbf{\\bar{b}}(\\mathbf{u}, \\mathbf{\\bar{u}}) &= - \\frac{Q}{\\rho \\left(1-\\nu^2\\right)}\\frac{2}{L_x^2 L_y^2}\\mathbf{\\Lambda} \\left[ \\mathbf{\\bar{u}}^{T} \\mathbf{\\Lambda} \\mathbf{\\bar{u}} \\right] \\mathbf{\\bar{u}}  \\\\\n\\mathbf{\\bar{b}}(\\mathbf{u}, \\mathbf{\\bar{u}}) &= - \\mathbf{C_b}\\mathbf{\\Lambda} \\left[ \\mathbf{\\bar{u}}^{T} \\mathbf{\\Lambda} \\mathbf{\\bar{u}} \\right] \\mathbf{\\bar{u}}  \\\\\n\\end{aligned}\n\\]\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib.animation import FuncAnimation\n\n\nsource\n\nWave2dSolverTensionModulated\n\n Wave2dSolverTensionModulated (sampling_rate:int=16000,\n                               final_time:float=0.5,\n                               n_gridpoints_x:int=41, length_x:float=0.4,\n                               aspect_ratio:float=0.8, rho:float=1380,\n                               h:float=0.00019, E:int=3500000000.0,\n                               nu:float=0.3, d1:float=8e-05,\n                               d3:float=1.4e-05, Ts0:float=2620,\n                               n_max_modes:int=36,\n                               use_nonlinear:bool=True)\n\nTension modulated wave equation solver for a rectangular stiff membrane. The parameters were taken from (Fletcher, 1991, p.86) and adapted to a rectangular case.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsampling_rate\nint\n16000\n1/s Temporal sampling frequency\n\n\nfinal_time\nfloat\n0.5\ns Duration of the simulation\n\n\nn_gridpoints_x\nint\n41\npts/m Spatial sampling grid\n\n\nlength_x\nfloat\n0.4\nm Length of x dimension\n\n\naspect_ratio\nfloat\n0.8\nAspect ratio of the membrane, Ly/Lx\n\n\nrho\nfloat\n1380\nkg/m**3 Density\n\n\nh\nfloat\n0.00019\nm Thickness\n\n\nE\nint\n3500000000.0\nPa Young’s modulus\n\n\nnu\nfloat\n0.3\nPoisson’s ratio\n\n\nd1\nfloat\n8e-05\nkg/(ms) Frequency independent loss\n\n\nd3\nfloat\n1.4e-05\nkg m/s Frequency dependent loss\n\n\nTs0\nfloat\n2620\nN/m Tension per unit length\n\n\nn_max_modes\nint\n36\nNumber of modal coordinates\n\n\nuse_nonlinear\nbool\nTrue\nUse nonlinear wave equation\n\n\n\n\n# Initialize the solver\nsolver = Wave2dSolverTensionModulated(sampling_rate=16000, final_time=0.005, n_max_modes=625,n_gridpoints_x=161, use_nonlinear=True)\n# Plot some of the modes\nnx = 3\nny = 2\nfig, ax = plt.subplots(nx, ny, figsize=(5, 15))\naspect_ratio_dxdy = solver.dx/solver.dy\n# Print this aspect ratio and the one used in the solver\nsolver.print_solver_info()\nprint(f\"Aspect ratio: {aspect_ratio_dxdy}\")\nprint(f\"Solver aspect ratio: {solver.aspect_ratio}\")\nfor i in range(nx):\n    for j in range(ny):\n        print(f\"Mode max value: {np.max(solver.modes[i, j, :, :])}\")\n        ax[i, j].imshow(solver.modes[i, j, :, :], aspect = aspect_ratio_dxdy, origin='lower')\n        ax[i, j].set_title(f\"Mode nx={i+1}, ny={j+1}\")\n        ax[i, j].set_xlabel(\"y\")\n        ax[i, j].set_ylabel(\"x\")\n        # ax[i, j].tight_layout()\n\ndx: 0.0025 in meters\ndy: 0.0025000000000000005 in meters\ndt: 6.25e-05 in seconds\nnumber of points in the x direction (n_gridpoints_x): 161\nnumber of points in the y direction (n_gridpoints_y): 129\ntime in samples (nt): (80,)\nnumber of modes in x direction (n_max_modes_x): 25\nnumber of modes in y direction (n_max_modes_y): 25\nnumber of modes (n_max_modes): 625\nlength in x direction (length_x): 0.4 in meters\nlength in y direction (length_y): 0.32000000000000006 in meters\ngrid_x shape: (161, 129)\ngrid_y shape: (161, 129)\nwavenumbers_x shape: (25,)\nwavenumbers_y shape: (25,)\nmodes shape: (25, 25, 161, 129)\nlambdas shape: (625,)\nAspect ratio: 0.9999999999999998\nSolver aspect ratio: 0.8\nMode max value: 1.0\nMode max value: 1.0\nMode max value: 1.0\nMode max value: 1.0\nMode max value: 0.9998072404820648\nMode max value: 1.0\n\n\n\n\n\n\n\n\n\n\n# Create a simple initial condition, one the modes + additive noise\nmode_n = 3\nmode_m = 3\nindn = mode_n - 1\nindm = mode_m - 1\n\nu0 = 0.0*solver.modes[indn, indm, :, :] + 0.001 * np.random.randn(solver.n_gridpoints_x, solver.n_gridpoints_y)\nv0 = np.zeros_like(u0)\n\n\n# This was code for checking the projection to modal coordinates depending on the integration method\n\nu0 = solver.modes[indn, indm, :, :]\nv0 = np.zeros_like(u0)\n\n# Project the initial condition to modal coordinates\nbar_u_simpson, bar_v_simpson = solver.to_modal(u0,v0)\n# Print the modal coordinates\nprint(\"Difference\")\n# Print the difference between the two methods\n# print(bar_z - bar_z2)\n\n# f = lambda y, x: np.sin(solver.wavenumbers_x[indn] * x) * np.sin(solver.wavenumbers_y[indm] * y)*np.sin(solver.wavenumbers_x[indn] * x) * np.sin(solver.wavenumbers_y[indm] * y)\n# for i, x in enumerate(solver.x):\n#     for j, y in enumerate(solver.y):\n#         f_val = f(y, x)\n#         difference = f_val-solver.modes[indn, indm, i, j]\n#         if difference &gt; 1e-15:\n#             print(f\"Error at ({x}, {y})\")\n#             print(f\"Exact: {f_val}\")\n#             print(f\"Approx: {solver.modes[indn, indm, i, j]}\")\n#             print(f\"Difference: {difference}\")\n# print(solver.length_x)\n# print(solver.length_y)\n# print(solver.wavenumbers_x[indn])\n# print(solver.wavenumbers_y[indm])\n# exact_int = dblquad(f, 0, 1.0, 0, 0.5)\n# print((exact_int))\n\nDifference\n\n\n\ndef gaussian_pulse(x_grid, y_grid, x0, y0, sigma):\n    return np.exp(-((x_grid-x0)**2 + (y_grid-y0)**2)/(2*sigma**2))\n\ndef noise(grid):\n    return np.random.randn(grid.shape)\n\n\n# Solve the wave equation\n# u0 = np.zeros((solver.n_gridpoints_x, solver.n_gridpoints_y))\nu0 = (solver.modes[0, 0, :, :]**2)\n# Create a gaussian impulse\nu0 = np.zeros((solver.n_gridpoints_x, solver.n_gridpoints_y))\nu0 = np.random.randn(solver.n_gridpoints_x, solver.n_gridpoints_y)\nctr = (0.37*solver.length_x, 0.63*solver.length_y)\nstd = 0.005\nfor i in range(solver.n_gridpoints_x):\n    for j in range(solver.n_gridpoints_y):\n        u0[i, j] = np.exp(-((solver.grid_x[i, j] - ctr[0])**2 + (solver.grid_y[i, j] - ctr[1])**2)/(2*std**2))\n\nu0_alt = gaussian_pulse(solver.grid_x, solver.grid_y, ctr[0], ctr[1], std)\n# Compare the two initial conditions\nprint(np.allclose(u0, u0_alt))\nv0 = np.zeros_like(u0)\nu0 = 0.005*u0\n# Add a delta impuse to the initial velocity, close to the center\n# v0[solver.n_gridpoints_x//2, solver.n_gridpoints_y//2] = 20\n\nt, u, v = solver.solve(u0=u0, v0=v0)\nprint(f\"u shape: {u.shape}\")\nprint(f\"v shape: {v.shape}\")\n\nTrue\nbar_u shape: (625, 80)\nbar_v shape: (625, 80)\nu shape: (80, 161, 129)\nv shape: (80, 161, 129)\n\n\n\n# Check that the boundary conditions are maintained\nprint(np.all(u[:, 0, :] == 0))\nprint(np.all(u[:, -1, :] == 0))\nprint(np.all(u[:, :, 0] == 0))\nprint(np.all(u[:, :, -1] == 0))\n\n# Plot the sum error of the solution at the edges for all timesteps\nplt.figure()\nplt.plot(t, np.sum(u[:, 0, :], axis=1), label=\"bottom\")\nplt.plot(t, np.sum(u[:, -1, :], axis=1), label=\"top\")\nplt.plot(t, np.sum(u[:, :, 0], axis=1), label=\"left\")\nplt.plot(t, np.sum(u[:, :, -1], axis=1), label=\"right\")\nplt.legend()\nplt.xlabel(\"Time\")\nplt.ylabel(\"Sum of displacement at the edges\")\nplt.title(\"Boundary conditions\")\nplt.show()\n\nTrue\nFalse\nTrue\nFalse\n\n\n\n\n\n\n\n\n\n\n# Plot the solution as an animation usign matplotlib\n\n# N_plots=100\nfig,ax = plt.subplots(1,2)\ndef animate(i):\n    ax[0].clear()\n    ax[1].clear()\n    ax[0].imshow(u[i,:,:], aspect = aspect_ratio_dxdy, origin='lower')\n    ax[1].imshow(v[i,:,:], aspect = aspect_ratio_dxdy, origin='lower')\n    ax[0].set_title(f\"Displacement\")\n    ax[0].set_xlabel(\"y\")\n    ax[0].set_ylabel(\"x\")\n    ax[1].set_title(f\"Velocity\")\n    ax[1].set_xlabel(\"y\")\n    ax[1].set_ylabel(\"x\")\nani = FuncAnimation(fig, animate, frames=20,\n                    interval=500, repeat=False)\nplt.close()\nfrom IPython.display import HTML\nHTML(ani.to_jshtml())\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect",
    "crumbs": [
      "Solver",
      "Tension modulated stiff membrane"
    ]
  },
  {
    "objectID": "solver/wave1d_solver_fe.html",
    "href": "solver/wave1d_solver_fe.html",
    "title": "Finite element solver for the 1D wave equation",
    "section": "",
    "text": "We use finite elements to obtain the mass \\(M\\) and stiffness \\(K\\) matrices. We use bilinear discretization for the time stepping.\n\\[\n\\begin{bmatrix} \\dot{\\mathbf{x}} \\\\ \\ddot{\\mathbf{x}} \\end{bmatrix} = \\begin{bmatrix} 0 & \\mathbf{I} \\\\ -\\mathbf{M}^{-1}\\mathbf{K} & 0 \\end{bmatrix} \\begin{bmatrix} \\mathbf{x} \\\\ \\dot{\\mathbf{x}} \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ \\mathbf{M}^{-1} \\end{bmatrix} \\mathbf{f}\n\\]\n\nsource\n\ndiscretize\n\n discretize (A, step)\n\nJax compatible bilinear discretization from https://github.com/srush/annotated-s4\n\nsource\n\n\nWave1dSolverFE\n\n Wave1dSolverFE (sampling_rate:float, final_time:float, length:float,\n                 n_gridpoints:int, wave_speed:float=1)\n\nThis class solves the 1D wave equation using finite elements and state space discretization.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsampling_rate\nfloat\n\nsampling rate in Hz\n\n\nfinal_time\nfloat\n\nfinal time in seconds\n\n\nlength\nfloat\n\nlength of the string in meters\n\n\nn_gridpoints\nint\n\nnumber of points in the string\n\n\nwave_speed\nfloat\n1\nwave speed in m/s\n\n\n\nTest\n\nfrom physmodjax.solver.generator import Gaussian\n\n\nn_gridpoints = 200\nsolver = Wave1dSolverFE(\n    sampling_rate=2000,\n    final_time=1,\n    length=1,\n    n_gridpoints=n_gridpoints,\n    wave_speed=10,\n)\n\nu0 = Gaussian(num_points=n_gridpoints)()\nv0 = np.zeros_like(u0)\n\nt, u, v = solver.solve(u0, v0)\n\ndx: 0.005025125628140704 in meters\ndt: 0.0005 in seconds\nnumber of points (n_gridpoints): (200,)\ntime in samples (nt): (2000,)\n\n\n\nplt.plot(solver.grid, u[50], label=\"initial\")\n\n\n\n\n\n\n\n\n\n# show the solution viewed from above\nplt.figure(figsize=(5, 10))\nplt.pcolormesh(solver.grid, t, u)\nplt.xlabel(\"x\")\nplt.ylabel(\"t\")\nplt.colorbar()\nplt.show()",
    "crumbs": [
      "Solver",
      "Finite element solver for the 1D wave equation"
    ]
  },
  {
    "objectID": "solver/wave1d_solver_modal.html",
    "href": "solver/wave1d_solver_modal.html",
    "title": "Modal Solver",
    "section": "",
    "text": "This is a solver based on the analytic modal decomposition for a 1D wave equation. The wave equation is given by: \\[\\frac{\\partial^2 u}{\\partial t^2} = c^2 \\frac{\\partial^2 u}{\\partial x^2}\\]\nSolving this equation using separation of variables, we use the following ansatz \\[u(x,t) = X(x)T(t)\\] which leads to the following equation: \\[\\frac{1}{c^2}\\frac{1}{T(t)}\\frac{d^{2} T }{dt^{2}} = \\frac{1}{X(x)}\\frac{d^{2} X}{dx^{2}} = -k^{2}\\] where \\(k\\) is a constant\n\\[\\frac{1}{T(t)}\\frac{d^{2} T }{dt^{2}} = -c^{2}k^{2} \\equiv - \\omega^{2}\\]\nThe solutions are therefore \\[X(x) = C\\cos(kx) + D\\sin(kx)\\] \\[T(t) = E\\cos(\\omega t) + F\\sin(\\omega t)\\]\nUsing the boundary conditions, we can get an expression for the allowed values of \\(k\\)\n\nDirichlet on both ends\n\\[u(0,t) = u(L,t) = 0\\] \\[X(0) = X(L) = 0\\] \\[C = 0\\] \\[k = \\frac{n\\pi}{L}\\] with n = 1,2,3,… And the eigenmodes are \\[X_{n}(x) = D_{n}\\sin(k_{n}x)\\] The complete solution then is \\[u(x,t) = \\sum_{n=1}^{\\infty} D_{n}\\sin(k_{n}x)\\left(E_{n}\\cos(\\omega_{n}t) + F_{n}\\sin(\\omega_{n}t)\\right)\\] Using \\(A_{n} = D_{n}E_{n}\\) and \\(B_{n} = D_{n}F_{n}\\), we get \\[u(x,t) = \\sum_{n=1}^{\\infty} \\sin(k_{n}x) \\left(A_{n}\\cos(\\omega_{n}t) + B_{n}\\sin(\\omega_{n}t)\\right)\\] The derivative, \\(v(x,t) = \\frac{\\partial u}{\\partial t}\\), is given by \\[v(x,t) = \\sum_{n=1}^{\\infty} \\sin(k_{n}x) \\left(-A_{n}\\omega_{n}\\sin(\\omega_{n}t) + B_{n}\\omega_{n}\\cos(\\omega_{n}t)\\right)\\]\nTo determine the coefficients \\(A_{n}\\) and \\(B_{n}\\), we use the initial conditions \\[u(x,0) = f(x)\\] \\[\\frac{\\partial u}{\\partial t}(x,0) = g(x)\\] which gives \\[f(x) = \\sum_{n=1}^{\\infty} A_{n}\\sin(k_{n}x)\\] \\[g(x) = \\sum_{n=1}^{\\infty} B_{n}\\omega_{n}\\sin(k_{n}x)\\]\nAs \\(k_{n}=n\\pi/L\\), we can see that summations correspond to a Fourier sine series expansion of \\(f(x)\\) and \\(g(x)\\). This assumes that \\(f(x)\\) and \\(g(x)\\) are odd functions, which is the case for the initial conditions, if we consider a periodic extension of the initial conditions, with period \\(2L\\). The initial conditions need to fulfill the boundary conditions, which means that \\(f(0)=f(L)=0\\) and, consequently \\(g(0)=g(L)=0\\). This is the case for odd functions, and therefore we can use the Fourier sine series expansion.\nThen the coefficients are given by \\[A_{n} = \\frac{2}{L}\\int_{0}^{L} f(x)\\sin(k_{n}x) dx\\] \\[B_{n} = \\frac{2}{L\\omega_{n}}\\int_{0}^{L} g(x)\\sin(k_{n}x) dx\\]\n\n\nNeumann on both ends\n\\[\\frac{\\partial u}{\\partial x}(0,t) = \\frac{\\partial u}{\\partial x}(L,t) = 0\\] \\[\\frac{dX}{dx}(0) = \\frac{dX}{dx}(L) = 0\\] \\[D = 0\\] \\[k = \\frac{n\\pi}{L}\\] with n = 0,1,2,3,… And the eigenmodes are \\[X_{n}(x) = C_{n}\\cos(k_{n}x)\\]\nThe difference between the Dirichlet and Neumann boundary conditions is the allowed values of n, and the form of the eigenfunctions, but the wavenumbers and modal frequencies are the same (except the existence of the zero frequency mode for the Neumann boundary conditions). For n=0, the solution \\(u(x,t)\\) is a constant, corresponding to the zero frequency mode. This is the rigid motion of the string, or air column, or whatever is being modeled.\nThe complete solution then is \\[u(x,t) = \\sum_{n=0}^{\\infty} C_{n}\\cos(k_{n}x)\\left(E_{n}\\cos(\\omega_{n}t) + F_{n}\\sin(\\omega_{n}t)\\right)\\] Using \\(A_{n} = C_{n}E_{n}\\) and \\(B_{n} = C_{n}F_{n}\\), we get \\[u(x,t) = \\sum_{n=0}^{\\infty} \\cos(k_{n}x) \\left(A_{n}\\cos(\\omega_{n}t) + B_{n}\\sin(\\omega_{n}t)\\right)\\]\nTo determine the coefficients \\(A_{n}\\) and \\(B_{n}\\), we use the initial conditions \\[u(x,0) = f(x)\\] \\[\\frac{\\partial u}{\\partial t}(x,0) = g(x)\\] which can be expressed as cosine series \\[f(x) = \\frac{A_{0}}{2} + \\sum_{n=1}^{\\infty} A_{n}\\cos(k_{n}x)\\] \\[g(x) = \\frac{B_{0}}{2} + \\sum_{n=1}^{\\infty} B_{n}\\omega_{n}\\cos(k_{n}x)\\]\nNote on initial velocity\nAs \\(k_{n}=n\\pi/L\\), we can see that summations correspond to a Fourier cosine series expansion of \\(f(x)\\) and \\(g(x)\\). This assumes that \\(f(x)\\) and \\(g(x)\\) are even functions, which is the case for initial conditions that also fulfil the boundary conditions, \\(\\frac{\\partial u}{\\partial x}(0,t) = \\frac{\\partial u}{\\partial x}(L,t) = 0\\) , if we consider a periodic extension of the initial conditions \\([-L,L]\\), with period \\(2L\\). The initial velocity definitily needs to be even, as its derivative has to be 0 for x=0\n\n\nDirichlet on one end, Neumann on the other\n\\[u(0,t) = 0\\] \\[\\frac{\\partial u}{\\partial x}(L,t) = 0\\] \\[C = 0\\] \\[k = \\frac{(n-\\frac{1}{2})\\pi}{L}\\] with n = 1,2,3,…\n\\[(u_{n+1} -2u_{n} +u_{n-1})/k^2 = c^2 Dxx u_n\\]\n\nimport matplotlib.pyplot as plt\n\n\nsource\n\n\nWave1dSolverModal\n\n Wave1dSolverModal (sampling_rate:int=48000, final_time:float=1.0,\n                    n_gridpoints:int=101, length:float=1,\n                    wave_speed:float=1,\n                    boundary_conditions:str='dirichlet_dirichlet',\n                    n_max_modes:int=50)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsampling_rate\nint\n48000\nsampling rate, Hz (default: 48000)\n\n\nfinal_time\nfloat\n1.0\nfinal time of the simulation, seconds (default: 1)\n\n\nn_gridpoints\nint\n101\nnumber of grid points (default: 101)\n\n\nlength\nfloat\n1\nlength of the domain, meters (default: 1)\n\n\nwave_speed\nfloat\n1\nwave speed, meters/second (default: 1)\n\n\nboundary_conditions\nstr\ndirichlet_dirichlet\nboundary conditions, either “dirichlet_dirichlet”, “neumann_neumann”, “dirichlet_neumann” (default: “dirichlet_dirichlet”)\n\n\nn_max_modes\nint\n50\nnumber of eigenmodes to calculate (default: 50)\n\n\nReturns\nNone\n\n\n\n\n\n\n# Test that the solver class is working\nsolver = Wave1dSolverModal(\n    final_time=1,\n    length=1,\n    wave_speed=1,\n    boundary_conditions=\"dirichlet_dirichlet\",\n)\nprint(2 * jnp.pi / solver.wavenumbers)\n\n# plot the first 5 mode shapes\nplt.figure(figsize=(8, 4))\nplt.plot(solver.grid, solver.modes[:5, :].T)  # plot the first 5 mode shapes\nplt.xlabel(\"x\")\nplt.ylabel(\"Mode shape\")\nplt.show()\n\nprint(solver.timesteps.shape)\nprint(solver.timesteps[-1])\n\n# print the types for the solver attributes\nprint(type(solver.grid))\nprint(type(float(solver.timesteps[0])))\n\nkey = jax.random.PRNGKey(0)\n# create initial conditions\nu0, v0 = solver.create_initial_conditions(key=key, type=\"gaussian\", x0=0.5, sigma=0.1)\n\n# Plot initial displacement\nplt.figure(figsize=(8, 4))\nplt.plot(solver.grid, u0)\nplt.xlabel(\"x\")\nplt.ylabel(\"Initial displacement\")\nplt.show()\n\ndx: 0.009999999776482582 in meters\ndt: 2.0833333333333333e-05 in seconds\nnumber of points (n_gridpoints): (101,)\ntime in samples (nt): (48000,)\n[2.         1.         0.6666667  0.5        0.4        0.33333334\n 0.2857143  0.25       0.22222222 0.2        0.18181819 0.16666667\n 0.15384616 0.14285715 0.13333334 0.125      0.11764707 0.11111111\n 0.10526316 0.1        0.0952381  0.09090909 0.08695652 0.08333334\n 0.08       0.07692308 0.07407408 0.07142857 0.06896552 0.06666667\n 0.06451613 0.0625     0.06060607 0.05882353 0.05714286 0.05555556\n 0.05405405 0.05263158 0.05128206 0.05       0.04878049 0.04761905\n 0.04651163 0.04545455 0.04444445 0.04347826 0.04255319 0.04166667\n 0.04081633 0.04      ]\n\n\n\n\n\n\n\n\n\n(48000,)\n0.99997914\n&lt;class 'jaxlib.xla_extension.ArrayImpl'&gt;\n&lt;class 'float'&gt;\n\n\n\n\n\n\n\n\n\n\n# solve the system with the class method\n(t, u, v) = solver.solve(u0=u0, v0=v0)\nprint(u.shape)\nprint(v.shape)\nprint(t.shape)\n\n(48000, 101)\n(48000, 101)\n(48000,)\n\n\n\n# Plot solution at different times, start middle and end\nplt.figure(figsize=(8, 4))\nplt.plot(solver.grid, u[0, :], label=\"t=0\")\nplt.plot(solver.grid, u[int(u.shape[0] / 2), :], label=\"t=0.5\")\nplt.plot(solver.grid, u[-1, :], label=\"t=1\")\n# show the solution viewed from above\nplt.figure(figsize=(5, 10))\nplt.pcolormesh(solver.grid, t, u)\nplt.xlabel(\"x\")\nplt.ylabel(\"t\")\nplt.colorbar()\nplt.show()\n\n# show the solution v viewed from above\nplt.figure(figsize=(5, 10))\nplt.pcolormesh(solver.grid, t, v)\nplt.xlabel(\"x\")\nplt.ylabel(\"t\")\nplt.colorbar()\nplt.show()",
    "crumbs": [
      "Solver",
      "Modal Solver"
    ]
  },
  {
    "objectID": "models/fno.html",
    "href": "models/fno.html",
    "title": "Fourier Neural Operator in 1D and 2D",
    "section": "",
    "text": "We are interested in learning the mapping between function spaces. In particular, we are interested in learning the mapping between the input space \\(\\Omega\\) and the output space \\(\\Lambda\\) of a function \\(u: \\Omega \\rightarrow \\Lambda\\). We will assume that the input space is a subset of \\(\\mathbb{R}^d\\) and the output space is a subset of \\(\\mathbb{R}^m\\). We will also assume that the function \\(u\\) is smooth, i.e., it has a finite number of derivatives. We will denote the derivatives of \\(u\\) by \\(u_{x_i}\\), \\(u_{x_i x_j}\\), etc. We will also assume that the function \\(u\\) satisfies a partial differential equation (PDE) \\(\\mathcal{L} u = 0\\) for some linear differential operator \\(\\mathcal{L}\\).\nA single layer of the neural operator is defined as follows:\n\\[\n\\begin{aligned}\n\\mathcal{F} &:= \\sigma \\left(W +\\mathcal{K} + b \\right) \\\\\n\\mathcal{G}_\\theta &:=  \\mathcal{Q} \\circ \\mathcal{F}  \\circ \\mathcal{P}\n\\end{aligned}\n\\]\nwhere\n\n\\(\\mathcal{P} : \\mathbb{R^{in}} \\to \\mathbb{R^{hidden}}\\) is a lifting layer\n\\(\\mathcal{Q} : \\mathbb{R^{hidden}} \\to  \\mathbb{R^{out}}\\) is a projection layer\n\\(\\mathcal{F} \\colon \\mathbb{R^{hidden}} \\to  \\mathbb{R^{hidden}}\\) is the Neural Operator Layer with\n\n\\(\\mathcal{K}\\) is one of several Kernel Operators\n\\({W}\\) is a matrix (local linear operator); a “skip connection” inspired by ResNet\n\\(b\\) is a “function” bias",
    "crumbs": [
      "Models",
      "Fourier Neural Operator in 1D and 2D"
    ]
  },
  {
    "objectID": "models/fno.html#neural-operator",
    "href": "models/fno.html#neural-operator",
    "title": "Fourier Neural Operator in 1D and 2D",
    "section": "",
    "text": "We are interested in learning the mapping between function spaces. In particular, we are interested in learning the mapping between the input space \\(\\Omega\\) and the output space \\(\\Lambda\\) of a function \\(u: \\Omega \\rightarrow \\Lambda\\). We will assume that the input space is a subset of \\(\\mathbb{R}^d\\) and the output space is a subset of \\(\\mathbb{R}^m\\). We will also assume that the function \\(u\\) is smooth, i.e., it has a finite number of derivatives. We will denote the derivatives of \\(u\\) by \\(u_{x_i}\\), \\(u_{x_i x_j}\\), etc. We will also assume that the function \\(u\\) satisfies a partial differential equation (PDE) \\(\\mathcal{L} u = 0\\) for some linear differential operator \\(\\mathcal{L}\\).\nA single layer of the neural operator is defined as follows:\n\\[\n\\begin{aligned}\n\\mathcal{F} &:= \\sigma \\left(W +\\mathcal{K} + b \\right) \\\\\n\\mathcal{G}_\\theta &:=  \\mathcal{Q} \\circ \\mathcal{F}  \\circ \\mathcal{P}\n\\end{aligned}\n\\]\nwhere\n\n\\(\\mathcal{P} : \\mathbb{R^{in}} \\to \\mathbb{R^{hidden}}\\) is a lifting layer\n\\(\\mathcal{Q} : \\mathbb{R^{hidden}} \\to  \\mathbb{R^{out}}\\) is a projection layer\n\\(\\mathcal{F} \\colon \\mathbb{R^{hidden}} \\to  \\mathbb{R^{hidden}}\\) is the Neural Operator Layer with\n\n\\(\\mathcal{K}\\) is one of several Kernel Operators\n\\({W}\\) is a matrix (local linear operator); a “skip connection” inspired by ResNet\n\\(b\\) is a “function” bias",
    "crumbs": [
      "Models",
      "Fourier Neural Operator in 1D and 2D"
    ]
  },
  {
    "objectID": "models/fno.html#the-fourier-neural-operator",
    "href": "models/fno.html#the-fourier-neural-operator",
    "title": "Fourier Neural Operator in 1D and 2D",
    "section": "The “Fourier” Neural operator",
    "text": "The “Fourier” Neural operator\nIt takes the form of the linear transformation (convolution) of the Fourier coeffcients of the input function \\(v\\), and the kernel \\(R_\\phi\\). The result is then transformed back using the inverse Fourier transform.\n\\[\n\\mathcal{K} = \\mathcal{F}^{-1} (R_\\phi \\cdot \\mathcal{F} (v))\n\\]\n\nsource\n\nSpectralConv1d\n\n SpectralConv1d (in_channels:int, d_vars:int, n_modes:int,\n                 linear_conv:bool=True, parent:Union[flax.linen.module.Mod\n                 ule,flax.core.scope.Scope,flax.linen.module._Sentinel,Non\n                 eType]=&lt;flax.linen.module._Sentinel object at\n                 0x12ff8ca90&gt;, name:Optional[str]=None)\n\nSpectral Convolution Layer for 1D inputs. The n_modes parameter should be set to the length of the output for now, as it is not clear that the truncation is done correctly\nTest\n\nbatch_size = 1\nin_channels = 2\nd_vars = 2\nlength = 10  # length of the input signal, also can be seen as the grid size\nn_modes = length\n\nconv = SpectralConv1d(\n    in_channels=in_channels,\n    d_vars=d_vars,\n    n_modes=n_modes,\n    linear_conv=True,\n)\n\nrng = jax.random.PRNGKey(0)\nx = jax.random.uniform(rng, shape=(length, in_channels))\n\nparams = conv.init(jax.random.PRNGKey(0), x=x)\n\ny = conv.apply(params, x)\n\nassert y.shape == (length, d_vars)\n\n\nsource\n\n\nSpectralLayers1d\n\n SpectralLayers1d (n_channels:int, n_modes:int, linear_conv:bool=True,\n                   n_layers:int=4, activation:flax.linen.module.Module=&lt;ja\n                   x._src.custom_derivatives.custom_jvp object at\n                   0x12fe5bc70&gt;, parent:Union[flax.linen.module.Module,fla\n                   x.core.scope.Scope,flax.linen.module._Sentinel,NoneType\n                   ]=&lt;flax.linen.module._Sentinel object at 0x12ff8ca90&gt;,\n                   name:Optional[str]=None)\n\nStack of 1D Spectral Convolution Layers\n\nhidden_channels = 6\ngrid_size = 101\n\nspectral_layers = SpectralLayers1d(\n    n_channels=hidden_channels,\n    n_modes=grid_size,\n    linear_conv=True,\n    n_layers=4,\n    activation=nn.relu,\n)\nparams = spectral_layers.init(\n    jax.random.PRNGKey(0), jnp.ones((grid_size, hidden_channels))\n)\n\nx = jnp.ones((grid_size, hidden_channels))\ny = spectral_layers.apply(params, x)\nassert y.shape == x.shape",
    "crumbs": [
      "Models",
      "Fourier Neural Operator in 1D and 2D"
    ]
  },
  {
    "objectID": "models/fno.html#fourier-neural-operator-in-1-dimension",
    "href": "models/fno.html#fourier-neural-operator-in-1-dimension",
    "title": "Fourier Neural Operator in 1D and 2D",
    "section": "Fourier Neural Operator in 1 Dimension",
    "text": "Fourier Neural Operator in 1 Dimension\n\nsource\n\nFNO1D\n\n FNO1D (hidden_channels:int, n_modes:int, d_vars:int=1,\n        linear_conv:bool=True, n_layers:int=4, n_steps:int=None,\n        activation:flax.linen.module.Module=&lt;function gelu&gt;,\n        norm:str=('layer',), training:bool=True, parent:Union[flax.linen.m\n        odule.Module,flax.core.scope.Scope,flax.linen.module._Sentinel,Non\n        eType]=&lt;flax.linen.module._Sentinel object at 0x12ff8ca90&gt;,\n        name:Optional[str]=None)\n\nTest\n\ntime = 1\nhidden_channels = 6\ngrid_size = 101\nin_channels = 1\nd_vars = 5\nn_layers = 2\nbatch_size = 10\n\nbatch_fno = BatchedFNO1D(\n    hidden_channels=hidden_channels,\n    n_modes=grid_size,\n    d_vars=d_vars,\n    n_layers=n_layers,\n    n_steps=1,\n)\n\nrng = jax.random.PRNGKey(0)\nx = jnp.ones((batch_size, time, grid_size, in_channels))\n\nparams = batch_fno.init(jax.random.PRNGKey(0), x)\ny = batch_fno.apply(params, x)\n\n# assert y.shape == x.shape\nassert y.shape[-1] == d_vars\nassert y.shape == (batch_size, time, grid_size, d_vars)\ndisplay(jax.tree_util.tree_map(jnp.shape, params[\"params\"]))\n\n{'Dense_0': {'bias': (6,), 'kernel': (1, 6)},\n 'Dense_1': {'bias': (128,), 'kernel': (6, 128)},\n 'Dense_2': {'bias': (5,), 'kernel': (128, 5)},\n 'SpectralLayers1d_0': {'layers_conv_0': {'weight_imag': (6, 6, 101),\n   'weight_real': (6, 6, 101)},\n  'layers_conv_1': {'weight_imag': (6, 6, 101), 'weight_real': (6, 6, 101)},\n  'layers_w_0': {'bias': (6,), 'kernel': (1, 6, 6)},\n  'layers_w_1': {'bias': (6,), 'kernel': (1, 6, 6)}}}",
    "crumbs": [
      "Models",
      "Fourier Neural Operator in 1D and 2D"
    ]
  },
  {
    "objectID": "models/fno.html#fourier-neural-operator-in-2d",
    "href": "models/fno.html#fourier-neural-operator-in-2d",
    "title": "Fourier Neural Operator in 1D and 2D",
    "section": "Fourier Neural Operator in 2D",
    "text": "Fourier Neural Operator in 2D\n\nsource\n\nSpectralConv2d\n\n SpectralConv2d (in_channels:int, out_channels:int, n_modes1:int,\n                 n_modes2:int, parent:Union[flax.linen.module.Module,flax.\n                 core.scope.Scope,flax.linen.module._Sentinel,NoneType]=&lt;f\n                 lax.linen.module._Sentinel object at 0x12ff8ca90&gt;,\n                 name:Optional[str]=None)\n\n\nbatch_size = 1\nin_channels = 2\nout_channels = 2\nheight = 10\nwidth = 10\nn_modes = width // 2 + 1\n\nconv = SpectralConv2d(\n    in_channels=in_channels,\n    out_channels=out_channels,\n    n_modes1=n_modes,\n    n_modes2=n_modes,\n)\n\nrng = jax.random.PRNGKey(0)\nx = jax.random.uniform(rng, shape=(height, width, in_channels))\n\nparams = conv.init(\n    rng,\n    x=x\n)\ny = conv.apply(params, x)\n\nassert y.shape == (height, width, out_channels)\n\n\nsource\n\n\nFNO2D\n\n FNO2D (hidden_channels:int, n_modes:int, d_vars:int=1,\n        linear_conv:bool=True, n_layers:int=4, n_steps:int=None,\n        activation:flax.linen.module.Module=&lt;function gelu&gt;,\n        d_model:Tuple[int,int]=(41, 37), use_positions:bool=False,\n        norm:str='layer', training:bool=True, parent:Union[flax.linen.modu\n        le.Module,flax.core.scope.Scope,flax.linen.module._Sentinel,NoneTy\n        pe]=&lt;flax.linen.module._Sentinel object at 0x12ff8ca90&gt;,\n        name:Optional[str]=None)\n\nTest\n\nT_in = 1\nT_out = 9\nB, T, H, W, C = 10, T_in, 32, 32, 2\nhidden_channels = 10\nn_modes = 16\n\nrng = jax.random.PRNGKey(0)\nx = jax.random.uniform(rng, shape=(B, T, H, W, C))\n\nbatched_fno = BatchedFNO2D(\n    hidden_channels=hidden_channels,\n    d_vars=C,\n    n_steps=T_out,\n    n_modes=n_modes,\n    use_positions=False,\n    d_model=(H, W),\n)\nparams = batched_fno.init(rng, x)\n\ny = batched_fno.apply(params, x)\nprint(y.shape)\nassert y.shape == (B, T_out, H, W, C)\ndisplay(jax.tree_util.tree_map(jnp.shape, params[\"params\"]))\n\n(10, 9, 32, 32, 2)\n\n\n{'P': {'bias': (10,), 'kernel': (2, 10)},\n 'Q': {'layers_0': {'bias': (128,), 'kernel': (10, 128)},\n  'layers_2': {'bias': (18,), 'kernel': (128, 18)}},\n 'conv_layers_0': {'weight_1_imag': (10, 10, 16, 16),\n  'weight_1_real': (10, 10, 16, 16),\n  'weight_2_imag': (10, 10, 16, 16),\n  'weight_2_real': (10, 10, 16, 16)},\n 'conv_layers_1': {'weight_1_imag': (10, 10, 16, 16),\n  'weight_1_real': (10, 10, 16, 16),\n  'weight_2_imag': (10, 10, 16, 16),\n  'weight_2_real': (10, 10, 16, 16)},\n 'conv_layers_2': {'weight_1_imag': (10, 10, 16, 16),\n  'weight_1_real': (10, 10, 16, 16),\n  'weight_2_imag': (10, 10, 16, 16),\n  'weight_2_real': (10, 10, 16, 16)},\n 'conv_layers_3': {'weight_1_imag': (10, 10, 16, 16),\n  'weight_1_real': (10, 10, 16, 16),\n  'weight_2_imag': (10, 10, 16, 16),\n  'weight_2_real': (10, 10, 16, 16)},\n 'w_layers_0': {'bias': (10,), 'kernel': (1, 10, 10)},\n 'w_layers_1': {'bias': (10,), 'kernel': (1, 10, 10)},\n 'w_layers_2': {'bias': (10,), 'kernel': (1, 10, 10)},\n 'w_layers_3': {'bias': (10,), 'kernel': (1, 10, 10)}}",
    "crumbs": [
      "Models",
      "Fourier Neural Operator in 1D and 2D"
    ]
  },
  {
    "objectID": "models/fno_rnn.html",
    "href": "models/fno_rnn.html",
    "title": "FNO embedded in a recurrent neural network",
    "section": "",
    "text": "This notebook adapts the FNO for its use in a recurrent neural network. The idea is to use the FNO to learn the dynamics of a system, and then use the FNO as a layer in a recurrent neural network to learn the dynamics of the system over time. This is a reimplementation of https://github.com/julian-parker/DAFX22_FNO in Jax.\n\njax.config.update(\"jax_platform_name\", \"cpu\")\n\n\nsource\n\nFNORNN\n\n FNORNN (hidden_channels:int, grid_size:int, n_spectral_layers:int=4,\n         out_channels:int=1, length:int=None, activation:flax.linen.module\n         .Module=&lt;jax._src.custom_derivatives.custom_jvp object at\n         0x1257873d0&gt;, parent:Union[flax.linen.module.Module,flax.core.sco\n         pe.Scope,flax.linen.module._Sentinel,NoneType]=&lt;flax.linen.module\n         ._Sentinel object at 0x1345271f0&gt;, name:Optional[str]=None)\n\n\nsource\n\n\nFNOCell\n\n FNOCell (hidden_channels:int, grid_size:int, layers:int=4,\n          out_channels:int=1, activation:flax.linen.module.Module=&lt;jax._sr\n          c.custom_derivatives.custom_jvp object at 0x1257873d0&gt;, parent:U\n          nion[flax.linen.module.Module,flax.core.scope.Scope,flax.linen.m\n          odule._Sentinel,NoneType]=&lt;flax.linen.module._Sentinel object at\n          0x1345271f0&gt;, name:Optional[str]=None)\n\nParker’s ARMA without input\n\njax.config.update(\"jax_platform_name\", \"cpu\")\nhidden_channels = 6\ngrid_size = 101\ntime_steps = 10\n\nfno_rnn = FNORNN(\n    hidden_channels=hidden_channels,\n    grid_size=grid_size,\n    length=time_steps,\n)\n\nh0 = jnp.ones((grid_size, 1))\nx = jnp.ones((time_steps, grid_size, 1))\n\nparams = fno_rnn.init(jax.random.PRNGKey(0), h0, x)\ny = fno_rnn.apply(params, h0, x)\n\nassert y.shape == x.shape\n\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1705516485.179141  406942 tfrt_cpu_pjrt_client.cc:349] TfrtCpuClient created.\n\n\n\nsource\n\n\nBatchFNORNN\n\n BatchFNORNN (hidden_channels:int, grid_size:int, n_spectral_layers:int=4,\n              out_channels:int=1, length:int=None, activation:flax.linen.m\n              odule.Module=&lt;jax._src.custom_derivatives.custom_jvp object\n              at 0x1257873d0&gt;, parent:Union[flax.linen.module.Module,flax.\n              core.scope.Scope,flax.linen.module._Sentinel,NoneType]=&lt;flax\n              .linen.module._Sentinel object at 0x1345271f0&gt;,\n              name:Optional[str]=None)\n\n\nbatch_size = 3\ntime_steps = 10\nx = jnp.ones((batch_size, time_steps, grid_size, 1))\nh0 = jnp.ones((batch_size, grid_size, 1))\n\nbatch_fno_rnn = BatchFNORNN(\n    hidden_channels=hidden_channels,\n    grid_size=grid_size,\n    length=time_steps,\n)\n\nparams = batch_fno_rnn.init(\n    jax.random.PRNGKey(0), h0, x\n)  # Why does it need to be initialised with the number of timesteps?\ny = batch_fno_rnn.apply(params, h0, x)\n# Print the shape of the output\nprint(y.shape)\n\n(3, 10, 101, 1)",
    "crumbs": [
      "Models",
      "FNO embedded in a recurrent neural network"
    ]
  },
  {
    "objectID": "models/autoencoders.html",
    "href": "models/autoencoders.html",
    "title": "Autoencoder models",
    "section": "",
    "text": "FourierAutoencoder2D (dynamics_model:flax.linen.module.Module,\n                       d_vars:int, d_model:Tuple[int,int],\n                       norm:str='layer', training:bool=True,\n                       use_positions:bool=False, n_modes:int=20, parent:Un\n                       ion[flax.linen.module.Module,flax.core.scope.Scope,\n                       flax.linen.module._Sentinel,NoneType]=&lt;flax.linen.m\n                       odule._Sentinel object at 0x124a34f40&gt;,\n                       name:Optional[str]=None)\n\n\nd_hidden = 128\nB, T, H, W, C = 5, 16, 41, 37, 2\ndummy = jnp.zeros((B, T, H, W, C))\ntarget = jnp.zeros((B, T, H, W, C))\n\ndynamics_model = partial(LRUDynamics, d_hidden=(20*20*2), r_min=0.9, r_max=1.0, max_phase=jnp.pi * 2, clip_eigs=False)\n\nmodel = BatchedFourierAutoencoder2D(\n    dynamics_model=dynamics_model,\n    d_vars=C,\n    d_model=(H, W),\n    norm=\"layer\",\n    training=True,\n    n_modes=20\n)\n\nvars = model.init(jax.random.PRNGKey(0), dummy)\nout = model.apply(vars, dummy)\n\nassert out.shape == (B, T, H, W, C)\n\n\n\n\n\n\n DenseKoopmanAutoencoder2D (encoder_model:flax.linen.module.Module,\n                            decoder_model:flax.linen.module.Module,\n                            dynamics_model:flax.linen.module.Module,\n                            d_vars:int, d_model:Tuple[int,int],\n                            n_steps:int, norm:str='layer',\n                            training:bool=True, use_positions:bool=False, \n                            parent:Union[flax.linen.module.Module,flax.cor\n                            e.scope.Scope,flax.linen.module._Sentinel,None\n                            Type]=&lt;flax.linen.module._Sentinel object at\n                            0x124a34f40&gt;, name:Optional[str]=None)\n\nKoopman Dense Autoencoder\n\nn_steps = 16\nd_hidden = 128\nB, T, H, W, C = 5, n_steps, 41, 37, 3\ndummy = jnp.zeros((B, T, H, W, C))\ntarget = jnp.zeros((B, T, H, W, C))\n\nencoder_model = partial(nn.Dense, features=d_hidden*2)\ndecoder_model = partial(nn.Dense, features=H * W * C)\ndynamics_model = partial(LRUDynamics, d_hidden=d_hidden, r_min=0.9, r_max=1.0, max_phase=jnp.pi * 2, clip_eigs=False)\n\nmodel = BatchedDenseKoopmanAutoencoder2D(\n    encoder_model=encoder_model,\n    decoder_model=decoder_model,\n    dynamics_model=dynamics_model,\n    n_steps=n_steps,\n    d_vars=C,\n    d_model=(H, W),\n    norm=\"layer\",\n    training=True\n)\n\nvars = model.init(jax.random.PRNGKey(0), dummy)\nout = model.apply(vars, dummy)\n\nassert out.shape == (B, T, H, W, C)\n\n\nencoded = model.apply(vars, dummy, method=\"encode\")\ndecoded = model.apply(vars, encoded, method=\"decode\")\n\nenc_sequence = model.apply(vars, target, method=\"encode\")\ndec_sequence = model.apply(vars, enc_sequence, method=\"decode\")\n\n\n\n\n\n\n KoopmanAutoencoder2D (encoder_model:physmodjax.models.conv.ConvEncoder,\n                       decoder_model:physmodjax.models.conv.ConvDecoder,\n                       dynamics_model:physmodjax.models.ssm.LRUDynamics,\n                       d_latent_channels:int,\n                       d_latent_dims:Tuple[int,int], n_steps:int,\n                       norm:str='layer', training:bool=True, parent:Union[\n                       flax.linen.module.Module,flax.core.scope.Scope,flax\n                       .linen.module._Sentinel,NoneType]=&lt;flax.linen.modul\n                       e._Sentinel object at 0x124a34f40&gt;,\n                       name:Optional[str]=None)\n\nKoopman Autoencoder\n\nn_steps = 16\nd_hidden = 128\nB, T, H, W, C = 5, n_steps, 40, 40, 3\ndummy = jnp.zeros((B, T, H, W, C))\ntarget = jnp.zeros((B, T, H, W, C))\n\nencoder_model = partial(ConvEncoder, block_size=(8, 16, 32))\ndecoder_model = partial(ConvDecoder, block_size=(8, 16, 32))\ndynamics_model = partial(LRUDynamics, d_hidden=16 * 5 * 5, r_min=0.9, r_max=1.0, max_phase=jnp.pi * 2, clip_eigs=False)\n\nmodel = BatchedKoopmanAutoencoder2D(\n    encoder_model=encoder_model,\n    decoder_model=decoder_model,\n    dynamics_model=dynamics_model,\n    d_latent_channels=32,\n    d_latent_dims=(5, 5),\n    n_steps=16,\n    norm=\"layer\",\n    training=True\n)\n\nvars = model.init(jax.random.PRNGKey(0), dummy)\nout = model.apply(vars, dummy)\nassert out.shape == (B, T, H, W, C)\n\n\nencoded = model.apply(vars, dummy, method=\"encode\")\ndecoded = model.apply(vars, encoded, method=\"decode\")\n\nenc_sequence = model.apply(vars, target, method=\"encode\")\ndec_sequence = model.apply(vars, enc_sequence, method=\"decode\")",
    "crumbs": [
      "Models",
      "Autoencoder models"
    ]
  },
  {
    "objectID": "models/autoencoders.html#d-convolutional-autoencoder-with-linear-dynamics",
    "href": "models/autoencoders.html#d-convolutional-autoencoder-with-linear-dynamics",
    "title": "Autoencoder models",
    "section": "",
    "text": "FourierAutoencoder2D (dynamics_model:flax.linen.module.Module,\n                       d_vars:int, d_model:Tuple[int,int],\n                       norm:str='layer', training:bool=True,\n                       use_positions:bool=False, n_modes:int=20, parent:Un\n                       ion[flax.linen.module.Module,flax.core.scope.Scope,\n                       flax.linen.module._Sentinel,NoneType]=&lt;flax.linen.m\n                       odule._Sentinel object at 0x124a34f40&gt;,\n                       name:Optional[str]=None)\n\n\nd_hidden = 128\nB, T, H, W, C = 5, 16, 41, 37, 2\ndummy = jnp.zeros((B, T, H, W, C))\ntarget = jnp.zeros((B, T, H, W, C))\n\ndynamics_model = partial(LRUDynamics, d_hidden=(20*20*2), r_min=0.9, r_max=1.0, max_phase=jnp.pi * 2, clip_eigs=False)\n\nmodel = BatchedFourierAutoencoder2D(\n    dynamics_model=dynamics_model,\n    d_vars=C,\n    d_model=(H, W),\n    norm=\"layer\",\n    training=True,\n    n_modes=20\n)\n\nvars = model.init(jax.random.PRNGKey(0), dummy)\nout = model.apply(vars, dummy)\n\nassert out.shape == (B, T, H, W, C)\n\n\n\n\n\n\n DenseKoopmanAutoencoder2D (encoder_model:flax.linen.module.Module,\n                            decoder_model:flax.linen.module.Module,\n                            dynamics_model:flax.linen.module.Module,\n                            d_vars:int, d_model:Tuple[int,int],\n                            n_steps:int, norm:str='layer',\n                            training:bool=True, use_positions:bool=False, \n                            parent:Union[flax.linen.module.Module,flax.cor\n                            e.scope.Scope,flax.linen.module._Sentinel,None\n                            Type]=&lt;flax.linen.module._Sentinel object at\n                            0x124a34f40&gt;, name:Optional[str]=None)\n\nKoopman Dense Autoencoder\n\nn_steps = 16\nd_hidden = 128\nB, T, H, W, C = 5, n_steps, 41, 37, 3\ndummy = jnp.zeros((B, T, H, W, C))\ntarget = jnp.zeros((B, T, H, W, C))\n\nencoder_model = partial(nn.Dense, features=d_hidden*2)\ndecoder_model = partial(nn.Dense, features=H * W * C)\ndynamics_model = partial(LRUDynamics, d_hidden=d_hidden, r_min=0.9, r_max=1.0, max_phase=jnp.pi * 2, clip_eigs=False)\n\nmodel = BatchedDenseKoopmanAutoencoder2D(\n    encoder_model=encoder_model,\n    decoder_model=decoder_model,\n    dynamics_model=dynamics_model,\n    n_steps=n_steps,\n    d_vars=C,\n    d_model=(H, W),\n    norm=\"layer\",\n    training=True\n)\n\nvars = model.init(jax.random.PRNGKey(0), dummy)\nout = model.apply(vars, dummy)\n\nassert out.shape == (B, T, H, W, C)\n\n\nencoded = model.apply(vars, dummy, method=\"encode\")\ndecoded = model.apply(vars, encoded, method=\"decode\")\n\nenc_sequence = model.apply(vars, target, method=\"encode\")\ndec_sequence = model.apply(vars, enc_sequence, method=\"decode\")\n\n\n\n\n\n\n KoopmanAutoencoder2D (encoder_model:physmodjax.models.conv.ConvEncoder,\n                       decoder_model:physmodjax.models.conv.ConvDecoder,\n                       dynamics_model:physmodjax.models.ssm.LRUDynamics,\n                       d_latent_channels:int,\n                       d_latent_dims:Tuple[int,int], n_steps:int,\n                       norm:str='layer', training:bool=True, parent:Union[\n                       flax.linen.module.Module,flax.core.scope.Scope,flax\n                       .linen.module._Sentinel,NoneType]=&lt;flax.linen.modul\n                       e._Sentinel object at 0x124a34f40&gt;,\n                       name:Optional[str]=None)\n\nKoopman Autoencoder\n\nn_steps = 16\nd_hidden = 128\nB, T, H, W, C = 5, n_steps, 40, 40, 3\ndummy = jnp.zeros((B, T, H, W, C))\ntarget = jnp.zeros((B, T, H, W, C))\n\nencoder_model = partial(ConvEncoder, block_size=(8, 16, 32))\ndecoder_model = partial(ConvDecoder, block_size=(8, 16, 32))\ndynamics_model = partial(LRUDynamics, d_hidden=16 * 5 * 5, r_min=0.9, r_max=1.0, max_phase=jnp.pi * 2, clip_eigs=False)\n\nmodel = BatchedKoopmanAutoencoder2D(\n    encoder_model=encoder_model,\n    decoder_model=decoder_model,\n    dynamics_model=dynamics_model,\n    d_latent_channels=32,\n    d_latent_dims=(5, 5),\n    n_steps=16,\n    norm=\"layer\",\n    training=True\n)\n\nvars = model.init(jax.random.PRNGKey(0), dummy)\nout = model.apply(vars, dummy)\nassert out.shape == (B, T, H, W, C)\n\n\nencoded = model.apply(vars, dummy, method=\"encode\")\ndecoded = model.apply(vars, encoded, method=\"decode\")\n\nenc_sequence = model.apply(vars, target, method=\"encode\")\ndec_sequence = model.apply(vars, enc_sequence, method=\"decode\")",
    "crumbs": [
      "Models",
      "Autoencoder models"
    ]
  },
  {
    "objectID": "models/autoencoders.html#koopman-autoencoder-1d",
    "href": "models/autoencoders.html#koopman-autoencoder-1d",
    "title": "Autoencoder models",
    "section": "Koopman Autoencoder 1D",
    "text": "Koopman Autoencoder 1D\n\n\nKoopmanAutoencoder1D\n\n KoopmanAutoencoder1D (encoder_model:flax.linen.module.Module,\n                       decoder_model:flax.linen.module.Module,\n                       dynamics_model:flax.linen.module.Module,\n                       d_vars:int, d_model:int, n_steps:int,\n                       norm:str='layer', training:bool=True, parent:Union[\n                       flax.linen.module.Module,flax.core.scope.Scope,flax\n                       .linen.module._Sentinel,NoneType]=&lt;flax.linen.modul\n                       e._Sentinel object at 0x124a34f40&gt;,\n                       name:Optional[str]=None)\n\nKoopman Autoencoder\n\nB, T, W, C = 5, 16, 101, 3\nd_hidden = 128\ndummy = jnp.zeros((B, T, W, C))\ntarget = jnp.zeros((B, T, W, C))\n\nencoder_model = partial(\n    nn.Dense,\n    features=d_hidden * 2,\n    kernel_init=nn.initializers.orthogonal(),\n    use_bias=False,\n)\ndecoder_model = partial(\n    nn.Dense,\n    features=W * C,\n    kernel_init=nn.initializers.orthogonal(),\n    use_bias=False,\n)\ndynamics_model = partial(\n    LRUDynamicsVarying,\n    d_hidden=d_hidden,\n    r_min=0.9,\n    r_max=1.0,\n    max_phase=jnp.pi * 2,\n    model=nn.Dense(features=d_hidden * 2, kernel_init=nn.initializers.orthogonal()),\n    clip_eigs=False,\n)\n\nmodel = BatchedKoopmanAutoencoder1D(\n    encoder_model=encoder_model,\n    decoder_model=decoder_model,\n    dynamics_model=dynamics_model,\n    d_vars=C,\n    d_model=W,\n    n_steps=T,\n    norm=\"layer\",\n    training=True,\n)\n\nvars = model.init(jax.random.PRNGKey(0), dummy)\nout = model.apply(vars, dummy)\n\nassert out.shape == (B, T, W, C)\n\nx (303,)\nx (303,)\n\n\n\nprint(dummy.shape)\nencoded = model.apply(vars, dummy, method=\"encode\")\nprint(\"encoded\", encoded.shape)\ndecoded = model.apply(vars, encoded, method=\"decode\")\nassert decoded.shape == dummy.shape\n\nenc_sequence = model.apply(vars, target, method=\"encode\")\ndec_sequence = model.apply(vars, enc_sequence, method=\"decode\")\n\nassert dec_sequence.shape == (B, T, W, C)\n\n(5, 16, 101, 3)\nx (16, 303)\nencoded (5, 16, 256)\nx (16, 303)\n\n\n\n\n\nKoopmanAutoencoder1DReal\n\n KoopmanAutoencoder1DReal (encoder_model:flax.linen.module.Module,\n                           decoder_model:flax.linen.module.Module,\n                           dynamics_model:flax.linen.module.Module,\n                           d_vars:int, d_model:int, n_steps:int,\n                           norm:str='layer', training:bool=True, parent:Un\n                           ion[flax.linen.module.Module,flax.core.scope.Sc\n                           ope,flax.linen.module._Sentinel,NoneType]=&lt;flax\n                           .linen.module._Sentinel object at 0x124a34f40&gt;,\n                           name:Optional[str]=None)\n\nKoopman Autoencoder but with real encoding and decoding\n\nB, T, W, C = 5, 16, 101, 3\nd_hidden = 128\ndummy = jnp.zeros((B, T, W, C))\ntarget = jnp.zeros((B, T, W, C))\n\nencoder_model = partial(\n    nn.Dense,\n    features=d_hidden,\n    kernel_init=nn.initializers.orthogonal(),\n    use_bias=False,\n)\ndecoder_model = partial(\n    nn.Dense,\n    features=W * C,\n    kernel_init=nn.initializers.orthogonal(),\n    use_bias=False,\n)\ndynamics_model = partial(\n    LRUDynamicsVarying,\n    d_hidden=d_hidden,\n    r_min=0.9,\n    r_max=1.0,\n    max_phase=jnp.pi * 2,\n    model=nn.Dense(\n        features=d_hidden * 2,\n        kernel_init=nn.initializers.orthogonal(),\n    ),\n    clip_eigs=False,\n)\n\nmodel = BatchedKoopmanAutoencoder1DReal(\n    encoder_model=encoder_model,\n    decoder_model=decoder_model,\n    dynamics_model=dynamics_model,\n    d_vars=C,\n    d_model=W,\n    n_steps=T,\n    norm=\"layer\",\n    training=True,\n)\n\nvars = model.init(jax.random.PRNGKey(0), dummy)\nout = model.apply(vars, dummy)\n\nassert out.shape == (B, T, W, C)",
    "crumbs": [
      "Models",
      "Autoencoder models"
    ]
  },
  {
    "objectID": "models/ssm.html",
    "href": "models/ssm.html",
    "title": "SSM Models",
    "section": "",
    "text": "adapted from https://github.com/lindermanlab/S5\n\nsource\n\n\n\n init_CV (init_fun, rng, shape, V)\n\nInitialize C_tilde=CV. First sample C. Then compute CV. Note we will parameterize this with two different matrices for complex numbers. Args: init_fun: the initialization function to use, e.g. lecun_normal() rng: jax random key to be used with init function. shape (tuple): desired shape (H,P) V: (complex64) the eigenvectors used for initialization Returns: C_tilde (complex64) of shape (H,P,2)\n\nsource\n\n\n\n\n trunc_standard_normal (key, shape)\n\n*Sample C with a truncated normal distribution with standard deviation 1. Args: key: jax random key shape (tuple): desired shape, of length 3, (H,P,_) Returns: sampled C matrix (float32) of shape (H,P,2) (for complex parameterization)*\n\nsource\n\n\n\n\n init_VinvB (init_fun, rng, shape, Vinv)\n\nInitialize B_tilde=V^{-1}B. First samples B. Then compute V^{-1}B. Note we will parameterize this with two different matrices for complex numbers. Args: init_fun: the initialization function to use, e.g. lecun_normal() rng: jax random key to be used with init function. shape (tuple): desired shape (P,H) Vinv: (complex64) the inverse eigenvectors used for initialization Returns: B_tilde (complex64) of shape (P,H,2)\n\nsource\n\n\n\n\n init_log_steps (key, input)\n\nInitialize an array of learnable timescale parameters Args: key: jax random key input: tuple containing the array shape H and dt_min and dt_max Returns: initialized array of timescales (float32): (H,)\n\nsource\n\n\n\n\n log_step_initializer (dt_min=0.001, dt_max=0.1)\n\nInitialize the learnable timescale Delta by sampling uniformly between dt_min and dt_max. Args: dt_min (float32): minimum value dt_max (float32): maximum value Returns: init function\n\nsource\n\n\n\n\n make_DPLR_HiPPO (N)\n\n*Makes components needed for DPLR representation of HiPPO-LegS From https://github.com/srush/annotated-s4/blob/main/s4/s4.py Note, we will only use the diagonal part Args: N:\nReturns: eigenvalues Lambda, low-rank term P, conjugated HiPPO input matrix B, eigenvectors V, HiPPO B pre-conjugation*\n\nsource\n\n\n\n\n make_NPLR_HiPPO (N)\n\n*Makes components needed for NPLR representation of HiPPO-LegS From https://github.com/srush/annotated-s4/blob/main/s4/s4.py Args: N (int32): state size\nReturns: N x N HiPPO LegS matrix, low-rank factor P, HiPPO input matrix B*\n\nsource\n\n\n\n\n make_HiPPO (N)\n\nCreate a HiPPO-LegS matrix. From https://github.com/srush/annotated-s4/blob/main/s4/s4.py Args: N (int32): state size Returns: N x N HiPPO LegS matrix\n\nsource\n\n\n\n\n apply_ssm (Lambda_bar, B_bar, C_tilde, input_sequence, conj_sym,\n            bidirectional)\n\nCompute the LxH output of discretized SSM given an LxH input. Args: Lambda_bar (complex64): discretized diagonal state matrix (P,) B_bar (complex64): discretized input matrix (P, H) C_tilde (complex64): output matrix (H, P) input_sequence (float32): input sequence of features (L, H) conj_sym (bool): whether conjugate symmetry is enforced bidirectional (bool): whether bidirectional setup is used, Note for this case C_tilde will have 2P cols Returns: ys (float32): the SSM outputs (S5 layer preactivations) (L, H)\n\nsource\n\n\n\n\n apply_dynamics (x0, steps, Lambda_bar, B_bar, C_tilde, conj_sym,\n                 bidirectional)\n\n\nsource\n\n\n\n\n binary_operator (q_i, q_j)\n\nBinary operator for parallel scan of linear recurrence. Assumes a diagonal matrix A. Args: q_i: tuple containing A_i and Bu_i at position i (P,), (P,) q_j: tuple containing A_j and Bu_j at position j (P,), (P,) Returns: new element ( A_out, Bu_out )\n\nsource\n\n\n\n\n discretize_zoh (Lambda, B_tilde, Delta)\n\nDiscretize a diagonalized, continuous-time linear SSM using zero-order hold method. Args: Lambda (complex64): diagonal state matrix (P,) B_tilde (complex64): input matrix (P, H) Delta (float32): discretization step sizes (P,) Returns: discretized Lambda_bar (complex64), B_bar (complex64) (P,), (P,H)\n\nsource\n\n\n\n\n discretize_bilinear (Lambda, B_tilde, Delta)\n\nDiscretize a diagonalized, continuous-time linear SSM using bilinear transform method. Args: Lambda (complex64): diagonal state matrix (P,) B_tilde (complex64): input matrix (P, H) Delta (float32): discretization step sizes (P,) Returns: discretized Lambda_bar (complex64), B_bar (complex64) (P,), (P,H)\n\nsource\n\n\n\n\n S5SSM (d_model:int, d_hidden:int, C_init:str='lecun_normal',\n        discretization:str='zoh', dt_min:float=0.0001, dt_max:float=0.1,\n        conj_sym:bool=True, clip_eigs:bool=False,\n        bidirectional:bool=False, step_rescale:float=1.0, blocks:int=16,\n        n_steps:Optional[int]=None, parent:Union[flax.linen.module.Module,\n        flax.core.scope.Scope,flax.linen.module._Sentinel,NoneType]=&lt;flax.\n        linen.module._Sentinel object at 0x12ff8ca90&gt;,\n        name:Optional[str]=None)",
    "crumbs": [
      "Models",
      "SSM Models"
    ]
  },
  {
    "objectID": "models/ssm.html#s5-model",
    "href": "models/ssm.html#s5-model",
    "title": "SSM Models",
    "section": "",
    "text": "adapted from https://github.com/lindermanlab/S5\n\nsource\n\n\n\n init_CV (init_fun, rng, shape, V)\n\nInitialize C_tilde=CV. First sample C. Then compute CV. Note we will parameterize this with two different matrices for complex numbers. Args: init_fun: the initialization function to use, e.g. lecun_normal() rng: jax random key to be used with init function. shape (tuple): desired shape (H,P) V: (complex64) the eigenvectors used for initialization Returns: C_tilde (complex64) of shape (H,P,2)\n\nsource\n\n\n\n\n trunc_standard_normal (key, shape)\n\n*Sample C with a truncated normal distribution with standard deviation 1. Args: key: jax random key shape (tuple): desired shape, of length 3, (H,P,_) Returns: sampled C matrix (float32) of shape (H,P,2) (for complex parameterization)*\n\nsource\n\n\n\n\n init_VinvB (init_fun, rng, shape, Vinv)\n\nInitialize B_tilde=V^{-1}B. First samples B. Then compute V^{-1}B. Note we will parameterize this with two different matrices for complex numbers. Args: init_fun: the initialization function to use, e.g. lecun_normal() rng: jax random key to be used with init function. shape (tuple): desired shape (P,H) Vinv: (complex64) the inverse eigenvectors used for initialization Returns: B_tilde (complex64) of shape (P,H,2)\n\nsource\n\n\n\n\n init_log_steps (key, input)\n\nInitialize an array of learnable timescale parameters Args: key: jax random key input: tuple containing the array shape H and dt_min and dt_max Returns: initialized array of timescales (float32): (H,)\n\nsource\n\n\n\n\n log_step_initializer (dt_min=0.001, dt_max=0.1)\n\nInitialize the learnable timescale Delta by sampling uniformly between dt_min and dt_max. Args: dt_min (float32): minimum value dt_max (float32): maximum value Returns: init function\n\nsource\n\n\n\n\n make_DPLR_HiPPO (N)\n\n*Makes components needed for DPLR representation of HiPPO-LegS From https://github.com/srush/annotated-s4/blob/main/s4/s4.py Note, we will only use the diagonal part Args: N:\nReturns: eigenvalues Lambda, low-rank term P, conjugated HiPPO input matrix B, eigenvectors V, HiPPO B pre-conjugation*\n\nsource\n\n\n\n\n make_NPLR_HiPPO (N)\n\n*Makes components needed for NPLR representation of HiPPO-LegS From https://github.com/srush/annotated-s4/blob/main/s4/s4.py Args: N (int32): state size\nReturns: N x N HiPPO LegS matrix, low-rank factor P, HiPPO input matrix B*\n\nsource\n\n\n\n\n make_HiPPO (N)\n\nCreate a HiPPO-LegS matrix. From https://github.com/srush/annotated-s4/blob/main/s4/s4.py Args: N (int32): state size Returns: N x N HiPPO LegS matrix\n\nsource\n\n\n\n\n apply_ssm (Lambda_bar, B_bar, C_tilde, input_sequence, conj_sym,\n            bidirectional)\n\nCompute the LxH output of discretized SSM given an LxH input. Args: Lambda_bar (complex64): discretized diagonal state matrix (P,) B_bar (complex64): discretized input matrix (P, H) C_tilde (complex64): output matrix (H, P) input_sequence (float32): input sequence of features (L, H) conj_sym (bool): whether conjugate symmetry is enforced bidirectional (bool): whether bidirectional setup is used, Note for this case C_tilde will have 2P cols Returns: ys (float32): the SSM outputs (S5 layer preactivations) (L, H)\n\nsource\n\n\n\n\n apply_dynamics (x0, steps, Lambda_bar, B_bar, C_tilde, conj_sym,\n                 bidirectional)\n\n\nsource\n\n\n\n\n binary_operator (q_i, q_j)\n\nBinary operator for parallel scan of linear recurrence. Assumes a diagonal matrix A. Args: q_i: tuple containing A_i and Bu_i at position i (P,), (P,) q_j: tuple containing A_j and Bu_j at position j (P,), (P,) Returns: new element ( A_out, Bu_out )\n\nsource\n\n\n\n\n discretize_zoh (Lambda, B_tilde, Delta)\n\nDiscretize a diagonalized, continuous-time linear SSM using zero-order hold method. Args: Lambda (complex64): diagonal state matrix (P,) B_tilde (complex64): input matrix (P, H) Delta (float32): discretization step sizes (P,) Returns: discretized Lambda_bar (complex64), B_bar (complex64) (P,), (P,H)\n\nsource\n\n\n\n\n discretize_bilinear (Lambda, B_tilde, Delta)\n\nDiscretize a diagonalized, continuous-time linear SSM using bilinear transform method. Args: Lambda (complex64): diagonal state matrix (P,) B_tilde (complex64): input matrix (P, H) Delta (float32): discretization step sizes (P,) Returns: discretized Lambda_bar (complex64), B_bar (complex64) (P,), (P,H)\n\nsource\n\n\n\n\n S5SSM (d_model:int, d_hidden:int, C_init:str='lecun_normal',\n        discretization:str='zoh', dt_min:float=0.0001, dt_max:float=0.1,\n        conj_sym:bool=True, clip_eigs:bool=False,\n        bidirectional:bool=False, step_rescale:float=1.0, blocks:int=16,\n        n_steps:Optional[int]=None, parent:Union[flax.linen.module.Module,\n        flax.core.scope.Scope,flax.linen.module._Sentinel,NoneType]=&lt;flax.\n        linen.module._Sentinel object at 0x12ff8ca90&gt;,\n        name:Optional[str]=None)",
    "crumbs": [
      "Models",
      "SSM Models"
    ]
  },
  {
    "objectID": "models/ssm.html#lru-model",
    "href": "models/ssm.html#lru-model",
    "title": "SSM Models",
    "section": "LRU Model",
    "text": "LRU Model\nadapted from https://github.com/NicolasZucchet/minimal-LRU\n\nsource\n\ngamma_log_init\n\n gamma_log_init (key, lamb)\n\n\nsource\n\n\ntheta_init\n\n theta_init (key, shape, max_phase, dtype=&lt;class 'jax.numpy.float32'&gt;)\n\n\nsource\n\n\nnu_init\n\n nu_init (key, shape, r_min, r_max, dtype=&lt;class 'jax.numpy.float32'&gt;)\n\n\nsource\n\n\nmatrix_init\n\n matrix_init (key, shape, dtype=&lt;class 'jax.numpy.float32'&gt;,\n              normalization=1)\n\n\nsource\n\n\nLRUDynamics\n\n LRUDynamics (d_hidden:int, r_min:float, r_max:float, max_phase:float,\n              clip_eigs:bool, parent:Union[flax.linen.module.Module,flax.c\n              ore.scope.Scope,flax.linen.module._Sentinel,NoneType]=&lt;flax.\n              linen.module._Sentinel object at 0x12ff8ca90&gt;,\n              name:Optional[str]=None)\n\nThis class implements only the dynamics of the LRU model. x_{k+1} = A x_k\n\nd_hidden = 64\nsteps = 50\ndyn = LRUDynamics(d_hidden=d_hidden, r_min=0.99, r_max=1.0, max_phase=jnp.pi * 2, clip_eigs=False)\nvars = dyn.init(jax.random.PRNGKey(0), jnp.ones((d_hidden)), 50)\nout = dyn.apply(vars, jnp.ones((1, d_hidden)), 50)\n\nassert out.shape == (steps, d_hidden)\n\n\nsource\n\n\napply_lru_dynamics_from_ic\n\n apply_lru_dynamics_from_ic (ic:jax.Array, n_steps:int,\n                             discrete_lambda:jax.Array, B_norm:jax.Array,\n                             C:jax.Array)\n\n\n\n\n\nType\nDetails\n\n\n\n\nic\nArray\n(1, d_model)\n\n\nn_steps\nint\n\n\n\ndiscrete_lambda\nArray\n(d_hidden,)\n\n\nB_norm\nArray\n(d_hidden, d_model)\n\n\nC\nArray\n(d_model, d_hidden)\n\n\n\n\nsource\n\n\napply_lru_dynamics\n\n apply_lru_dynamics (inputs:jax.Array, discrete_lambda:jax.Array,\n                     B_norm:jax.Array, C:jax.Array, D:jax.Array)\n\n\n\n\n\nType\nDetails\n\n\n\n\ninputs\nArray\n(time, d_model)\n\n\ndiscrete_lambda\nArray\n(d_hidden,)\n\n\nB_norm\nArray\n(d_hidden, d_model)\n\n\nC\nArray\n(d_model, d_hidden)\n\n\nD\nArray\n(d_model,)\n\n\n\n\nsource\n\n\nLRU\n\n LRU (d_hidden:int, d_model:int, r_min:float=0.0, r_max:float=1.0,\n      max_phase:float=6.28, n_steps:Optional[int]=None, parent:Union[flax.\n      linen.module.Module,flax.core.scope.Scope,flax.linen.module._Sentine\n      l,NoneType]=&lt;flax.linen.module._Sentinel object at 0x12ff8ca90&gt;,\n      name:Optional[str]=None)\n\nLRU module in charge of the recurrent processing. Implementation following the one of Orvieto et al. 2023.",
    "crumbs": [
      "Models",
      "SSM Models"
    ]
  },
  {
    "objectID": "models/ssm.html#deep-stacked-and-batched-versions",
    "href": "models/ssm.html#deep-stacked-and-batched-versions",
    "title": "SSM Models",
    "section": "Deep (Stacked) and Batched versions",
    "text": "Deep (Stacked) and Batched versions\n\nsource\n\nSequenceLayer\n\n SequenceLayer (ssm:flax.linen.module.Module, d_model:int,\n                dropout:float=0.0, norm:str='layer', training:bool=True,\n                activation:str='half_glu1', prenorm:bool=True, parent:Unio\n                n[flax.linen.module.Module,flax.core.scope.Scope,flax.line\n                n.module._Sentinel,NoneType]=&lt;flax.linen.module._Sentinel\n                object at 0x12ff8ca90&gt;, name:Optional[str]=None)\n\nSingle layer, with one SSM module, GLU, dropout and batch/layer norm\n\nsource\n\n\nStackedSSM\n\n StackedSSM (ssm:flax.linen.module.Module, d_model:int, d_vars:int,\n             n_layers:int, ssm_first_layer:flax.linen.module.Module=None,\n             n_steps:Optional[int]=None, dropout:float=0.0,\n             training:bool=True, norm:str='layer',\n             activation:str='half_glu1', prenorm:bool=True, parent:Union[f\n             lax.linen.module.Module,flax.core.scope.Scope,flax.linen.modu\n             le._Sentinel,NoneType]=&lt;flax.linen.module._Sentinel object at\n             0x12ff8ca90&gt;, name:Optional[str]=None)\n\n\nB, T, W, C = 10, 50, 20, 3\nd_hidden = 64\ndeep_ssm = BatchStackedSSMModel(\n    ssm_first_layer=partial(S5SSM, d_hidden=d_hidden, n_steps=50),\n    ssm=partial(S5SSM, d_hidden=d_hidden),\n    d_model=W,\n    d_vars=C,\n    n_layers=2,\n)\nx = jnp.empty((B, T, W, C))\nvariables = deep_ssm.init(jax.random.PRNGKey(65), x)\nout = deep_ssm.apply(variables, x)\n\nassert out.shape == (B, T, W, C)\n\n\ndeep_ssm = BatchStackedSSMModel(\n    ssm_first_layer=partial(LRU, d_hidden=d_hidden, n_steps=50),\n    ssm=partial(LRU, d_hidden=d_hidden),\n    d_model=W,\n    d_vars=C,\n    n_layers=2,\n)\nx = jnp.empty((B, T, W, C))\nvariables = deep_ssm.init(jax.random.PRNGKey(65), x)\nout = deep_ssm.apply(variables, x)\n\nassert out.shape == (B, T, W, C)\n\n\nsource\n\n\nStackedSSM2D\n\n StackedSSM2D (ssm:flax.linen.module.Module, d_model:Tuple[int,int],\n               d_vars:int, n_layers:int,\n               ssm_first_layer:flax.linen.module.Module=None,\n               n_steps:Optional[int]=None, dropout:float=0.0,\n               training:bool=True, norm:str='layer',\n               activation:str='half_glu1', prenorm:bool=True, parent:Union\n               [flax.linen.module.Module,flax.core.scope.Scope,flax.linen.\n               module._Sentinel,NoneType]=&lt;flax.linen.module._Sentinel\n               object at 0x12ff8ca90&gt;, name:Optional[str]=None)\n\n\nB, T, H, W, C = 10, 50, 20, 20, 3\ndeep_ssm = BatchStackedSSM2DModel(\n    ssm_first_layer=partial(LRU, d_hidden=d_hidden, n_steps=T),\n    ssm=partial(LRU, d_hidden=d_hidden),\n    d_model=(H, W),\n    d_vars=C,\n    n_layers=2,\n)\n\nx = jnp.empty((B, T, H, W, C))\nvariables = deep_ssm.init(jax.random.PRNGKey(65), x)\nout = deep_ssm.apply(variables, x)\n\nassert out.shape == (B, T, H, W, C)\n\n\nB, T, H, W, C = 10, 50, 20, 20, 3\ndeep_ssm = BatchStackedSSM2DModel(\n    ssm_first_layer=partial(S5SSM, d_hidden=d_hidden, n_steps=T),\n    ssm=partial(S5SSM, d_hidden=d_hidden),\n    d_model=(H, W),\n    d_vars=C,\n    n_layers=2,\n)\n\nx = jnp.empty((B, T, H, W, C))\nvariables = deep_ssm.init(jax.random.PRNGKey(65), x)\nout = deep_ssm.apply(variables, x)\n\nassert out.shape == (B, T, H, W, C)",
    "crumbs": [
      "Models",
      "SSM Models"
    ]
  },
  {
    "objectID": "utils/ftm.html",
    "href": "utils/ftm.html",
    "title": "Funtional Transformation Method Utilities",
    "section": "",
    "text": "This notebook contains a set of utility functions for the functional transformation method.\nsource",
    "crumbs": [
      "Utils",
      "Funtional Transformation Method Utilities"
    ]
  },
  {
    "objectID": "utils/ftm.html#parameters",
    "href": "utils/ftm.html#parameters",
    "title": "Funtional Transformation Method Utilities",
    "section": "Parameters:",
    "text": "Parameters:\nn_max_modes_x: int The number of modes in the x direction. n_max_modes_y: int The number of modes in the y direction. l1: float The width of the plate. l2: float The height of the plate.",
    "crumbs": [
      "Utils",
      "Funtional Transformation Method Utilities"
    ]
  },
  {
    "objectID": "utils/ftm.html#returns",
    "href": "utils/ftm.html#returns",
    "title": "Funtional Transformation Method Utilities",
    "section": "Returns:",
    "text": "Returns:\nwn_x: np.ndarray The wavenumbers in the x direction. wn_y: np.ndarray The wavenumbers in the y direction*\n\nimport matplotlib.pyplot as plt\n\n/Users/diaz/mambaforge/envs/physmodjax/lib/python3.10/site-packages/fastcore/docscrape.py:230: UserWarning: potentially wrong underline length... \nParameters: \n---------- in \nCompute the modes of the drumhead.\nThe modes of the drumhead are given by the Bessel function times the sine/cosine of the angle....\n  else: warn(msg)\n/Users/diaz/mambaforge/envs/physmodjax/lib/python3.10/site-packages/fastcore/docscrape.py:230: UserWarning: potentially wrong underline length... \nReturns: \n------- in \nCompute the modes of the drumhead.\nThe modes of the drumhead are given by the Bessel function times the sine/cosine of the angle....\n  else: warn(msg)\n\nsource\n\ndrumhead_eigenfunctions\n\n drumhead_eigenfunctions (wavenumbers:numpy.ndarray, r:numpy.ndarray,\n                          theta:numpy.ndarray)\n\n*Compute the modes of the drumhead. The modes of the drumhead are given by the Bessel function times the sine/cosine of the angle.",
    "crumbs": [
      "Utils",
      "Funtional Transformation Method Utilities"
    ]
  },
  {
    "objectID": "utils/ftm.html#parameters-1",
    "href": "utils/ftm.html#parameters-1",
    "title": "Funtional Transformation Method Utilities",
    "section": "Parameters:",
    "text": "Parameters:\nwavenumbers: np.ndarray The wavenumbers for the drumhead. r: np.ndarray Radial grid points. theta: np.ndarray Angular grid points.",
    "crumbs": [
      "Utils",
      "Funtional Transformation Method Utilities"
    ]
  },
  {
    "objectID": "utils/ftm.html#returns-1",
    "href": "utils/ftm.html#returns-1",
    "title": "Funtional Transformation Method Utilities",
    "section": "Returns:",
    "text": "Returns:\nmodes: np.ndarray The eigenfunctions for the drumhead.*\n\n\n\n\nType\nDetails\n\n\n\n\nwavenumbers\nndarray\n(n_max_modes, m_max_modes)\n\n\nr\nndarray\n(n_gridpoints_r)\n\n\ntheta\nndarray\n(n_gridpoints_theta)\n\n\nReturns\nndarray\n\n\n\n\n/Users/diaz/mambaforge/envs/physmodjax/lib/python3.10/site-packages/fastcore/docscrape.py:230: UserWarning: potentially wrong underline length... \nParameters: \n---------- in \nCompute the eigenvalues of the drumhead.\nThe eigenvalues of the drumhead are given by the square of the wavenumbers....\n  else: warn(msg)\n/Users/diaz/mambaforge/envs/physmodjax/lib/python3.10/site-packages/fastcore/docscrape.py:230: UserWarning: potentially wrong underline length... \nReturns: \n------- in \nCompute the eigenvalues of the drumhead.\nThe eigenvalues of the drumhead are given by the square of the wavenumbers....\n  else: warn(msg)\n\nsource\n\ndrumhead_eigenvalues\n\n drumhead_eigenvalues (wavenumbers:numpy.ndarray)\n\n*Compute the eigenvalues of the drumhead. The eigenvalues of the drumhead are given by the square of the wavenumbers.",
    "crumbs": [
      "Utils",
      "Funtional Transformation Method Utilities"
    ]
  },
  {
    "objectID": "utils/ftm.html#parameters-2",
    "href": "utils/ftm.html#parameters-2",
    "title": "Funtional Transformation Method Utilities",
    "section": "Parameters:",
    "text": "Parameters:\nwavenumbers: np.ndarray The wavenumbers for the drumhead. squared: bool If True, return the squared eigenvalues.",
    "crumbs": [
      "Utils",
      "Funtional Transformation Method Utilities"
    ]
  },
  {
    "objectID": "utils/ftm.html#returns-2",
    "href": "utils/ftm.html#returns-2",
    "title": "Funtional Transformation Method Utilities",
    "section": "Returns:",
    "text": "Returns:\neigenvalues: np.ndarray The eigenvalues of the drumhead.*\n\n\n\n\nType\nDetails\n\n\n\n\nwavenumbers\nndarray\n(n_max_modes, m_max_modes)\n\n\n\n/Users/diaz/mambaforge/envs/physmodjax/lib/python3.10/site-packages/fastcore/docscrape.py:230: UserWarning: potentially wrong underline length... \nParameters: \n---------- in \nCompute the wavenumbers of the drumhead.\n...\n  else: warn(msg)\n/Users/diaz/mambaforge/envs/physmodjax/lib/python3.10/site-packages/fastcore/docscrape.py:230: UserWarning: potentially wrong underline length... \nReturns: \n------- in \nCompute the wavenumbers of the drumhead.\n...\n  else: warn(msg)\n\nsource\n\ndrumhead_wavenumbers\n\n drumhead_wavenumbers (n_max_modes:int, m_max_modes:int, radius:float)\n\n*Compute the wavenumbers of the drumhead.",
    "crumbs": [
      "Utils",
      "Funtional Transformation Method Utilities"
    ]
  },
  {
    "objectID": "utils/ftm.html#parameters-3",
    "href": "utils/ftm.html#parameters-3",
    "title": "Funtional Transformation Method Utilities",
    "section": "Parameters:",
    "text": "Parameters:\nn_max_modes: int The number of angular modes. m_max_modes: int The number of radial modes. radius: float The radius of the drumhead.",
    "crumbs": [
      "Utils",
      "Funtional Transformation Method Utilities"
    ]
  },
  {
    "objectID": "utils/ftm.html#returns-3",
    "href": "utils/ftm.html#returns-3",
    "title": "Funtional Transformation Method Utilities",
    "section": "Returns:",
    "text": "Returns:\nwavenumbers: np.ndarray The wavenumbers for the drumhead.*\n\nsource\n\ndblintegral\n\n dblintegral (integrand, x, y, method='simpson')\n\nCompute the double integral of a function K over the domain x and y.\n\n# Example usage\nn_max_modes = 25\nm_max_modes = 25\nradius = 1.0\nn_gridpoints_r = 100\nn_gridpoints_theta = 100\n\nwavenumbers = drumhead_wavenumbers(n_max_modes, m_max_modes, radius)\neigenvalues = drumhead_eigenvalues(wavenumbers)\nr = np.linspace(0, radius, n_gridpoints_r)\ntheta = np.linspace(0, 2 * np.pi, n_gridpoints_theta)\nK_fwd, K_inv, K_N = drumhead_eigenfunctions(wavenumbers, r, theta)\n\nassert K_inv.shape == (\n    n_max_modes,\n    m_max_modes,\n    n_gridpoints_r,\n    n_gridpoints_theta,\n)\n\nassert K_fwd.shape == (\n    n_max_modes,\n    m_max_modes,\n    n_gridpoints_r,\n    n_gridpoints_theta,\n)\n\n\\[\nK_{n,m}(r, \\varphi) = \\cos (n \\varphi) J_n\\left(\\mu_{n, m} \\frac{r}{R}\\right)\n\\]\nwhere \\(J_n\\) is the Bessel function of the first kind of order \\(n\\), and \\(\\mu_{n, m}\\) is the \\(m\\)-th root of the \\(n\\)-th order Bessel function of the first kind.\n\nn_max_modes_x = 6\nn_max_modes_y = 6\nn_gridpoints_x = 20\nn_gridpoints_y = 20\nlength_x = 1.08\nlength_y = 1.08\ngrid_x = np.linspace(0, length_x, n_gridpoints_x)\ngrid_y = np.linspace(0, length_y, n_gridpoints_y)\n\n# slow version\n# Define the range for n and m\nn_values = np.arange(1, n_max_modes_x + 1)\nm_values = np.arange(1, n_max_modes_y + 1)\n                     \n# Define the range for x and y\nx_values = np.linspace(0, length_x, n_gridpoints_x)\ny_values = np.linspace(0, length_y, n_gridpoints_y)\n\n# Initialize the 4D array to store the results\nK = np.zeros((len(n_values), len(m_values), len(x_values), len(y_values)))\nLambda = np.zeros((len(n_values), len(m_values)))\n# Compute the values\nfor i, n in enumerate(n_values):\n    for j, m in enumerate(m_values):\n        Lambda[i, j] = np.pi**2 * ((n / length_x)**2 + (m / length_y)**2)\n        for k, x in enumerate(x_values):\n            for l, y in enumerate(y_values):\n                K[i, j, k, l] = np.sin(n * np.pi * x / length_x) * np.sin(m * np.pi * y / length_y)\n\n\nwnx, wny = plate_wavenumbers(n_max_modes_x, n_max_modes_y, length_x, length_y)\nassert np.allclose(plate_eigenfunctions(wnx, wny, grid_x, grid_y), K)\nassert np.allclose(plate_eigenvalues(wnx, wny), Lambda)\n\n/Users/diaz/mambaforge/envs/physmodjax/lib/python3.10/site-packages/fastcore/docscrape.py:230: UserWarning: Unknown section Parameters:\n  else: warn(msg)\n/Users/diaz/mambaforge/envs/physmodjax/lib/python3.10/site-packages/fastcore/docscrape.py:230: UserWarning: Unknown section Returns:\n  else: warn(msg)\n\nsource\n\n\ninverse_STL\n\n inverse_STL (K:numpy.ndarray, u_bar:numpy.ndarray, length:float)\n\nCompute the inverse STL transform using the formula of Rabenstein et al. (2000).\n\n\n\n\nType\nDetails\n\n\n\n\nK\nndarray\n(n_modes, n_gridpoints)\n\n\nu_bar\nndarray\n(n_modes, n_samples) or (n_modes,)\n\n\nlength\nfloat\nlength of the string\n\n\nReturns\nndarray\n\n\n\n\n\nsource\n\n\nforward_STL\n\n forward_STL (K:numpy.ndarray, u:numpy.ndarray, dx:float)\n\nCompute the forward STL transform. The integration is done using the trapezoidal rule.\n\n\n\n\nType\nDetails\n\n\n\n\nK\nndarray\n(n_modes, n_gridpoints)\n\n\nu\nndarray\n(n_gridpoints, n_samples) or (n_gridpoints,)\n\n\ndx\nfloat\ngrid spacing\n\n\nReturns\nndarray\n\n\n\n\n\nsource\n\n\ninverse_STL_2d\n\n inverse_STL_2d (K:numpy.ndarray, u_bar:numpy.ndarray, l1:float, l2:float)\n\nCompute the inverse STL transform using the formula of Rabenstein et al. (2000).\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nK\nndarray\n(n_modes_x, n_modes_y, n_gridpoints_x, n_gridpoints_y)\n\n\nu_bar\nndarray\n(n_modes_x, n_modes_y, n_samples) or (n_modes_x, n_modes_y)\n\n\nl1\nfloat\nlength in x\n\n\nl2\nfloat\nlength in y\n\n\nReturns\nndarray\n\n\n\n\n\nsource\n\n\nforward_STL_2d\n\n forward_STL_2d (K:numpy.ndarray, u:numpy.ndarray, x:float, y:float,\n                 use_simpson:bool=False)\n\nCompute the forward STL transform. The integration is done using the trapezoidal rule.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nK\nndarray\n\n(n_modes_x, n_modes_y, n_gridpoints_x, n_gridpoints_y)\n\n\nu\nndarray\n\n(n_gridpoints_x, n_gridpoints_y, n_samples) or (n_gridpoints_x, n_gridpoints_y)\n\n\nx\nfloat\n\ngrid spacing\n\n\ny\nfloat\n\ngrid spacing\n\n\nuse_simpson\nbool\nFalse\n\n\n\nReturns\nndarray\n\n\n\n\n\n\nlength_x = 1.08\nlength_y = 0.8\nn_max_modes_x = 25\nn_max_modes_y = 25\nn_gridpoints_x = 100\nn_gridpoints_y = 100\n\nx = np.linspace(0, length_x, n_gridpoints_x)\ny = np.linspace(0, length_y, n_gridpoints_y)\n\nwnx, wny = plate_wavenumbers(\n    n_max_modes_x,\n    n_max_modes_y,\n    length_x,\n    length_y,\n)\nK = plate_eigenfunctions(wnx, wny, x, y)\n\ng = 0.5 * K[2, 2] + 0.5 * K[3, 3]\n\nbar_g = forward_STL_2d(K, g, x, y, use_simpson=True)\ng_reconstructed = inverse_STL_2d(K, bar_g, length_x, length_y)\n\nassert np.allclose(g, g_reconstructed, atol=1e-2)\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 5))\n\nax[0].imshow(g, origin=\"lower\", aspect=\"auto\")\nax[0].set_title(\"Original excitation\")\nax[1].imshow(g_reconstructed, origin=\"lower\", aspect=\"auto\")\nax[1].set_title(\"Reconstructed excitation\")\n\nText(0.5, 1.0, 'Reconstructed excitation')\n\n\n\n\n\n\n\n\n\n\nsource\n\n\ninverse_STL_drumhead\n\n inverse_STL_drumhead (K_inv:numpy.ndarray, u_bar:numpy.ndarray)\n\nCompute the inverse STL transform using the formula of Rabenstein et al. (2000).\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nK_inv\nndarray\n(n_modes_x, n_modes_y, n_gridpoints_x, n_gridpoints_y)\n\n\nu_bar\nndarray\n(n_modes_x, n_modes_y, n_samples) or (n_modes_x, n_modes_y)\n\n\nReturns\nndarray\n\n\n\n\n\nsource\n\n\nforward_STL_drumhead\n\n forward_STL_drumhead (K:numpy.ndarray, u:numpy.ndarray, r:numpy.ndarray,\n                       theta:numpy.ndarray, use_simpson:bool=False)\n\nCompute the forward STL transform. The integration is done using the trapezoidal rule or Simpson’s rule.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nK\nndarray\n\n(n_modes_r, n_modes_theta, n_gridpoints_r, n_gridpoints_theta)\n\n\nu\nndarray\n\n(n_gridpoints_x, n_gridpoints_y, n_samples) or (n_gridpoints_x, n_gridpoints_y)\n\n\nr\nndarray\n\nradial grid\n\n\ntheta\nndarray\n\nangular grid\n\n\nuse_simpson\nbool\nFalse\n\n\n\nReturns\nndarray\n\n\n\n\n\n\n# Example usage\nn_max_modes = 10\nm_max_modes = 10\nradius = 1.0\nn_gridpoints_r = 100\nn_gridpoints_theta = 100\n\nwavenumbers = drumhead_wavenumbers(n_max_modes, m_max_modes, radius)\neigenvalues = drumhead_eigenvalues(wavenumbers)\nr = np.linspace(0, radius, n_gridpoints_r)\ntheta = np.linspace(0, 2 * np.pi, n_gridpoints_theta)\nK_fwd, K_inv, K_N = drumhead_eigenfunctions(wavenumbers, r, theta)\n\nassert np.allclose(\n    K_fwd.shape, (n_max_modes, m_max_modes, n_gridpoints_r, n_gridpoints_theta)\n)  # Should be (10, 10, 100, 100)\nassert np.allclose(\n    K_inv.shape, (n_max_modes, m_max_modes, n_gridpoints_r, n_gridpoints_theta)\n)  # Should be (10, 10, 100, 100)\n\n# Create an example g array to test the transforms\ng = K_fwd[3, 3]\n\nbar_g = forward_STL_drumhead(K_fwd, g, r, theta, use_simpson=False)\ng_reconstructed = inverse_STL_drumhead(K_inv, bar_g)\n\n# Verify if g can be reconstructed\nassert np.allclose(g, g_reconstructed, atol=1e-2)\nprint(g.min(), g.max())\nprint(g_reconstructed.min(), g_reconstructed.max())\n\n# Plot using pcolormesh\nfig, ax = plt.subplots(\n    1,\n    2,\n    subplot_kw={\"projection\": \"polar\"},\n    figsize=(10, 5),\n)\nc = ax[0].pcolormesh(theta, r, g, shading=\"auto\", cmap=\"viridis\")\nc = ax[1].pcolormesh(theta, r, g_reconstructed, shading=\"auto\", cmap=\"viridis\")\n\n-0.4320502477222054 0.43401550352665574\n-0.4320519880367027 0.4340172517572766\n\n\n\n\n\n\n\n\n\n\nsource\n\n\neigenvalues_from_pde\n\n eigenvalues_from_pde (strpars:__main__.StringParameters,\n                       wavenumbers:numpy.ndarray)\n\nCompute the positive imaginary side of the eigenvalues of the continuous-time system from the PDE parameters.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nstrpars\nStringParameters\n\n\n\nwavenumbers\nndarray\nThe wavenumbers of the modes.\n\n\nReturns\nndarray\nThe eigenvalues of the continuous-time system.\n\n\n\n\nfrom IPython.display import Audio\n\n\nn_max_modes = 50\nsr = 44100\ndt = 1 / sr\nfinal_time = 1.0\nn_samples = int(final_time / dt)\np_params = StringParameters()\nmu = np.arange(1, n_max_modes + 1)\nwn = np.pi * mu / p_params.length\neigvals = eigenvalues_from_pde(p_params, wn)\n\nprint(eigvals.imag.min() / (2 * np.pi))\n\neigvals_d = np.exp(eigvals * dt)\n\nstates = np.vander(eigvals_d, n_samples, increasing=True).real\ndisplay(Audio(states.sum(0), rate=sr))\n\n247.0158068963442\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\nsource\n\n\neigenvalues_from_plate_pde\n\n eigenvalues_from_plate_pde (platepars:__main__.PlateParameters,\n                             wnx:numpy.ndarray, wny:numpy.ndarray)\n\nCompute the positive imaginary side of the eigenvalues of the continuous-time system from the PDE parameters of the rectangular plate. From 5.96 of Digital Sound Synthesis using the FTM, and Eq. 8 of TENSION MODULATED NONLINEAR 2D MODELS FOR DIGITAL SOUND SYNTHESIS WITH THE FUNCTIONAL TRANSFORMATION METHOD.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nplatepars\nPlateParameters\n\n\n\nwnx\nndarray\nwavenumbers x (n_max_modes_x,)\n\n\nwny\nndarray\nwavenumbers y (n_max_modes_y,)\n\n\nReturns\nndarray\nThe eigenvalues of the continuous-time system.\n\n\n\n\nn_max_modes_x = 20\nn_max_modes_y = 20\nsr = 44100\ndt = 1 / sr\nfinal_time = 6.0\nn_samples = int(final_time / dt)\n\np_params = PlateParameters()\nwnx, wny = plate_wavenumbers(n_max_modes_x, n_max_modes_y, p_params.l1, p_params.l2)\neigvals = eigenvalues_from_plate_pde(p_params, wnx, wny).reshape(-1)\n\nprint(eigvals.imag.min() / (2 * np.pi))\neigvals_d = np.exp(eigvals * dt)\n\nstates = np.vander(eigvals_d, n_samples, increasing=True).real\n\ndisplay(Audio(states.sum(0), rate=sr))\n\n10.456826975580865\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\nsource\n\n\neigenvalues_from_drumhead_pde\n\n eigenvalues_from_drumhead_pde\n                                (drumhead_pars:__main__.CircularDrumHeadPa\n                                rameters, Lambda_nm:numpy.ndarray)\n\nCompute the positive imaginary side of the eigenvalues of the continuous-time system from the PDE parameters of the rectangular plate. From 5.96 of Digital Sound Synthesis using the FTM, and Eq. 8 of TENSION MODULATED NONLINEAR 2D MODELS FOR DIGITAL SOUND SYNTHESIS WITH THE FUNCTIONAL TRANSFORMATION METHOD.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndrumhead_pars\nCircularDrumHeadParameters\n\n\n\nLambda_nm\nndarray\n(n_max_modes_r, m_max_modes_theta)\n\n\nReturns\nndarray\nThe eigenvalues of the continuous-time system.\n\n\n\n\nn_max_modes_x = 20\nn_max_modes_y = 20\nsr = 44100\ndt = 1 / sr\nfinal_time = 2.0\nn_samples = int(final_time / dt)\np_params = CircularDrumHeadParameters.avanzini()\n\nv = drumhead_eigenvalues(drumhead_wavenumbers(n_max_modes_x, n_max_modes_y, p_params.r0))\neigvals = eigenvalues_from_drumhead_pde(p_params, v).reshape(-1)\n\n# import matplotlib.pyplot as plt\nprint(eigvals.imag.min() / (2 * np.pi))\nprint(eigvals.imag.max() / (2 * np.pi))\n# plt.plot(eigvals)\n\neigvals_d = np.exp(eigvals * dt)\nstates = np.vander(eigvals_d, n_samples, increasing=True).real\n\n# fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n# ax.plot(states[0])\ndisplay(Audio(states[0], rate=sr))\n\n142.6549044721433\n6141.459247890741\n\n\n\n                \n                    \n                    Your browser does not support the audio element.\n                \n              \n\n\n\nsource\n\n\nsample_parallel_tf\n\n sample_parallel_tf (num:numpy.ndarray, den:numpy.ndarray, dt:float,\n                     method:str='impulse')\n\nSample a parallel transfer function using the impulse invariant method.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnum\nndarray\n\n(n_modes,)\n\n\nden\nndarray\n\n(n_modes,)\n\n\ndt\nfloat\n\n\n\n\nmethod\nstr\nimpulse\n\n\n\nReturns\nnp.ndarray\n\nThe numerator of the discrete-time transfer function.\n\n\n\n\nsource\n\n\ntf_excitation_discrete\n\n tf_excitation_discrete (eigenvalues:numpy.ndarray, density:float,\n                         dt:float)\n\nCompute the discrete-time excitation transfer function of a system.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\neigenvalues\nndarray\nThe eigenvalues of the system.\n\n\ndensity\nfloat\nsurface or area density\n\n\ndt\nfloat\ntime step\n\n\nReturns\nTuple\nThe numerator of the discrete-time transfer function.\n\n\n\n\nsource\n\n\ntf_excitation_continuous\n\n tf_excitation_continuous (eigenvalues:numpy.ndarray, density:float)\n\nCompute the continuous excitation transfer function.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\neigenvalues\nndarray\nThe eigenvalues of the system.\n\n\ndensity\nfloat\nsurface or area density\n\n\nReturns\nTuple\nThe numerator of the discrete-time transfer function.\n\n\n\n\nsource\n\n\ntf_initial_conditions_discrete\n\n tf_initial_conditions_discrete (eigenvalues:numpy.ndarray, dt:float)\n\nCompute the discrete-time initial conditions transfer function of a system.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\neigenvalues\nndarray\nThe eigenvalues of the system.\n\n\ndt\nfloat\ntime step\n\n\nReturns\nTuple\nThe numerator of the discrete-time transfer function.\n\n\n\n\nsource\n\n\ntf_initial_conditions_continuous\n\n tf_initial_conditions_continuous (eigenvalues:numpy.ndarray)\n\nCompute the continuos “initial-conditions” transfer function from the eigenvalues of the system.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\neigenvalues\nndarray\nThe eigenvalues of the system.\n\n\nReturns\nTuple\nThe numerator of the discrete-time transfer function.\n\n\n\n\nb, a = tf_excitation_discrete(eigvals, p_params.surface_density, dt)\nb_ic, a_ic = tf_initial_conditions_discrete(eigvals, dt)\n\n# manual discretization\neigenvalues_d = np.exp(eigvals * dt)\n\n# for the excitation tf\nb1 = (\n    np.exp(eigvals.real * dt)\n    * np.sin(eigvals.imag * dt)\n    / eigvals.imag\n    / p_params.surface_density\n)\n\n# for the initial conditions tf\nb1_ic = (\n    np.exp(eigvals.real * dt)\n    * (\n        np.sin(eigvals.imag * dt) / eigvals.imag * -eigvals.real\n        - np.cos(eigvals.imag * dt)\n    )\n)\n\na1 = -2 * np.exp(eigvals.real * dt) * np.cos(eigvals.imag * dt)\na2 = np.exp(2 * eigvals.real * dt)\nb_manual = np.stack([np.zeros_like(b1), b1, np.zeros_like(b1)], axis=-1) * dt\na_manual = np.stack([np.ones_like(a1), a1, a2], axis=-1)\n\nb_ic_manual = np.stack([np.ones_like(b1_ic), b1_ic], axis=-1) * dt\n\nprint(b[0])\nprint(b_manual[0])\nassert np.allclose(b[:, 1], b_manual[:, 1])\nassert np.allclose(a, a_manual)\nassert np.allclose(b_ic[:, :2], b_ic_manual[:, :2])\n\n[0.00000000e+00 1.90416682e-09 1.11022302e-16]\n[0.00000000e+00 1.90416703e-09 0.00000000e+00]",
    "crumbs": [
      "Utils",
      "Funtional Transformation Method Utilities"
    ]
  },
  {
    "objectID": "utils/checkpoint.html",
    "href": "utils/checkpoint.html",
    "title": "Checkpoint utils",
    "section": "",
    "text": "/Users/diaz/mambaforge/envs/physmodjax/lib/python3.10/site-packages/fastcore/docscrape.py:230: UserWarning: potentially wrong underline length... \nReturns: \n------- in \nRestores the train state from a run.\n...\n  else: warn(msg)\nsource",
    "crumbs": [
      "Utils",
      "Checkpoint utils"
    ]
  },
  {
    "objectID": "utils/checkpoint.html#returns",
    "href": "utils/checkpoint.html#returns",
    "title": "Checkpoint utils",
    "section": "Returns:",
    "text": "Returns:\ntrain_state.TrainState: The train state of the experiment\nnn.Module: The model used in the experiment\nCheckpointManager: The checkpoint manager*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrun_path\nPath\n\nPath to the run directory (e.g. “outputs/2024-01-23/22-15-11”)\n\n\nbest\nbool\nTrue\nIf True, restore the best checkpoint instead of the latest\n\n\nstep_to_restore\nint\nNone\nIf not None, restore the checkpoint at this step\n\n\nx0_shape\nTuple\n(1, 101, 1)\nShape of the initial condition\n\n\nx_shape\nTuple\n(1, 1, 101, 1)\nShape of the input data\n\n\nkwargs\ndict\n{}\nAdditional arguments to pass to the model\n\n\nReturns\nTuple\n\n\n\n\n\n\nsource\n\ndownload_ckpt_single_run\n\n download_ckpt_single_run (run_name:str, project:str,\n                           tmp_dir:pathlib.Path=Path('/tmp/physmodjax'),\n                           overwrite:bool=False)\n\n\nfrom hydra import initialize, compose\nfrom hydra.core.hydra_config import HydraConfig\nfrom physmodjax.scripts.train_rnn import train_rnn\nfrom pathlib import Path\n\n\ndata_array = \"../data/ftm_string_nonlin_1000_Noise_4000Hz_1.0s.npy\"\nbatch_size = 1\nsplit = [0.01, 0.01, 0.01]\nextract_channels = [0]\noutput_dir = \"\"\n\nwith initialize(version_base=None, config_path=\"../../conf\"):\n    cfg = compose(\n        return_hydra_config=True,\n        config_name=\"train_rnn\",\n        overrides=[\n            \"+experiment=1d_koopman\",\n            f\"++datamodule.data_array={data_array}\",\n            f\"++datamodule.batch_size={batch_size}\",\n            f\"++datamodule.split={split}\",\n            f\"++datamodule.extract_channels={extract_channels}\",\n            \"++model.d_vars=1\",\n            \"++epochs=1\",\n            \"++epochs_val=1\",\n            \"++wandb.project=physmodjax\",\n            \"++wandb.entity=iir-modal\"\n        ],\n    )\n    OmegaConf.register_new_resolver(\"eval\", eval, replace=True)\n    OmegaConf.resolve(cfg)\n\n    cfg_no_hydra = {k:v for (k,v) in cfg.items() if \"hydra\" not in k} \n    print(OmegaConf.to_yaml(cfg_no_hydra))\n\n    HydraConfig.instance().set_config(cfg)\n    print(OmegaConf.to_yaml((HydraConfig.get().runtime)))\n\n    output_dir = Path(cfg.hydra.run.dir).absolute()\n    # HydraConfig.get().runtime[\"output_dir\"] = output_dir\n    HydraConfig.instance().set_config(cfg)\n\n    print(f\"Output dir: {output_dir}\")\n\n    train_rnn(cfg)\n\nwandb: WARNING Path /Users/diaz/projects/physmodjax/nbs/utils/outputs/2024-09-03/12-28-33/wandb/ wasn't writable, using system temp directory.\n\n\nmodel:\n  _target_: physmodjax.models.autoencoders.BatchedKoopmanAutoencoder1D\n  _partial_: true\n  d_vars: 1\n  d_model: 101\n  norm: layer\n  encoder_model:\n    _target_: physmodjax.models.mlp.MLP\n    _partial_: true\n    hidden_channels:\n    - 128\n    - 128\n    - 256\n    kernel_init:\n      _target_: flax.linen.initializers.orthogonal\n  decoder_model:\n    _target_: physmodjax.models.mlp.MLP\n    _partial_: true\n    hidden_channels:\n    - 128\n    - 128\n    - 101\n    kernel_init:\n      _target_: flax.linen.initializers.orthogonal\n  dynamics_model:\n    _target_: physmodjax.models.recurrent.LRUDynamics\n    _partial_: true\n    d_hidden: 128\n    r_min: 0.99\n    r_max: 0.999\n    max_phase: 6.28\n    clip_eigs: true\ndatamodule:\n  _target_: physmodjax.utils.data.DirectoryDataModule\n  split:\n  - 0.01\n  - 0.01\n  - 0.01\n  batch_size: 1\n  extract_channels:\n  - 0\n  total_num_train: 4000\n  total_num_val: 4000\n  total_num_test: 4000\n  num_steps_train:\n  - 1\n  - 3999\n  num_steps_val:\n  - 1\n  - 3999\n  mode: split\n  standardize_dataset: true\n  windowed: false\n  cache: true\n  data_array: ../data/ftm_string_nonlin_1000_Noise_4000Hz_1.0s.npy\njax:\n  platform_name: null\n  preallocate_gpu_memory: false\noptimiser:\n  _target_: optax.adamw\n  learning_rate: 0.0001\ngradient_clip:\n  _target_: optax.clip_by_global_norm\n  max_norm: 1.0\nloss:\n  _target_: physmodjax.utils.losses.lindyn_loss\n  _partial_: true\n  encdec_weight: 1.0\n  lindyn_weight: 0.01\n  pred_weight: 1.0\nseed: 3407\nepochs: 1\nepochs_val: 1\nfrozen: []\ninit_from_linear: false\nschedule_type: constant\nwandb:\n  group: 1d\n  project: physmodjax\n  entity: iir-modal\n\nversion: 1.3.2\nversion_base: '1.3'\ncwd: /Users/diaz/projects/physmodjax/nbs/utils\nconfig_sources:\n- path: hydra.conf\n  schema: pkg\n  provider: hydra\n- path: /Users/diaz/projects/physmodjax/conf\n  schema: file\n  provider: main\n- path: ''\n  schema: structured\n  provider: schema\noutput_dir: ???\nchoices:\n  experiment: 1d_koopman\n  loss: lindyn\n  gradient_clip: default.yaml\n  optimiser: default.yaml\n  jax: default.yaml\n  datamodule: string\n  model: 1d_koopman\n  hydra/env: default\n  hydra/callbacks: null\n  hydra/job_logging: default\n  hydra/hydra_logging: default\n  hydra/hydra_help: default\n  hydra/help: default\n  hydra/sweeper: basic\n  hydra/launcher: basic\n  hydra/output: default\n\nOutput dir: /Users/diaz/projects/physmodjax/nbs/utils/outputs/2024-09-03/12-28-33\n\n\nFinishing last run (ID:bg96gmb3) before initializing another...\n\n\n View run chocolate-dream-1762 at: https://wandb.ai/iir-modal/physmodjax/runs/bg96gmb3 View project at: https://wandb.ai/iir-modal/physmodjaxSynced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n\n\nFind logs at: /var/folders/f_/jbsvj3wx2gv9z_2s7ywlc8p00000gn/T/wandb/run-20240903_120018-bg96gmb3/logs\n\n\nSuccessfully finished last run (ID:bg96gmb3). Initializing new run:\n\n\nTracking run with wandb version 0.17.8\n\n\nRun data is saved locally in /var/folders/f_/jbsvj3wx2gv9z_2s7ywlc8p00000gn/T/wandb/run-20240903_122833-4z5togcj\n\n\nSyncing run serene-butterfly-1763 to Weights & Biases (docs)\n\n\n View project at https://wandb.ai/iir-modal/physmodjax\n\n\n View run at https://wandb.ai/iir-modal/physmodjax/runs/4z5togcj\n\n\n\n---------------------------------------------------------------------------\nAssertionError                            Traceback (most recent call last)\nFile ~/mambaforge/envs/physmodjax/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:92, in _call_target(_target_, _partial_, args, kwargs, full_key)\n     91 try:\n---&gt; 92     return _target_(*args, **kwargs)\n     93 except Exception as e:\n\nFile ~/projects/physmodjax/physmodjax/utils/data.py:407, in DirectoryDataModule.__init__(self, data_array, split, batch_size, extract_channels, num_steps_train, num_steps_val, standardize_dataset, mean, std, mode, windowed, hankelize, shuffle_train, cache, rolling_windows, total_num_train, total_num_val, total_num_test)\n    405 self.val_batch_size = batch_size\n--&gt; 407 assert Path(data_array).exists() or all(\n    408     [Path(d).exists() for d in data_array]\n    409 ), \"The data array does not exist\"\n    411 # if we have a list of directories, we will concatenate the data\n    412 # else we will assume that the directory contains the data\n\nAssertionError: The data array does not exist\n\nThe above exception was the direct cause of the following exception:\n\nInstantiationException                    Traceback (most recent call last)\nCell In[12], line 41\n     37 HydraConfig.instance().set_config(cfg)\n     39 print(f\"Output dir: {output_dir}\")\n---&gt; 41 train_rnn(cfg)\n\nFile ~/mambaforge/envs/physmodjax/lib/python3.10/site-packages/hydra/main.py:83, in main.&lt;locals&gt;.main_decorator.&lt;locals&gt;.decorated_main(cfg_passthrough)\n     80 @functools.wraps(task_function)\n     81 def decorated_main(cfg_passthrough: Optional[DictConfig] = None) -&gt; Any:\n     82     if cfg_passthrough is not None:\n---&gt; 83         return task_function(cfg_passthrough)\n     84     else:\n     85         args_parser = get_args_parser()\n\nFile ~/projects/physmodjax/physmodjax/scripts/train_rnn.py:482, in train_rnn(cfg)\n    471 run = wandb.init(\n    472     dir=output_dir,\n    473     config=OmegaConf.to_container(\n   (...)\n    478     **cfg.wandb,\n    479 )\n    481 model_cls = hydra.utils.instantiate(cfg.model)\n--&gt; 482 datamodule = hydra.utils.instantiate(cfg.datamodule)\n    484 # Log data info\n    485 wandb.config.update({\"output_dir\": output_dir})\n\nFile ~/mambaforge/envs/physmodjax/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:226, in instantiate(config, *args, **kwargs)\n    223     _convert_ = config.pop(_Keys.CONVERT, ConvertMode.NONE)\n    224     _partial_ = config.pop(_Keys.PARTIAL, False)\n--&gt; 226     return instantiate_node(\n    227         config, *args, recursive=_recursive_, convert=_convert_, partial=_partial_\n    228     )\n    229 elif OmegaConf.is_list(config):\n    230     # Finalize config (convert targets to strings, merge with kwargs)\n    231     config_copy = copy.deepcopy(config)\n\nFile ~/mambaforge/envs/physmodjax/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:347, in instantiate_node(node, convert, recursive, partial, *args)\n    342                 value = instantiate_node(\n    343                     value, convert=convert, recursive=recursive\n    344                 )\n    345             kwargs[key] = _convert_node(value, convert)\n--&gt; 347     return _call_target(_target_, partial, args, kwargs, full_key)\n    348 else:\n    349     # If ALL or PARTIAL non structured or OBJECT non structured,\n    350     # instantiate in dict and resolve interpolations eagerly.\n    351     if convert == ConvertMode.ALL or (\n    352         convert in (ConvertMode.PARTIAL, ConvertMode.OBJECT)\n    353         and node._metadata.object_type in (None, dict)\n    354     ):\n\nFile ~/mambaforge/envs/physmodjax/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:97, in _call_target(_target_, _partial_, args, kwargs, full_key)\n     95 if full_key:\n     96     msg += f\"\\nfull_key: {full_key}\"\n---&gt; 97 raise InstantiationException(msg) from e\n\nInstantiationException: Error in call to target 'physmodjax.utils.data.DirectoryDataModule':\nAssertionError('The data array does not exist')\nfull_key: datamodule\n\n\n\n\n# instantiate the datamodule\n\ndatamodule = hydra.utils.instantiate(cfg.datamodule)\ntrain_dataloader = datamodule.train_dataloader\nval_dataloader = datamodule.val_dataloader\ntest_dataloader = datamodule.test_dataloader\n\n\ncheckpoint_path, cfg = download_ckpt_single_run(\"eager-valley-1758\")\nkwargs = {\"n_steps\": datamodule.num_steps_target_val}\nstate, model, ckpt_manager = restore_experiment_state(\n    checkpoint_path,\n    kwargs=kwargs,\n)\n\nCheckpoint already exists at /tmp/physmodjax/checkpoints_fiug7qv5:v0, skipping\nUsing data_info from config: [1, 101, 1]\nRestoring checkpoint from step 1...\n\n\n/home/diaz/anaconda3/envs/physmodjax_private/lib/python3.10/site-packages/orbax/checkpoint/type_handlers.py:1552: UserWarning: Couldn't find sharding info under RestoreArgs. Populating sharding info from sharding file. Please note restoration time will be slightly increased due to reading from file instead of directly from RestoreArgs. Note also that this option is unsafe when restoring on a different topology than the checkpoint was saved with.\n  warnings.warn(\n\n\n\nfrom functools import partial\nfrom physmodjax.utils.metrics import (\n    mse,\n    mae,\n    mse_relative,\n    mae_relative,\n    accumulate_metrics,\n)\nimport numpy as np\n\n\n@partial(jax.jit, static_argnames=(\"model\", \"norm\"))\ndef val_step(\n    state: train_state.TrainState,\n    x,\n    y,\n    model,\n    norm,\n):\n    if norm in [\"batch\"]:\n        pred = model.apply(\n            {\"params\": state.params, \"batch_stats\": state.batch_stats}, x\n        )\n    else:\n        pred = model.apply({\"params\": state.params}, x)\n\n    metrics = {\n        \"val/mse\": mse(y, pred),\n        \"val/mae\": mae(y, pred),\n        \"val/mse_rel\": mse_relative(y, pred),\n        \"val/mae_rel\": mae_relative(y, pred),\n    }\n    return metrics, pred\n\n\nval_batch_metrics = []\nfor x, y in val_dataloader:\n\n    metrics, pred = val_step(\n        state,\n        x=x,\n        y=y,\n        model=model,\n        norm=cfg.model.norm,\n    )\n    val_batch_metrics.append(metrics)\nval_batch_metrics = accumulate_metrics(val_batch_metrics)\n\nmetrics = ckpt_manager.metrics(ckpt_manager.best_step())\nval_metrics = {k: v for k, v in metrics.items() if \"val\" in k}\n\nfor key, value in val_metrics.items():\n    assert np.isclose(\n        value, val_batch_metrics[key], atol=1e-6\n    ), f\"Metric {key} does not match: {value} != {val_batch_metrics[key]}\"",
    "crumbs": [
      "Utils",
      "Checkpoint utils"
    ]
  },
  {
    "objectID": "utils/plot.html",
    "href": "utils/plot.html",
    "title": "Plotting utilities",
    "section": "",
    "text": "source\n\nplot_poles_zeros\n\n plot_poles_zeros (p:numpy.ndarray, ax=None, **kwargs)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\np\nndarray\n\n(B, p) zeros\n\n\nax\nNoneType\nNone\n\n\n\nkwargs\n\n\n\n\n\n\n\nsource\n\n\nplot_solution\n\n plot_solution (gt:numpy.ndarray, pred:numpy.ndarray,\n                ar_gt:numpy.ndarray=None, ar_pred:numpy.ndarray=None)\n\n*Plot a comparison of the ground truth and predicted solution.\nArgs: gt: A numpy array of shape (time_steps, grid_size) representing the ground truth values. pred: A numpy array of shape (time_steps, grid_size) representing the predicted values. ar_pred (optional): A numpy array of shape (time_steps, grid_size) representing the autoregressive predicted values.\nReturns: A matplotlib figure object containing the subplots of the ground truth, predicted, and autoregressive predicted solutions.*\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ngt\nndarray\n\n(time_steps, grid_size)\n\n\npred\nndarray\n\n(time_steps, grid_size)\n\n\nar_gt\nndarray\nNone\n(time_steps, grid_size)\n\n\nar_pred\nndarray\nNone\n(time_steps, grid_size)\n\n\nReturns\nFigure\n\n\n\n\n\n\nsource\n\n\nplot_solution_2d\n\n plot_solution_2d (gt:numpy.ndarray, pred:numpy.ndarray,\n                   ar_pred:numpy.ndarray=None, random_sample:bool=False)\n\n*Plot a comparison of the ground truth and predicted solution.\nArgs: gt: A numpy array of shape (time_steps, grid_size) representing the ground truth values. pred: A numpy array of shape (time_steps, grid_size) representing the predicted values. ar_pred (optional): A numpy array of shape (time_steps, grid_size) representing the autoregressive predicted values.\nReturns: A matplotlib figure object containing the subplots of the ground truth, predicted, and autoregressive predicted solutions.*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ngt\nndarray\n\n(T, H, W)\n\n\npred\nndarray\n\n(T, H, W)\n\n\nar_pred\nndarray\nNone\n(T, H, W)\n\n\nrandom_sample\nbool\nFalse\nwhether to randomly sample a time step\n\n\nReturns\nFigure\n\n\n\n\n\n\nsource\n\n\nplot_eigenvalues\n\n plot_eigenvalues (eigenvalues:numpy.ndarray, sample_rate:int=None,\n                   log:bool=False)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\neigenvalues\nndarray\n\n(B, p)\n\n\nsample_rate\nint\nNone\nsample rate of the signal for radians otherwise we use normalized frequency\n\n\nlog\nbool\nFalse\n\n\n\n\n\nsource\n\n\nget_max_row_size\n\n get_max_row_size (alpha, dtype=&lt;class 'float'&gt;)\n\n\nsource\n\n\newma_vectorized_safe\n\n ewma_vectorized_safe (data, alpha, row_size=None, dtype=None, order='C',\n                       out=None)\n\nReshapes data before calculating EWMA, then iterates once over the rows to calculate the offset without precision issues :param data: Input data, will be flattened. :param alpha: scalar float in range (0,1) The alpha parameter for the moving average. :param row_size: int, optional The row size to use in the computation. High row sizes need higher precision, low values will impact performance. The optimal value depends on the platform and the alpha being used. Higher alpha values require lower row size. Default depends on dtype. :param dtype: optional Data type used for calculations. Defaults to float64 unless data.dtype is float32, then it will use float32. :param order: {‘C’, ‘F’, ‘A’}, optional Order to use when flattening the data. Defaults to ‘C’. :param out: ndarray, or None, optional A location into which the result is stored. If provided, it must have the same shape as the desired output. If not provided or None, a freshly-allocated array is returned. :return: The flattened result.\n\nsource\n\n\newma_vectorized_2d\n\n ewma_vectorized_2d (data, alpha, axis=None, offset=None, dtype=None,\n                     order='C', out=None)\n\nCalculates the exponential moving average over a given axis. :param data: Input data, must be 1D or 2D array. :param alpha: scalar float in range (0,1) The alpha parameter for the moving average. :param axis: The axis to apply the moving average on. If axis==None, the data is flattened. :param offset: optional The offset for the moving average. Must be scalar or a vector with one element for each row of data. If set to None, defaults to the first value of each row. :param dtype: optional Data type used for calculations. Defaults to float64 unless data.dtype is float32, then it will use float32. :param order: {‘C’, ‘F’, ‘A’}, optional Order to use when flattening the data. Ignored if axis is not None. :param out: ndarray, or None, optional A location into which the result is stored. If provided, it must have the same shape as the desired output. If not provided or None, a freshly-allocated array is returned.\n\nsource\n\n\newma_vectorized\n\n ewma_vectorized (data, alpha, offset=None, dtype=None, order='C',\n                  out=None)\n\nCalculates the exponential moving average over a vector. Will fail for large inputs. :param data: Input data :param alpha: scalar float in range (0,1) The alpha parameter for the moving average. :param offset: optional The offset for the moving average, scalar. Defaults to data[0]. :param dtype: optional Data type used for calculations. Defaults to float64 unless data.dtype is float32, then it will use float32. :param order: {‘C’, ‘F’, ‘A’}, optional Order to use when flattening the data. Defaults to ‘C’. :param out: ndarray, or None, optional A location into which the result is stored. If provided, it must have the same shape as the input. If not provided or None, a freshly-allocated array is returned.\n\nsource\n\n\nplot_freqz\n\n plot_freqz (h:numpy.ndarray, ax=None, **kwargs)\n\n*Plots the frequency response of a filter.\nParameters: - h: jtx.ArrayLike: The filter’s frequency response. - ax: matplotlib.axes.Axes, optional: The axes to plot on. If not provided, a new figure and axes will be created.\nReturns: - ax: matplotlib.axes.Axes: The plotted axes.*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nndarray\n\nThe filter’s frequency response.\n\n\nax\nNoneType\nNone\nThe axes to plot on. If not provided, a new figure and axes will be created.\n\n\nkwargs\n\n\n\n\n\nReturns\nAxes\n\nAdditional arguments to pass to the plot function.",
    "crumbs": [
      "Utils",
      "Plotting utilities"
    ]
  },
  {
    "objectID": "utils/linear.html",
    "href": "utils/linear.html",
    "title": "Linear utility functions",
    "section": "",
    "text": "source",
    "crumbs": [
      "Utils",
      "Linear utility functions"
    ]
  },
  {
    "objectID": "utils/linear.html#utilities-to-replace-weights",
    "href": "utils/linear.html#utilities-to-replace-weights",
    "title": "Linear utility functions",
    "section": "Utilities to replace weights",
    "text": "Utilities to replace weights\n\nsource\n\nset_params_from_linear\n\n set_params_from_linear (params:Dict, single_eigvals:jax.Array,\n                         single_lstvecs:jax.Array, model:str)\n\n\n\n\n\nType\nDetails\n\n\n\n\nparams\nDict\n\n\n\nsingle_eigvals\nArray\n\n\n\nsingle_lstvecs\nArray\n\n\n\nmodel\nstr\n“lru” or “koopman”\n\n\nReturns\nDict\n\n\n\n\n\nsource\n\n\nget_linear_approximation\n\n get_linear_approximation (y:jax.Array, r:int=50, method:str='dmd')\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ny\nArray\n\n(time_steps, grid_size)\n\n\nr\nint\n50\n\n\n\nmethod\nstr\ndmd\n“dmd”, “full”, “analytical”\n\n\nReturns\nTuple",
    "crumbs": [
      "Utils",
      "Linear utility functions"
    ]
  },
  {
    "objectID": "results.html",
    "href": "results.html",
    "title": "Results",
    "section": "",
    "text": "Result for the paper “Towards Efficient Modelling of String Dynamics: A Comparison of State Space and Koopman Methods”",
    "crumbs": [
      "Results"
    ]
  },
  {
    "objectID": "results.html#animated-predictions",
    "href": "results.html#animated-predictions",
    "title": "Results",
    "section": "Animated Predictions",
    "text": "Animated Predictions\n\nNon-linear Gaussian\n\n\n\nVideo\n\n\nVideo 1\n\n\n\nVideo 1 shows the evolution of the non-linear string at 16kHz with Gaussian-like initial conditions. The first 300 steps are shown.\n\n\nLinear Noise\n\n\n\nVideo\n\n\nVideo 2\n\n\n\nVideo 2 shows the evolution of the linear string at 16kHz with noise-like initial conditions. Only the first 150 steps are shown.",
    "crumbs": [
      "Results"
    ]
  },
  {
    "objectID": "results.html#audio",
    "href": "results.html#audio",
    "title": "Results",
    "section": "Audio",
    "text": "Audio\n\nThe following table shows the audio predictions for a single point in the string for DMD, Koopman, KoopmanVAR, LRU, and S5 methods for both the linear noise and non-linear Gaussian initial conditions.\n\n\n\n\n\n\n\n\n\nLinear Noise\nNon-linear Gaussian\n\n\n\n\nGround Truth\n\n\n\n\nDMD\n\n\n\n\nKoopman\n\n\n\n\nKoopmanVAR\n\n\n\n\nLRU\n\n\n\n\nS5",
    "crumbs": [
      "Results"
    ]
  },
  {
    "objectID": "results.html#table-of-results",
    "href": "results.html#table-of-results",
    "title": "Results",
    "section": "Table of Results",
    "text": "Table of Results\n\n\nResults for the non-linear dataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nGaussian 4000kHz MSE Rel\nGaussian 4000kHz MAE Rel\nGaussian 16000kHz MSE Rel\nGaussian 16000kHz MAE Rel\nNoise 4000kHz MSE Rel\nNoise 4000kHz MAE Rel\nNoise 16000kHz MSE Rel\nNoise 16000kHz MAE Rel\n\n\n\n\nDMD\n1.1865(0.2019)\n0.8289(0.0857)\n1.0938(0.1311)\n0.8747(0.0749)\n1.6695(0.2687)\n1.0420(0.1178)\n1.8313(0.2467)\n1.0953(0.087)\n\n\nKoopman\n0.1041(0.0144)\n0.3271(0.0259)\n0.0971(0.0029)\n0.3117(0.0044)\n0.2070(0.0939)\n0.3978(0.1084)\n0.0865(0.0155)\n0.2596(0.0275)\n\n\nKoopman_var\n0.0113(0.0061)\n0.0977(0.0284)\n0.0094(0.0046)\n0.0888(0.0245)\n0.0041(0.0008)\n0.0527(0.0081)\n0.0531(0.0572)\n0.1714(0.1056)\n\n\nLRU\n0.0260(0.0067)\n0.1571(0.0240)\n0.0390(0.0187)\n0.1870(0.0450)\n0.0250(0.0065)\n0.1284(0.0077)\n0.0476(0.0058)\n0.1922(0.0125)\n\n\nS5\n0.1165(0.0260)\n0.3318(0.0291)\n0.0224(0.0013)\n0.1467(0.0053)\n0.0507(0.0127)\n0.1916(0.0190)\n0.0387(0.0062)\n0.1493(0.0078)\n\n\n\n\n\nResults for the linear dataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nGaussian 4000kHz MSE Rel\nGaussian 4000kHz MAE Rel\nGaussian 16000kHz MSE Rel\nGaussian 16000kHz MAE Rel\nNoise 4000kHz MSE Rel\nNoise 4000kHz MAE Rel\nNoise 16000kHz MSE Rel\nNoise 16000kHz MAE Rel\n\n\n\n\nDMD\n0.0000(0.0000)\n0.0060(0.0007)\n0.0001(0.0000)\n0.0097(0.0006)\n0.0000(0.0000)\n0.0042(0.0004)\n0.0001(0.0000)\n0.0066(0.0004)\n\n\nKoopman\n0.0110(0.0069)\n0.1005(0.0331)\n0.0048(0.0009)\n0.0692(0.0074)\n0.0073(0.0052)\n0.0789(0.0322)\n0.0019(0.0001)\n0.0423(0.0004)\n\n\nKoopman_var\n0.0020(0.0013)\n0.0427(0.0145)\n0.0013(0.0012)\n0.0321(0.0142)\n0.0002(0.0001)\n0.0134(0.0023)\n0.0495(0.0973)\n0.1125(0.1785)\n\n\nLRU\n0.0014(0.0005)\n0.0373(0.0065)\n0.0010(0.0002)\n0.0317(0.0034)\n0.0005(0.0001)\n0.0199(0.0025)\n0.0005(0.0002)\n0.0217(0.0036)\n\n\nS5\n0.0386(0.0273)\n0.1896(0.0597)\n0.0156(0.0102)\n0.1206(0.0421)\n0.0112(0.0029)\n0.1023(0.0139)\n0.0037(0.0012)\n0.0539(0.0119)\n\n\n\nMean and standard deviation (in parentheses) for 5 different seeds of the a) non-linear and b) linear validation data across different models and sampling rates, under Gaussian and noise-like initial conditions. We use 4000 steps for both 4kHz and 16kHz. Since DMD does not depend on a seed, we include the standard deviation of the MSE and MAE across the validation dataset.",
    "crumbs": [
      "Results"
    ]
  },
  {
    "objectID": "utils/metrics.html",
    "href": "utils/metrics.html",
    "title": "Metrics and losses",
    "section": "",
    "text": "source\n\naccumulate_metrics\n\n accumulate_metrics (metrics)\n\n\nsource\n\n\nmae_relative\n\n mae_relative (y_true, y_pred, axis=None)\n\n\nsource\n\n\nmse_relative\n\n mse_relative (y_true, y_pred, axis=None)\n\n\nsource\n\n\nmae\n\n mae (y_true, y_pred, axis=None)\n\n\nsource\n\n\nmse\n\n mse (y_true, y_pred, axis=None)\n\n\nsource\n\n\nabsolute_error\n\n absolute_error (y_true, y_pred)\n\n\nsource\n\n\nsquared_error\n\n squared_error (y_true, y_pred)",
    "crumbs": [
      "Utils",
      "Metrics and losses"
    ]
  },
  {
    "objectID": "utils/modal.html",
    "href": "utils/modal.html",
    "title": "Modal utils",
    "section": "",
    "text": "The modal matrix $ ^{G K} $ represents the mode shapes of a system, with each column as a mode shape corresponding to a vibration mode. Wavenumbers $ ^K $ are given by $ k_= $ for modes $ $ in a system of length $ L $. The grid points $ ^G $ represent spatial discretization, with $ g_j = j x $.\nThe modal matrix is not a direct outer product of $ $ and $ $. Instead, it’s constructed by evaluating mode shapes at these grid points. For systems like vibrating strings, this often involves sinusoidal functions of $ k_$ and $ g_j $, but more complex systems may require detailed analysis or numerical methods.\n\nsource\n\ncreate_modal_matrix\n\n create_modal_matrix (mode_numbers:numpy.ndarray, string_length:float=1.0,\n                      grid:numpy.ndarray=None)\n\n*Creates a matrix with the modal shapes as columns.\n\nparam mode_numbers: Array of mode numbers, representing different vibration modes. :param string_length: Total length of the string. :param grid: Grid of points to evaluate the modes on. :return: Matrix with the modal shapes as columns (shape: (grid.size, mode_numbers.size)).*\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmode_numbers\nndarray\n\narray of mode numbers (integers)\n\n\nstring_length\nfloat\n1.0\ntotal length of the string in meters\n\n\ngrid\nndarray\nNone\ngrid of points to evaluate the modes on\n\n\nReturns\nndarray\n\n\n\n\n\n\nM = create_modal_matrix(np.arange(1, 51), grid=np.linspace(0, 1, 100))\nassert M.shape == (100, 50)\n\nTo convert from the physical domain to the modal domain, we use the modal matrix \\(\\mathbf{M}\\) and a scaling factor:\n\\[\n\\mathbf{u} = \\frac{2}{l} \\mathbf{M} \\cdot \\mathbf{q}\n\\]\nTo convert from the modal domain to the physical domain, we use the inverse modal matrix \\(\\mathbf{M}^{-1}\\) and a scaling factor. Since the modal matrix is orthogonal, the inverse is equal to the transpose:\n\\[\n\\mathbf{q} = \\frac{l}{g} \\mathbf{M}^T \\cdot \\mathbf{u}\n\\]\nwhere \\(g\\) is the number of grid points and \\(l\\) is the length of the string.\n\nsource\n\n\nto_modal\n\n to_modal (physical_displacement:numpy.ndarray,\n           modal_shapes:numpy.ndarray, string_length:float=1.0,\n           num_gridpoints:int=100)\n\n*Convert physical displacement to modal amplitudes.\n\nparam physical_displacement: Array of displacements at grid points. :param modal_shapes: Matrix of modal shapes (each column is a mode shape). :param string_length: Length of the string. :param num_gridpoints: Number of grid points along the string. :return: Array of amplitudes in the modal domain.*\n\n\n\nType\nDefault\nDetails\n\n\n\n\nphysical_displacement\nndarray\n\nDisplacement at grid points\n\n\nmodal_shapes\nndarray\n\nModal shapes (eigenvectors)\n\n\nstring_length\nfloat\n1.0\nLength of the string in meters\n\n\nnum_gridpoints\nint\n100\nNumber of grid points\n\n\nReturns\nndarray\n\n\n\n\n\n\nsource\n\n\nto_displacement\n\n to_displacement (modal_amplitudes:numpy.ndarray,\n                  modal_shapes:numpy.ndarray, string_length:float=1.0)\n\n*Convert modal amplitudes to physical displacement along the string.\n\nparam modal_amplitudes: Array of amplitudes in the modal domain. :param modal_shapes: Matrix of modal shapes (each column is a mode shape). :param string_length: Length of the string. :return: Array of physical displacements at the grid points.*\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmodal_amplitudes\nndarray\n\nAmplitudes in the modal domain\n\n\nmodal_shapes\nndarray\n\nModal shapes (eigenvectors)\n\n\nstring_length\nfloat\n1.0\nLength of the string in meters\n\n\nReturns\nndarray\n\n\n\n\n\n\nsource\n\n\ncreate_pluck_modal\n\n create_pluck_modal (mode_numbers:numpy.ndarray,\n                     pluck_position:float=0.28,\n                     initial_deflection:float=0.03,\n                     string_length:float=1.0)\n\n*Calculate the Fourier-Sine coefficients of the initial deflection of a plucked string in modal coordinates.\n\nparam modes: Array of mode numbers, representing different vibration modes. :param pluck_position: Position of the pluck on the string. :param initial_deflection: Initial displacement of the string at the pluck position. :param string_length: Total length of the string. :return: Array of Fourier-Sine coefficients for each mode.*\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmode_numbers\nndarray\n\narray of mode numbers (integers)\n\n\npluck_position\nfloat\n0.28\nposition of pluck on the string in meters\n\n\ninitial_deflection\nfloat\n0.03\ninitial deflection of the string in meters\n\n\nstring_length\nfloat\n1.0\ntotal length of the string in meters\n\n\nReturns\nndarray\n\n\n\n\n\n\nn_gridpoints = 100\ndx  = 1 / n_gridpoints   # m spatial sampling interval\nmu = np.arange(1, 50 + 1) # mode numbers\nlength = 1.0 # m\nmode_numbers = np.arange(1, 50 + 1)\ngrid = np.arange(0, length, dx)\n\nq = create_pluck_modal(\n    mode_numbers,\n    pluck_position=0.28,\n    initial_deflection=0.03,\n)\n\nM = create_modal_matrix(\n    mu, \n    length, \n    grid\n)\n\nu = to_displacement(q, M, length)\nq = to_modal(u, M, length, n_gridpoints)\nu0_new = to_displacement(q, M, length)\nassert np.allclose(u, u0_new, atol=1e-5)",
    "crumbs": [
      "Utils",
      "Modal utils"
    ]
  },
  {
    "objectID": "utils/losses.html",
    "href": "utils/losses.html",
    "title": "Losses",
    "section": "",
    "text": "source",
    "crumbs": [
      "Utils",
      "Losses"
    ]
  },
  {
    "objectID": "utils/losses.html#loss-functions-for-training",
    "href": "utils/losses.html#loss-functions-for-training",
    "title": "Losses",
    "section": "Loss functions for training",
    "text": "Loss functions for training\n\nsource\n\nfft_loss\n\n fft_loss (params, state:flax.training.train_state.TrainState,\n           x:jax.Array, y:jax.Array, dropout_key:jax.Array=None,\n           norm:str='layer')\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nparams\n\n\n\n\n\nstate\nTrainState\n\n\n\n\nx\nArray\n\ninput sequence (batch, timesteps, grid_size, 1) zeros in our case\n\n\ny\nArray\n\noutput sequence (batch, timesteps, grid_size, 1) u in our case\n\n\ndropout_key\nArray\nNone\n\n\n\nnorm\nstr\nlayer\n\n\n\nReturns\nTuple\n\nloss, pred\n\n\n\n\nsource\n\n\nmse_loss\n\n mse_loss (params, state:flax.training.train_state.TrainState,\n           x:jax.Array, y:jax.Array, dropout_key:jax.Array=None,\n           norm:str='layer')\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nparams\n\n\n\n\n\nstate\nTrainState\n\n\n\n\nx\nArray\n\ninput sequence (batch, timesteps, grid_size, 1) zeros in our case\n\n\ny\nArray\n\noutput sequence (batch, timesteps, grid_size, 1) u in our case\n\n\ndropout_key\nArray\nNone\n\n\n\nnorm\nstr\nlayer\n\n\n\nReturns\nTuple\n\nloss, pred\n\n\n\n\nsource\n\n\nlindyn_loss\n\n lindyn_loss (params, state:flax.training.train_state.TrainState,\n              x:jax.Array, y:jax.Array, encdec_weight:float=1.0,\n              lindyn_weight:float=0.01, pred_weight:float=1.0,\n              dropout_key:jax.Array=None, norm:str='layer')\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nparams\n\n\n\n\n\nstate\nTrainState\n\n\n\n\nx\nArray\n\n(B, T, G, C) pde solution\n\n\ny\nArray\n\n(B, T, G, C) shifted pde solution\n\n\nencdec_weight\nfloat\n1.0\n\n\n\nlindyn_weight\nfloat\n0.01\n\n\n\npred_weight\nfloat\n1.0\n\n\n\ndropout_key\nArray\nNone\n\n\n\nnorm\nstr\nlayer\n\n\n\nReturns\nTuple\n\nloss, pred",
    "crumbs": [
      "Utils",
      "Losses"
    ]
  },
  {
    "objectID": "utils/data.html",
    "href": "utils/data.html",
    "title": "Dataloading utilities",
    "section": "",
    "text": "source\n\nreshape_array\n\n reshape_array (array)\n\n\nsource\n\n\nload_as_big_array\n\n load_as_big_array (files)\n\n\nsource\n\n\nunstandardize\n\n unstandardize (x, mean, std, only_scale=True)\n\n\nsource\n\n\nstandardize\n\n standardize (x, mean, std, only_scale=True)\n\n\nsource\n\n\ncreate_grid\n\n create_grid (height:int, width:int, min_val:float=-1.0,\n              max_val:float=1.0)\n\nCreate a grid of size (height, width) with values between min_val and max_val inclusive.\n\nsource\n\n\nhankel_matrix\n\n hankel_matrix (x, depth:int=2)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nx\n\n\ninput array with shape (B, grid_size, time_steps, channels)\n\n\ndepth\nint\n2\nrepeats the array on the first axis n times\n\n\nReturns\nndarray\n\n\n\n\n\n\na = np.arange(20).reshape(5, 4)\na = np.stack([a, a, a], axis=0)\na = np.stack([a, a*2], axis=-1)\nd = 2\n\nb = hankel_matrix(a, depth=2)\nassert b.shape == (a.shape[0], a.shape[1]- (d-1), a.shape[2]*d, a.shape[3])\n\n\nsource\n\n\nselect_slices\n\n select_slices (key:&lt;function PRNGKey&gt;, idx:jax.Array, data:jax.Array,\n                indices:jax.Array, num_input:int, num_target:int,\n                mode:str, batch_size:int)\n\n\n\n\n\nType\nDetails\n\n\n\n\nkey\nPRNGKey\n\n\n\nidx\nArray\nbatch indices\n\n\ndata\nArray\ninput array with shape (B, T, …)\n\n\nindices\nArray\nindices of the batches\n\n\nnum_input\nint\nnumber of time steps to slice\n\n\nnum_target\nint\nnumber of time steps to predict\n\n\nmode\nstr\nblocks, sequential, passthrough\n\n\nbatch_size\nint\nnumber of slices to take in multi_block mode\n\n\nReturns\nTuple\n\n\n\n\n\nsource\n\n\nsplit_xy\n\n split_xy (data, num_input, num_target)\n\nSplit the data into input and target\n\nsource\n\n\nslice_tensor_single\n\n slice_tensor_single (key:&lt;function PRNGKey&gt;, x:jax.Array, num_input,\n                      num_target, split_mode:str='no_overlap')\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nkey\nPRNGKey\n\n\n\n\nx\nArray\n\ninput array with shape (B, T, …)\n\n\nnum_input\n\n\nnumber of time steps to slice\n\n\nnum_target\n\n\nnumber of time steps to predict\n\n\nsplit_mode\nstr\nno_overlap\nno_split, overlap, no_overlap\n\n\n\n\nsource\n\n\nslice_tensor_multi\n\n slice_tensor_multi (key:&lt;function PRNGKey&gt;, x:jax.Array, num_slices:int,\n                     num_input:int, num_target:int,\n                     split_mode:str='no_overlap')\n\nMany random slices of the tensor along the time axis Warning: Here the time axis is the first axis of the tensor\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nkey\nPRNGKey\n\n\n\n\nx\nArray\n\ninput array with shape (T, …)\n\n\nnum_slices\nint\n\nnumber of slices to take\n\n\nnum_input\nint\n\nnumber of time steps as input\n\n\nnum_target\nint\n\nnumber of time steps as target\n\n\nsplit_mode\nstr\nno_overlap\nno_split, overlap, no_overlap\n\n\n\n\nB, T, W, C = 16, 4000, 40, 2\nx = jnp.ones((B, T, W, C))\n\nnum_input = 1\nnum_target = 199\n\nx, y = select_slices(\n    key=jax.random.PRNGKey(65),\n    idx=0,\n    data=x,\n    indices=jnp.arange(B),\n    num_input=num_input,\n    num_target=num_target,\n    mode=\"many_random_no_overlap\",\n    batch_size=B,\n)\nassert x.shape == (B, num_input, W, C)\nassert y.shape == (B, num_target, W, C)\n\n\nx = jnp.ones((B, T, W, C))\n\nx, y = select_slices(\n    key=jax.random.PRNGKey(65),\n    idx=0,\n    data=x,\n    indices=jnp.arange(B),\n    num_input=1,\n    num_target=199,\n    mode=\"many_random_overlap\",\n    batch_size=B,\n)\nassert x.shape == (B, 199, W, C)\nassert y.shape == (B, 199, W, C)\n\n\nx = jnp.ones((B, T, W, C))\n\n\nx, y = select_slices(\n    key=jax.random.PRNGKey(65),\n    idx=jnp.arange(B),\n    data=x,\n    indices=jnp.arange(B),\n    num_input=num_input,\n    num_target=num_target,\n    mode=\"single_random_no_overlap\",\n    batch_size=None,\n)\nassert x.shape == (B, num_input, W, C)\nassert y.shape == (B, num_target, W, C)\n\n\nsource\n\n\nJaxDataloader\n\n JaxDataloader (data:numpy.ndarray, num_input:int=-1, num_target:int=-1,\n                batch_size:int=16, shuffle:bool=True, drop_last:bool=True,\n                key:Optional[PRNGKey]=Array([0, 0], dtype=uint32),\n                mode:str='passthrough')\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata\nndarray\n\n\n\n\nnum_input\nint\n-1\nlength of the input segment\n\n\nnum_target\nint\n-1\nlength of the target segment\n\n\nbatch_size\nint\n16\nbatch size\n\n\nshuffle\nbool\nTrue\nshuffle the data\n\n\ndrop_last\nbool\nTrue\ndrop the last batch if it’s smaller than batch_size\n\n\nkey\nOptional\n[0 0]\nrandom key\n\n\nmode\nstr\npassthrough\nmode of the dataloader\n\n\n\n\nsource\n\n\nmake_rolling_windows\n\n make_rolling_windows (x:numpy.ndarray, window_size:int)\n\nGenerate rolling windows of size window_size over the time axis of x. Warning: This might generate a large amount of data if the input is large.\n\n\n\n\nType\nDetails\n\n\n\n\nx\nndarray\n(B, T, …)\n\n\nwindow_size\nint\n\n\n\n\n\nB, T, H, W, C = 5, 64, 40, 40, 2\nwin = 16\ndummy = np.ones((B, T, H, W, C))\ndummy = make_rolling_windows(dummy, win)\nassert dummy.shape == (B * (T-win+1), win, H, W, C)\n\n\nsource\n\n\nsplit_data\n\n split_data (mapped_data, split:List[float], extract_channels:List[int])\n\n\nsource\n\n\nDirectoryDataModule\n\n DirectoryDataModule (data_array:Union[str,List[str]],\n                      split:List[float]=[0.8, 0.2, 0.0], batch_size:int=1,\n                      extract_channels:List[int]=[],\n                      num_steps_train:Union[int,List[int],NoneType]=None,\n                      num_steps_val:Union[int,List[int],NoneType]=None,\n                      standardize_dataset:bool=False,\n                      mean:Optional[float]=None, std:Optional[float]=None,\n                      mode:str='passthrough', windowed:bool=False,\n                      hankelize:int=0, shuffle_train:bool=True,\n                      cache:bool=False, rolling_windows:bool=False,\n                      total_num_train:Optional[int]=None,\n                      total_num_val:Optional[int]=None,\n                      total_num_test:Optional[int]=None)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata_array\nUnion\n\n\n\n\nsplit\nList\n[0.8, 0.2, 0.0]\ntrain, val, test\n\n\nbatch_size\nint\n1\nbatch size per device (time steps in parallel mode)\n\n\nextract_channels\nList\n[]\nextract only these channels (u, v)\n\n\nnum_steps_train\nUnion\nNone\n\n\n\nnum_steps_val\nUnion\nNone\nnumber of time steps to use for training\n\n\nstandardize_dataset\nbool\nFalse\nstandardize the dataset per channel\n\n\nmean\nOptional\nNone\nmean for standardization\n\n\nstd\nOptional\nNone\nstd for standardization\n\n\nmode\nstr\npassthrough\nmode of the dataloader\n\n\nwindowed\nbool\nFalse\nslice the data in a windowedd way\n\n\nhankelize\nint\n0\nhankelize the data with depth (0 = no hankelization)\n\n\nshuffle_train\nbool\nTrue\nshuffle the training data\n\n\ncache\nbool\nFalse\ncache the data\n\n\nrolling_windows\nbool\nFalse\ngenerate rolling windows\n\n\ntotal_num_train\nOptional\nNone\ntotal number of training samples\n\n\ntotal_num_val\nOptional\nNone\ntotal number of validation samples\n\n\ntotal_num_test\nOptional\nNone\ntotal number of test samples\n\n\n\n\nsource\n\n\nis_list_like\n\n is_list_like (obj)\n\n\n# generate and save the data\nnum_samples = 100\nnum_timesteps = 120\ngrid_size = 20\nchannels = 2\n\ndata = np.random.randn(num_samples, num_timesteps, grid_size, channels)\nnp.save(\"/tmp/data.npy\", data)\n\n\nbatch_size = 2\n\ndatamodule = DirectoryDataModule(\n    data_array=\"/tmp/data.npy\",\n    split=[0.8, 0.1, 0.1],\n    batch_size=batch_size,\n    extract_channels=[0, 1],\n    num_steps_train=[1, 19],\n    num_steps_val=[3, 17],\n    cache=True,\n    standardize_dataset=True,\n    mode=\"many_random_no_overlap\",\n    windowed=False,\n    hankelize=0,\n)\n\ntrain_x, train_y = next(iter(datamodule.train_dataloader))\nassert train_x.shape == (batch_size, 1, grid_size, channels)\nassert train_y.shape == (batch_size, 19, grid_size, channels)\n\nval_x, val_y = next(iter(datamodule.val_dataloader))\nassert val_x.shape == (batch_size, 3, grid_size, channels)\nassert val_y.shape == (batch_size, 17, grid_size, channels)\n\ntest_data = next(iter(datamodule.test_dataloader))\nassert test_data.shape == (1, num_timesteps, grid_size, channels)\n\n\nbatch_size = 2\ndatamodule = DirectoryDataModule(\n    data_array=\"/tmp/data.npy\",\n    split=[0.8, 0.1, 0.1],\n    batch_size=batch_size,\n    extract_channels=[0, 1],\n    cache=True,\n    standardize_dataset=True,\n    mode=\"passthrough\",\n    windowed=False,\n)\n\ntrain_x = next(iter(datamodule.train_dataloader))\nassert train_x.shape == (batch_size, num_timesteps, grid_size, channels)\n\nval_x = next(iter(datamodule.val_dataloader))\nassert val_x.shape == (batch_size, num_timesteps, grid_size, channels)\n\ntest_data = next(iter(datamodule.test_dataloader))\nassert test_data.shape == (1, num_timesteps, grid_size, channels)\n\n\nbatch_size = 2\nnum_steps_train = [1, 59]\nnum_steps_val = [1, 59]\ndatamodule = DirectoryDataModule(\n    data_array=\"/tmp/data.npy\",\n    split=[0.8, 0.1, 0.1],\n    batch_size=batch_size,\n    extract_channels=[0, 1],\n    num_steps_train=num_steps_train,\n    num_steps_val=num_steps_val,\n    cache=True,\n    standardize_dataset=True,\n    mode=\"passthrough\",\n    windowed=True,\n)\n\ntrain_x = next(iter(datamodule.train_dataloader))\nassert train_x.shape == (batch_size, sum(num_steps_train), grid_size, channels)\n\nval_x = next(iter(datamodule.val_dataloader))\nassert val_x.shape == (batch_size, sum(num_steps_val), grid_size, channels)\n\ntest_data = next(iter(datamodule.test_dataloader))\nassert test_data.shape == (1, num_timesteps, grid_size, channels)\n\n\nbatch_size = 2\nnum_steps_train = 50\nnum_steps_val = 50\ndatamodule = DirectoryDataModule(\n    data_array=\"/tmp/data.npy\",\n    split=[0.8, 0.1, 0.1],\n    batch_size=batch_size,\n    extract_channels=[0, 1],\n    num_steps_train=[1, 49],\n    num_steps_val=[1, 49],\n    cache=True,\n    standardize_dataset=True,\n    mode=\"many_random_no_split\",\n    windowed=False,\n)\n\ntrain_x = next(iter(datamodule.train_dataloader))\nassert train_x.shape == (batch_size, num_steps_train, grid_size, channels)\n\nval_x = next(iter(datamodule.val_dataloader))\nassert val_x.shape == (batch_size, num_steps_val, grid_size, channels)\n\ntest_data = next(iter(datamodule.test_dataloader))\nassert test_data.shape == (1, num_timesteps, grid_size, channels)\n\n\nbatch_size = 16\nnum_steps_train = 50\nnum_steps_val = 50\ndatamodule = DirectoryDataModule(\n    data_array=\"/tmp/data.npy\",\n    split=[0.8, 0.1, 0.1],\n    batch_size=batch_size,\n    extract_channels=[0, 1],\n    num_steps_train=[1, 49],\n    num_steps_val=[1, 49],\n    cache=True,\n    standardize_dataset=True,\n    mode=\"single_random_no_split\",\n    windowed=False,\n)\n\ntrain_x = next(iter(datamodule.train_dataloader))\nassert train_x.shape == (batch_size, num_steps_train, grid_size, channels)\n\nval_x = next(iter(datamodule.val_dataloader))\nassert val_x.shape == (10, num_steps_val, grid_size, channels)\n\ntest_data = next(iter(datamodule.test_dataloader))\nassert test_data.shape == (1, num_timesteps, grid_size, channels)\n\n\nbatch_size = 16\nnum_steps_train = [1, 59]\nnum_steps_val = [1, 59]\ndatamodule = DirectoryDataModule(\n    data_array=\"/tmp/data.npy\",\n    split=[0.8, 0.1, 0.1],\n    batch_size=batch_size,\n    extract_channels=[0, 1],\n    num_steps_train=num_steps_train,\n    num_steps_val=num_steps_val,\n    cache=True,\n    standardize_dataset=True,\n    mode=\"split\",\n    windowed=True,\n)\n\ntrain_x, train_y = next(iter(datamodule.train_dataloader))\nassert train_x.shape == (batch_size, num_steps_train[0], grid_size, channels)\n\nval_x, val_y = next(iter(datamodule.val_dataloader))\nassert val_x.shape == (10, num_steps_val[0], grid_size, channels)\n\ntest_data = next(iter(datamodule.test_dataloader))\nassert test_data.shape == (1, num_timesteps, grid_size, channels)\n\n\ndef iterate_over_dataloader():\n    for x in datamodule.train_dataloader:\n        pass\n\n2.29 ms ± 156 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)",
    "crumbs": [
      "Utils",
      "Dataloading utilities"
    ]
  },
  {
    "objectID": "models/mlp.html",
    "href": "models/mlp.html",
    "title": "MLP models",
    "section": "",
    "text": "source\n\nMLP\n\n MLP (hidden_channels:Sequence[int],\n      activation:flax.linen.module.Module=&lt;PjitFunction of &lt;function selu\n      at 0x107f9b7f0&gt;&gt;, kernel_init:Union[jax.nn.initializers.Initializer,\n      collections.abc.Callable[...,Any]]=&lt;function init&gt;,\n      use_bias:bool=True, layer_norm:bool=False, parent:Union[flax.linen.m\n      odule.Module,flax.core.scope.Scope,flax.linen.module._Sentinel,NoneT\n      ype]=&lt;flax.linen.module._Sentinel object at 0x11a1a75e0&gt;,\n      name:Optional[str]=None)\n\nMLP with SELU activation and LeCun normal initialization.",
    "crumbs": [
      "Models",
      "MLP models"
    ]
  },
  {
    "objectID": "models/recurrent.html",
    "href": "models/recurrent.html",
    "title": "Recurrent Models",
    "section": "",
    "text": "Linear dynamics using initisialisation of the eigenvalues based on the LRU paper\n\n\n\n\nsource\n\n\n\n\n LRUDynamicsVarying (d_hidden:int, r_min:float, r_max:float,\n                     max_phase:float, clip_eigs:bool,\n                     model:flax.linen.module.Module, parent:Union[flax.lin\n                     en.module.Module,flax.core.scope.Scope,flax.linen.mod\n                     ule._Sentinel,NoneType]=&lt;flax.linen.module._Sentinel\n                     object at 0x11a1a75e0&gt;, name:Optional[str]=None)\n\n\nfrom physmodjax.models.mlp import MLP\n\n\nd_hidden = 64\nsteps = 50\nmodel = MLP(hidden_channels=[64, 64, 64])\ndyn = LRUDynamicsVarying(\n    d_hidden=d_hidden,\n    r_min=0.99,\n    r_max=1.0,\n    max_phase=jnp.pi * 2,\n    model=model,\n    clip_eigs=False,\n)",
    "crumbs": [
      "Models",
      "Recurrent Models"
    ]
  },
  {
    "objectID": "models/recurrent.html#lru-dynamics",
    "href": "models/recurrent.html#lru-dynamics",
    "title": "Recurrent Models",
    "section": "",
    "text": "Linear dynamics using initisialisation of the eigenvalues based on the LRU paper\n\n\n\n\nsource\n\n\n\n\n LRUDynamicsVarying (d_hidden:int, r_min:float, r_max:float,\n                     max_phase:float, clip_eigs:bool,\n                     model:flax.linen.module.Module, parent:Union[flax.lin\n                     en.module.Module,flax.core.scope.Scope,flax.linen.mod\n                     ule._Sentinel,NoneType]=&lt;flax.linen.module._Sentinel\n                     object at 0x11a1a75e0&gt;, name:Optional[str]=None)\n\n\nfrom physmodjax.models.mlp import MLP\n\n\nd_hidden = 64\nsteps = 50\nmodel = MLP(hidden_channels=[64, 64, 64])\ndyn = LRUDynamicsVarying(\n    d_hidden=d_hidden,\n    r_min=0.99,\n    r_max=1.0,\n    max_phase=jnp.pi * 2,\n    model=model,\n    clip_eigs=False,\n)",
    "crumbs": [
      "Models",
      "Recurrent Models"
    ]
  },
  {
    "objectID": "models/recurrent.html#deep-gru",
    "href": "models/recurrent.html#deep-gru",
    "title": "Recurrent Models",
    "section": "Deep GRU",
    "text": "Deep GRU\n\nsource\n\nDeepRNN\n\n DeepRNN (d_model:int, d_vars:int, n_layers:int,\n          cell:flax.linen.module.Module, training:bool=True,\n          norm:str='layer', parent:Union[flax.linen.module.Module,flax.cor\n          e.scope.Scope,flax.linen.module._Sentinel,NoneType]=&lt;flax.linen.\n          module._Sentinel object at 0x11a1a75e0&gt;,\n          name:Optional[str]=None)\n\nA deep RNN model that applies a RNN cell over the last dimension of the input. Works with nn.GRUCell, nn.RNNCell, nn.SimpleCell, nn.MGUCell.\n\nB, T, W, C = 10, 50, 20, 3\ndeep_rnn = BatchedDeepRNN(d_model=W, d_vars=C, n_layers=2, cell=partial(nn.GRUCell))\nx = jnp.ones((B, T, W, C))\nx0 = jnp.ones((B, W, C))\nvariables = deep_rnn.init(jax.random.PRNGKey(65), x0, x)\nout = deep_rnn.apply(variables, x0, x)\n\nassert out.shape == (B, T, W, C)",
    "crumbs": [
      "Models",
      "Recurrent Models"
    ]
  },
  {
    "objectID": "models/conv.html",
    "href": "models/conv.html",
    "title": "Convolutional models",
    "section": "",
    "text": "source\n\nConvDecoder\n\n ConvDecoder (output_features:int=3, block_size:Tuple[int,...]=(16, 32,\n              64), padding:str='SAME', norm:str='layer',\n              training:bool=True, parent:Union[flax.linen.module.Module,fl\n              ax.core.scope.Scope,flax.linen.module._Sentinel,NoneType]=&lt;f\n              lax.linen.module._Sentinel object at 0x11a1a75e0&gt;,\n              name:Optional[str]=None)\n\n\nsource\n\n\nConvEncoder\n\n ConvEncoder (block_size:Tuple[int,...]=(16, 32, 64), padding:str='SAME',\n              norm:str='layer', training:bool=True, parent:Union[flax.line\n              n.module.Module,flax.core.scope.Scope,flax.linen.module._Sen\n              tinel,NoneType]=&lt;flax.linen.module._Sentinel object at\n              0x11a1a75e0&gt;, name:Optional[str]=None)\n\n\nsource\n\n\nUpsampleBlock\n\n UpsampleBlock (features:int, kernel_size:Tuple[int,int]=(3, 3),\n                padding:str='SAME', norm:str='layer', training:bool=True, \n                parent:Union[flax.linen.module.Module,flax.core.scope.Scop\n                e,flax.linen.module._Sentinel,NoneType]=&lt;flax.linen.module\n                ._Sentinel object at 0x11a1a75e0&gt;,\n                name:Optional[str]=None)\n\n\nsource\n\n\nDownsampleBlock\n\n DownsampleBlock (features:int, padding:str='SAME', norm:str='layer',\n                  training:bool=True, parent:Union[flax.linen.module.Modul\n                  e,flax.core.scope.Scope,flax.linen.module._Sentinel,None\n                  Type]=&lt;flax.linen.module._Sentinel object at\n                  0x11a1a75e0&gt;, name:Optional[str]=None)\n\n*Two unpadded convolutions & downsample 2x.\nAttributes: features: Num convolutional features. padding: Type of padding: ‘SAME’ or ‘VALID’. norm: Whether to use batchnorm at the end or not.*\n\nsource\n\n\nDeConv3x3\n\n DeConv3x3 (features:int, padding:str='SAME', norm:str='layer',\n            training:bool=True, parent:Union[flax.linen.module.Module,flax\n            .core.scope.Scope,flax.linen.module._Sentinel,NoneType]=&lt;flax.\n            linen.module._Sentinel object at 0x11a1a75e0&gt;,\n            name:Optional[str]=None)\n\n*Deconvolution layer for upscaling.\nAttributes: features: Num convolutional features. padding: Type of padding: ‘SAME’ or ‘VALID’. norm: Whether to use batchnorm at the end or not.*\n\nsource\n\n\nConvRelu2\n\n ConvRelu2 (features:int, padding:str='SAME', norm:str='layer',\n            training:bool=True, parent:Union[flax.linen.module.Module,flax\n            .core.scope.Scope,flax.linen.module._Sentinel,NoneType]=&lt;flax.\n            linen.module._Sentinel object at 0x11a1a75e0&gt;,\n            name:Optional[str]=None)\n\n*Two unpadded convolutions & relus.\nAttributes: features: Num convolutional features. padding: Type of padding: ‘SAME’ or ‘VALID’. norm: Whether to use batchnorm at the end or not.*\n\ndummy_2d = jnp.ones((40, 40, 3))\n\nblock_size = (12, 24, 48)\npadding = \"SAME\"\nnorm = \"layer\"\n\nconv_encoder = ConvEncoder(\n    block_size=block_size,\n    padding=padding,\n    norm=norm,\n)\nconv_vars = conv_encoder.init(jax.random.PRNGKey(0), jnp.ones_like(dummy_2d))\nout = conv_encoder.apply(conv_vars, dummy_2d)\n\nconv_decoder = ConvDecoder(\n    output_features=3,\n    block_size=block_size,\n    padding=padding,\n    norm=norm,\n)\n\nconv_dec_vars = conv_decoder.init(jax.random.PRNGKey(0), jnp.ones_like(out))\nout = conv_decoder.apply(conv_dec_vars, out)\n\nassert out.shape == dummy_2d.shape",
    "crumbs": [
      "Models",
      "Convolutional models"
    ]
  },
  {
    "objectID": "solver/wave2d_solver_modal.html",
    "href": "solver/wave2d_solver_modal.html",
    "title": "Wave 2D linear solver",
    "section": "",
    "text": "adapted from Paker repo\n\nsource\n\nWaveSolver2DJax\n\n WaveSolver2DJax (sampling_rate:int=48000, final_time:float=0.02,\n                  rho:float=1.2041, n_max_modes:int=10, lx:float=1.0,\n                  ly:float=1.0, c0:float=343, damping=1.0,\n                  spatial_delta=0.001)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsampling_rate\nint\n48000\n1/s Temporal sampling frequency\n\n\nfinal_time\nfloat\n0.02\ns Duration of the simulation\n\n\nrho\nfloat\n1.2041\nkg/m**3 Density\n\n\nn_max_modes\nint\n10\nNumber of modal expansion terms\n\n\nlx\nfloat\n1.0\nm Length in x direction\n\n\nly\nfloat\n1.0\nm Length in y direction\n\n\nc0\nfloat\n343\nm/s Speed of sound\n\n\ndamping\nfloat\n1.0\nDamping factor\n\n\nspatial_delta\nfloat\n0.001\nm Spatial sampling grid\n\n\n\n\n# jax.config.update(\"jax_enable_x64\", False)\n# os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_deterministic_ops=true\" # add xla flags\n\ndur = 0.001\nnum_variations = 1024\n\nfs = 48000\nnum_points = 40\nsimulated_modes = 25\nroom_size = 1\nroom_aspect_ratio = 1\nnum_example_timesteps = 100\n\n#######################################################################################################################\nsolver = WaveSolver2DJax(\n    final_time=dur,\n    sampling_rate=fs,\n    lx=room_size,\n    ly=room_aspect_ratio * room_size,\n    spatial_delta=room_size / num_points,\n    n_max_modes=simulated_modes,\n)\n\n\n# jax.config.update(\"jax_enable_x64\", False)\n\nfe_x = solver.create_random_initial(np.random.default_rng(42))\n# fe_x = solver.create_impulse(0.5, 0.5)\n\nybar, y_sp, y_vx, y_vy = solver.solve(fe_x)\nybar_vander, y_sp_vander, y_vx_vander, y_vy_vander = solver.solve(fe_x, parallel=True)\n\ndiff_ybar = np.abs(ybar - ybar_vander)\ndiff_y_sp = np.abs(y_sp - y_sp_vander)\ndiff_y_vx = np.abs(y_vx - y_vx_vander)\ndiff_y_vy = np.abs(y_vy - y_vy_vander)\n\nprint(\"ybar diff\", np.max(diff_ybar))\nprint(\"y_sp diff\", np.max(diff_y_sp))\nprint(\"y_vx diff\", np.max(diff_y_vx))\nprint(\"y_vy diff\", np.max(diff_y_vy))\n\nybar diff 0.0\ny_sp diff 0.0\ny_vx diff 0.0\ny_vy diff 0.0\n\n\n\nprint(y_sp.shape, y_vx.shape, y_vy.shape)\n\nfig, ax = plt.subplots(1, 3, figsize=(10, 5))\nax[0].imshow(y_sp[:,:,200])\nax[1].imshow(y_vx[:,:,200])\nax[2].imshow(y_vy[:,:,200])\n\n(40, 40, 48) (40, 40, 48) (40, 40, 48)\n\n\n\n\n\n\n\n\n\n\n\nSave a fast dataset\n\nsource\n\n\ncreate_2d_wave_data\n\n create_2d_wave_data (num_ics:int, data_dir:str, W:int=40, dur:float=0.01,\n                      sample_rate:int=48000, simulated_modes:int=25,\n                      seed:int=42, ic_type:str='random')\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnum_ics\nint\n\nnumber of initial conditions\n\n\ndata_dir\nstr\n\ndirectory to save the data\n\n\nW\nint\n40\nwidth\n\n\ndur\nfloat\n0.01\ntime\n\n\nsample_rate\nint\n48000\nsampling rate\n\n\nsimulated_modes\nint\n25\nnumber of modes\n\n\nseed\nint\n42\nrandom seed\n\n\nic_type\nstr\nrandom\ntype of initial condition (random or impulse)\n\n\n\n\ndata_dir = \"2d_wave_data\"\n\ncreate_2d_wave_data(1000, data_dir, ic_type=\"random\")\n\nTotal size in GB 0.000192\n\n\n100%|██████████| 1000/1000 [01:30&lt;00:00, 11.01it/s]\n\n\n\nimport matplotlib.pyplot as plt\n\n\n# check the data, the first 3 files should be different\nfor i in range(1, 4):\n    data = np.load(f\"{data_dir}/ic_{i:05d}.npy\")\n    print(data.shape)\n    fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n    ax[0].imshow(data[100, :, :, 0])\n    ax[1].imshow(data[100, :, :, 1])\n    ax[2].imshow(data[100, :, :, 2])\n\nplt.show()\n\n(480, 40, 40, 3)\n(480, 40, 40, 3)\n(480, 40, 40, 3)",
    "crumbs": [
      "Solver",
      "Wave 2D linear solver"
    ]
  },
  {
    "objectID": "solver/wave1d_solver_pseudospectral.html",
    "href": "solver/wave1d_solver_pseudospectral.html",
    "title": "Pseudo-spectral Solver",
    "section": "",
    "text": "The wave equation in 1D is given by:\n\\[\\frac{\\partial^2 u}{\\partial t^2} = c^2 \\frac{\\partial^2 u}{\\partial x^2}\\]\nwhere \\(c\\) is the wave speed.\nIn the pseudo-spectral method, we transform the derivatives in space to the frequency domain, solve the equation in the frequency domain, and then transform back to the spatial domain. We solve the problem and iterate using an ode solver.\nThe 2nd derivative in space is given by:\n\\[\n\\frac{\\partial^2 u}{\\partial x^2} = \\mathcal{F}^{-1} \\left[ (ik)^2 \\mathcal{F} \\left( u \\right) \\right]\n\\]\nwhere \\(\\mathcal{F}\\) and \\(\\mathcal{F}^{-1}\\) are the forward and inverse Fourier transforms, respectively, and \\(k\\) is the wavenumber.\n\nimport matplotlib.pyplot as plt\n\n\nsource\n\nfourier_derivative_2\n\n fourier_derivative_2 (u:numpy.ndarray, k:numpy.ndarray)\n\nCompute the 2nd derivative of a function in Fourier space, and return the result in physical space.\n\n\n\n\nType\nDetails\n\n\n\n\nu\nndarray\nfunction in physical space\n\n\nk\nndarray\nwave number array\n\n\n\nDefine the right-hand side of the equation as\n\nsource\n\n\nWave1dSolverPseudoSpectral\n\n Wave1dSolverPseudoSpectral (sampling_rate:float, final_time:float,\n                             length:float, n_gridpoints:int,\n                             wave_speed:float=1)\n\nThis class solves the 1D wave equation using the pseudo-spectral method. Inspired by the content in https://www.coursera.org/learn/computers-waves-simulations/home/week/5 It assumes dirchlet boundary conditions on both ends of the string.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsampling_rate\nfloat\n\nsampling rate in Hz\n\n\nfinal_time\nfloat\n\nfinal time in seconds\n\n\nlength\nfloat\n\nlength of the string in meters\n\n\nn_gridpoints\nint\n\nnumber of points in the string\n\n\nwave_speed\nfloat\n1\nwave speed in m/s\n\n\n\nTest the solver\n\nfrom physmodjax.solver.generator import Gaussian\n\n\nn_gridpoints = 1000\nsolver = Wave1dSolverPseudoSpectral(\n    sampling_rate=44100,\n    final_time=1,\n    length=1,\n    n_gridpoints=n_gridpoints,\n    wave_speed=1,\n)\n\nu0 = Gaussian(num_points=n_gridpoints)()\nv0 = np.zeros_like(u0)\n\nt, u, v = solver.solve(u0, v0)\n\ndx: 0.010101010101010102 in meters\ndt: 2.0833333333333333e-05 in seconds\nnumber of points (n_gridpoints): (100,)\ntime in samples (nt): (48000,)\n(48000,) (48000, 100) (48000, 100)\n\n\n\n# show the solution viewed from above\nplt.figure(figsize=(5, 10))\nplt.pcolormesh(solver.grid, t[::100], u[::100])\nplt.xlabel(\"x\")\nplt.ylabel(\"t\")\nplt.colorbar()\nplt.show()",
    "crumbs": [
      "Solver",
      "Pseudo-spectral Solver"
    ]
  },
  {
    "objectID": "solver/impulse_generator.html",
    "href": "solver/impulse_generator.html",
    "title": "Impulse generator",
    "section": "",
    "text": "import matplotlib.pyplot as plt\n\n\nsource\n\nGenerator\n\n Generator ()\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nGaussian\n\n Gaussian (num_points:int=100)\n\nInitialize self. See help(type(self)) for accurate signature.\n\ny = Gaussian(num_points=501)(mean=0.5, std=0.0000005)\nassert len(y) == 501\n# plot the gaussian\nplt.plot(y)\n\n\n\n\n\n\n\n\n\nsource\n\n\nGaussian2d\n\n Gaussian2d (num_points_x:int=100, aspect_ratio:float=1.0)\n\nThis class generates a 2D gaussian distribution.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnum_points_x\nint\n100\n\n\n\naspect_ratio\nfloat\n1.0\naspect ratio of the lengths of the two axes, ly/lx\n\n\n\n\nnx = 101\naspect_ratio = 0.7\nz = Gaussian2d(num_points_x=nx, aspect_ratio=aspect_ratio)(mean=(0.9,1.0), std=0.05)\nny = int(np.floor((nx -1) * aspect_ratio)) + 1\nprint(z.shape)\nprint(nx, ny)\nassert z.shape == (nx, ny)\n# plot the gaussian\nplt.imshow(z, vmin=0, vmax=1)\n\n(101, 71)\n101 71\n\n\n\n\n\n\n\n\n\n\nsource\n\n\nNoiseBurst\n\n NoiseBurst (num_points:int=100)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nrng = np.random.default_rng(42)\ny = NoiseBurst(num_points=500)(rng, noise_range=[0, 1], burst_mean=0.5, burst_std=0.05)\nassert len(y) == 500\n\n\nsource\n\n\nNoise\n\n Noise (num_points:int=100)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nNoise2d\n\n Noise2d (num_points_x:int=100, aspect_ratio:float=1.0)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnum_points_x\nint\n100\n\n\n\naspect_ratio\nfloat\n1.0\naspect ratio of the lengths of the two axes, ly/lx\n\n\n\n\nrng = np.random.default_rng(42)\nz = Noise2d(num_points_x=100, aspect_ratio=0.7)(rng, noise_range=[0, 1])\nassert z.shape == (100, 70)\nplt.imshow(z, vmin=0, vmax=1)\n\n\n\n\n\n\n\n\n\nsource\n\n\nSineMode\n\n SineMode (num_points:int=100)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\ngenerate_initial_condition\n\n generate_initial_condition\n                             (rng:numpy.random._generator.Generator=Genera\n                             tor(PCG64) at 0x126827CA0, generator:__main__\n                             .Generator=&lt;__main__.Gaussian object at\n                             0x126b48670&gt;, ic_type:str='pluck',\n                             ic_max_amplitude:float=1.0,\n                             ic_min_amplitude:float=0.0,\n                             ic_amplitude_random:bool=False,\n                             ic_sine_k:int=1)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nrng\nGenerator\nGenerator(PCG64)\n\n\n\ngenerator\nGenerator\n&lt;main.Gaussian object at 0x126b48670&gt;\n\n\n\nic_type\nstr\npluck\n“pluck” or “hammer”\n\n\nic_max_amplitude\nfloat\n1.0\nAmplitude of the initial condition, when ic_amplitude_random is True, this is the upper bound\n\n\nic_min_amplitude\nfloat\n0.0\nonly used when ic_amplitude_random is True\n\n\nic_amplitude_random\nbool\nFalse\nIf True, the amplitude is chosen randomly between ic_min_amplitude and ic_max_amplitude\n\n\nic_sine_k\nint\n1\nonly used when ic_type is “sine”\n\n\nReturns\nTuple\n\na tuple of position and velocity\n\n\n\n\nsource\n\n\nmake_pluck_hammer\n\n make_pluck_hammer (y:numpy.ndarray, ic_type:str='pluck')\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ny\nndarray\n\n\n\n\nic_type\nstr\npluck\n“pluck” or “hammer”\n\n\nReturns\nTuple\n\n\n\n\n\n\nrng = np.random.default_rng()\nic_type = \"pluck\"\nic_max_amplitude = 0.7\nic_min_amplitude = 0.1\nic_amplitude_random = False\nnum_points = 500\nu, v = generate_initial_condition(\n    rng,\n    SineMode(num_points=num_points),\n    ic_type=ic_type,\n    ic_max_amplitude=ic_max_amplitude,\n    ic_min_amplitude=ic_min_amplitude,\n    ic_amplitude_random=ic_amplitude_random,\n    ic_sine_k=10,\n)\nif ic_type == \"pluck\":\n    assert np.all(v == 0)\n    if ic_amplitude_random:\n        assert np.max(np.abs(u)) &lt;= ic_max_amplitude\n        assert np.max(np.abs(u)) &gt;= ic_min_amplitude\n    else:\n        assert np.max(np.abs(u)) == ic_max_amplitude\nelif ic_type == \"hammer\":\n    assert np.all(u == 0)\n    if ic_amplitude_random:\n        assert np.max(np.abs(v)) &lt;= ic_max_amplitude\n        assert np.max(np.abs(v)) &gt;= ic_min_amplitude\n    else:\n        assert np.max(np.abs(v)) == ic_max_amplitude\n\n# Plot the initial conditions\nfig, ax = plt.subplots()\nax.plot(u)\nax.plot(v)\n\n\n\n\n\n\n\n\n\n# Test the 2d functions\n\nrng = np.random.default_rng()\nic_type = \"pluck\"\nic_max_amplitude = 0.7\nic_min_amplitude = 0.1\nic_amplitude_random = False\nnum_points = 500\nu, v = generate_initial_condition(\n    rng,\n    Noise2d(num_points_x=num_points, aspect_ratio=0.7),\n    ic_type=ic_type,\n    ic_max_amplitude=ic_max_amplitude,\n    ic_min_amplitude=ic_min_amplitude,\n    ic_amplitude_random=ic_amplitude_random,\n)\nif ic_type == \"pluck\":\n    assert np.all(v == 0)\n    if ic_amplitude_random:\n        assert np.max(np.abs(u)) &lt;= ic_max_amplitude\n        assert np.max(np.abs(u)) &gt;= ic_min_amplitude\n    else:\n        assert np.allclose(np.max(np.abs(u)), ic_max_amplitude)\nelif ic_type == \"hammer\":\n    assert np.all(u == 0)\n    if ic_amplitude_random:\n        assert np.max(np.abs(v)) &lt;= ic_max_amplitude\n        assert np.max(np.abs(v)) &gt;= ic_min_amplitude\n    else:\n        assert np.allclose(np.max(np.abs(v)), ic_max_amplitude)\n\n# Plot the initial conditions\nfig, ax = plt.subplots(1,2)\nax[0].imshow(u)\nax[1].imshow(v)\n\n\n\n\n\n\n\n\n\nprint(np.max(np.abs(u)))\n\n0.7\n\n\n\nsource\n\n\nraised_cosine_2d\n\n raised_cosine_2d (grid_x, grid_y, c0:float=0.5, x_0:float=0.1,\n                   y_0:float=0.1, width:float=0.1,\n                   excitation_type:str='pluck')\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ngrid_x\n\n\nnumber of points along the x direction\n\n\ngrid_y\n\n\nnumber of points along the y direction\n\n\nc0\nfloat\n0.5\npeak amplitude in newtons\n\n\nx_0\nfloat\n0.1\ncenter of the excitation in x direction\n\n\ny_0\nfloat\n0.1\ncenter of the excitation in y direction\n\n\nwidth\nfloat\n0.1\nwidth of the excitation in meters\n\n\nexcitation_type\nstr\npluck\n\n\n\n\n\nsource\n\n\nraised_cosine_string\n\n raised_cosine_string (excitation_type:str='pluck', c0:float=0.5,\n                       x_0:float=0.1, width:float=0.1, length:float=1.0,\n                       grid_points:int=101)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nexcitation_type\nstr\npluck\n\n\n\nc0\nfloat\n0.5\npeak amplitude in newtons\n\n\nx_0\nfloat\n0.1\ncenter of the excitation in meters\n\n\nwidth\nfloat\n0.1\nwidth of the excitation in meters\n\n\nlength\nfloat\n1.0\ntotal length of the string in meters\n\n\ngrid_points\nint\n101\nnumber of points along the string\n\n\n\n\nexc = raised_cosine_string(\n    excitation_type=\"pluck\",\n    c0=0.7,\n    x_0=0,\n    width=0.1,\n    length=1.0,\n    grid_points=101,\n)\n\nplt.plot(exc)\n\n\n\n\n\n\n\n\n\ndef ricker(dt, pt):\n    nt = int(2 * pt / dt)\n    c = np.zeros(nt)\n    t0 = pt / dt\n    a_ricker = 4 / pt\n\n    for it in range(0, nt):\n        t = ((it + 1) - t0) * dt\n        c[it] = -2 * a_ricker * t * np.exp(-(a_ricker * t) ** 2)\n\n    return c\n\n\ndt = 1/44100\nT0 = 1/200\ntmp = ricker(dt, T0)\ntmp = np.diff(tmp)\n\nplt.plot(tmp)\n\n\n\n\n\n\n\n\n\ndef gaus2d(\n    x: np.ndarray,\n    y: np.ndarray,\n    A: float = 1, # amplitude\n    mx: float = 0, # center x\n    my: float = 0, # center y\n    sx: float = 1, # sigma x (width in x direction)\n    sy: float = 1, # sigma y (width in y direction)\n):\n\n    # norm = 1.0 / (2.0 * np.pi * sx * sy)\n    gaussian = np.exp(\n        -((x - mx) ** 2.0 / (2.0 * sx**2.0) + (y - my) ** 2.0 / (2.0 * sy**2.0))\n    )\n    return A * gaussian\n\ny = np.linspace(0, 50)\nx = np.linspace(0, 50)\nx, y = np.meshgrid(x, y) # get 2D variables instead of 1D\nz = gaus2d(x, y, 2, 5, 5)\n\nprint(z.max())\n\n1.9792833848731148\n\n\n\nsource\n\n\ncreate_pluck_modal\n\n create_pluck_modal (wavenumbers:numpy.ndarray, xe:float=0.28,\n                     hi:float=0.03, length:float=1.0)\n\nCreate a pluck excitation for a string with a given length and pluck position. The pluck is modeled in the modal domain. This function is based on the function https://github.com/julian-parker/DAFX22_FNO.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nwavenumbers\nndarray\n\nThe wavenumbers of the modes.\n\n\nxe\nfloat\n0.28\npluck position in m\n\n\nhi\nfloat\n0.03\ninitial deflection in m\n\n\nlength\nfloat\n1.0\nlength of the string in m\n\n\nReturns\nndarray\n\nThe pluck excitation in the modal domain.",
    "crumbs": [
      "Solver",
      "Impulse generator"
    ]
  },
  {
    "objectID": "solver/wave1d_solver_tensionmodulated.html",
    "href": "solver/wave1d_solver_tensionmodulated.html",
    "title": "Tension modulated string",
    "section": "",
    "text": "Step 1:\nStart with the non-linear tension modulated string model. The model is defined by the following equations:\n\\[\n\\begin{align}\n\\rho A \\frac{\\partial^2 y}{\\partial t^2} + EI \\frac{\\partial^4 y}{\\partial x^4} - T_{NL}(y) \\frac{\\partial^2 y}{\\partial x^2} + d_{1} \\frac{\\partial y}{\\partial t} + d_{3} \\frac{\\partial^3 y}{\\partial t^3} = f(x,t)\n\\end{align}\n\\]\nwhere \\(T_{NL}\\) is the non-linear tension function truncated at the third order:\n\\[\n\\begin{aligned}\nT_{N L}(y) & =T_0+T_1(y(x, t)) \\\\\n& =T_0+\\frac{E A}{2 l_0} \\int_0^{l_0} y^2(x, t) d x .\n\\end{aligned}\n\\]\n\n\nStep 2:\nPerform a transformation of the PDE with respect to the spatial variable \\(x\\). We can do this using the transformation kernel \\(K(x, \\beta_{\\mu})\\).\n\\[\n\\begin{aligned}\nK\\left(x, \\beta_\\mu\\right) & =\\sin \\left(\\frac{\\mu \\pi}{l_0} x\\right) \\\\\n\\beta_\\mu^4 & =E I\\left(\\frac{\\mu \\pi}{l_0}\\right)^4+T_0\\left(\\frac{\\mu \\pi}{l_0}\\right)^2\n\\end{aligned}\n\\]\nwhere \\(\\beta_\\mu\\) is the frequency variable. We see that the \\(K(x, \\beta_{\\mu})\\) is a function that generates the fourier sine series of the spatial variable \\(x\\).\nThe spatial tranformation of the non-linear term \\(T_{1}\\) is given as:\n\\[\n\\mathcal{T}\\left\\{T_1\\right\\} = \\bar{b}(\\mu,y,\\bar{y})\n\\]\nWe now can write the transformed PDE as:\n\\[\n\\boxed{\n\\begin{aligned}\n\\rho A \\ddot{\\bar{y}}(\\mu, t) + \\left(d_3 \\eta_\\mu^2+d_1\\right) \\dot{\\bar{y}}(\\mu, t) + \\beta_\\mu^4 \\bar{y}(\\mu, t)-\\bar{b}(\\mu, y, \\bar{y}) = 0\n\\end{aligned}\n}\n\\]\nWhere \\(\\eta_\\mu=-\\left(\\mu \\pi / l_0\\right)^2\\). The initial conditions are given as:\n\\[\n\\begin{aligned}\n\\bar{y}_0(\\mu) &= \\mathcal{T}{\\left\\{y_0(x)\\right\\}} \\\\\n\\dot{\\bar{y}}_0(\\mu) &= \\mathcal{T}{\\left\\{\\dot{y}_0(x)\\right\\}} = 0\n\\end{aligned}\n\\]\n\n\nStep 3:\nDiscretize the non-linear term \\(\\bar{b}(\\mu, y, \\bar{y})\\)\n\\[\n\\begin{aligned}\n\\bar{b}^d(\\mu) & =\\eta_\\mu^2 \\frac{E A \\bar{y}(\\mu)}{2 l_0} \\int_0^{l_0}\\left[\\sum_{\\nu=1}^M \\frac{1}{N_\\nu} \\bar{y}^d(\\nu) K(\\xi, \\nu)\\right]^{\\prime 2} d x \\\\\n& =\\eta_\\mu^2 \\frac{E A \\pi^2 \\bar{y}(\\mu)}{l_0^4} \\sum_{\\nu=1}^M \\nu^2\\left(\\bar{y}^d(\\nu)\\right)^2\n\\end{aligned}\n\\]\n\n\nStep 4\nWrite as a system of first order ODEs:\n\\[\n\\begin{aligned}\n\\dot{\\bar{y}}(\\mu, t) &= \\bar{v}(\\mu, t) \\\\\n\\dot{\\bar{v}}(\\mu, t) &= \\frac{-\\left(d_3 \\eta_\\mu^2+d_1\\right)}{\\rho A} \\bar{v}(\\mu, t) - \\frac{\\beta_\\mu^4}{\\rho A} \\bar{y}(\\mu, t) + \\frac{\\bar{b}(\\mu, y, \\bar{y})}{\\rho A}\n\\end{aligned}\n\\]\nThis is a system of first-order ODEs. In matrix form, we can write this as:\n\\[\n\\boxed{\n\\begin{aligned}\n\\mathbf{\\dot{\\bar{y}}} &= \\mathbf{\\bar{v}} \\\\\n\\mathbf{\\dot{\\bar{v}}} &= -\\mathbf{M_v} \\mathbf{\\bar{v}} - \\mathbf{M_y} \\mathbf{\\bar{y}} + \\mathbf{\\bar{b}}\n\\end{aligned}\n}\n\\]\nThe Matrices \\(\\mathbf{M_v}\\), \\(\\mathbf{M_y}\\) are diagonal matrices whose order is equal to the number of modes \\(M\\).\n\\[\n\\begin{aligned}\n\\mathbf{M_v} &= \\text{diag}\\left(\\frac{d_3 \\eta_\\mu^2+d_1}{\\rho A}\\right) \\\\\n\\mathbf{M_y} &= \\text{diag}\\left(\\frac{\\beta_\\mu^4}{\\rho A}\\right)\n\\end{aligned}\n\\]\nThe vector \\(\\mathbf{b}\\) contains the non-linear terms and is given as:\n\\[\n\\mathbf{\\Eta} = \\text{diag}\\left(\\eta_\\mu^2\\right) \\\\\nT_{1} = \\frac{E A \\pi^2}{l_0^4} \\mathbf{\\bar{y}}(\\mu)^T \\cdot \\Eta \\cdot \\mathbf{\\bar{y}} \\\\\n\\mathbf{\\bar{b}} = T_{1} \\text{diag}(\\frac{\\eta_\\mu^2}{\\rho A}) \\mathbf{\\bar{y}}\n\\]\n\nfrom matplotlib import pyplot as plt\n\nThe parameters of the model are:\n\n\\(N\\): number of points in the string\n\\(T\\): total time of simulation\n\\(f_s\\): sampling rate\n\\(l\\): length of string\n\\(A\\): string cross-sectional area\n\\(E\\): Young’s modulus\n\\(I\\): string moment of inertia\n\\(\\rho\\): density\n\\(Ts_0\\): initial tension\n\\(d_{1}\\): string frequency independent damping\n\\(d_{3}\\): string frequency dependent damping\n\\(M\\): number of modes to include in the modal expansion\n\n\nsource\n\n\nWave1dSolverTensionModulated\n\n Wave1dSolverTensionModulated (sampling_rate:int=48000,\n                               final_time:float=0.5, n_gridpoints:int=101,\n                               length:float=1.0, A:float=1.9634e-07,\n                               I:float=2.454e-14, rho:float=7800,\n                               E:int=190000000000.0, d1:float=0.004,\n                               d3:float=6e-05, Ts0:float=150,\n                               n_max_modes:int=50,\n                               use_nonlinear:bool=True,\n                               method:str='DOP853', rtol:float=1e-12,\n                               atol:float=1e-14)\n\n*Tension modulated wave equation solver.\nThis solver is based on the paper “Sound Synthesis With Tension Modulated Nonlinearities” and the accompanying code to the paper “Physical Modeling using Recurrent Neural Networks with Fast Convolutional Layers”.*\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsampling_rate\nint\n48000\n1/s Temporal sampling frequency\n\n\nfinal_time\nfloat\n0.5\ns Duration of the simulation\n\n\nn_gridpoints\nint\n101\npts/m Spatial sampling grid\n\n\nlength\nfloat\n1.0\nm Length at rest\n\n\nA\nfloat\n1.9634e-07\nm**2 Cross section area\n\n\nI\nfloat\n2.454e-14\nm**4 Moment of intertia\n\n\nrho\nfloat\n7800\nkg/m**3 Density\n\n\nE\nint\n190000000000.0\nPa Young’s modulus\n\n\nd1\nfloat\n0.004\nkg/(ms) Frequency independent loss\n\n\nd3\nfloat\n6e-05\nkg m/s Frequency dependent loss\n\n\nTs0\nfloat\n150\nN Tension\n\n\nn_max_modes\nint\n50\nNumber of modal expansion terms\n\n\nuse_nonlinear\nbool\nTrue\nUse nonlinear wave equation\n\n\nmethod\nstr\nDOP853\nIntegration method\n\n\nrtol\nfloat\n1e-12\nRelative tolerance\n\n\natol\nfloat\n1e-14\nAbsolute tolerance\n\n\n\n\nsource\n\n\nnonlinear_string_func\n\n nonlinear_string_func (t, state, n_max_modes, use_nonlinear, pre, H, H_1,\n                        M_v, M_y)\n\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nt\n\ntime\n\n\nstate\n\nstate vector\n\n\nn_max_modes\n\nnumber of modes\n\n\nuse_nonlinear\n\nuse nonlinear wave equation\n\n\npre\n\nprecalculated constant\n\n\nH\n\nH matrix\n\n\nH_1\n\nH_1 matrix\n\n\nM_v\n\nM_v matrix\n\n\nM_y\n\nM_y matrix\n\n\nReturns\nndarray\nstate at timestep t and position x (u(x, t))\n\n\n\nTest the solver\n\nfrom physmodjax.solver.generator import (\n    Gaussian,\n    generate_initial_condition,\n)\n\n\nlength = 0.65\nA = 0.5188e-6\nI = 0.141e-12\nrho = 1140\nE = 5.4e9 \nd1 = 8e-5\nd3 = 1.4e-5\nTs0 = 60.97\nn_gridpoints = 101\nn_max_modes = 99\nsr = 96000\n\n\nsolver = Wave1dSolverTensionModulated(\n    sampling_rate=sr,\n    final_time=0.1,\n    A=A,\n    I=I,\n    rho=rho,\n    E=E,\n    d1=d1,\n    d3=d3,\n    Ts0=Ts0,\n    length=length,\n    n_gridpoints=n_gridpoints,\n    n_max_modes=n_max_modes,\n    use_nonlinear=True,\n    # d3=1e-7,\n)\n\n# initial conditions\nic_max_amplitude = 0.02\nu0, v0 = generate_initial_condition(\n    rng=np.random.default_rng(354),\n    generator=Gaussian(num_points=n_gridpoints),\n    ic_max_amplitude=ic_max_amplitude,\n    ic_amplitude_random=False,\n)\n\nt, u, v = solver.solve(u0, v0)\nprint(f\"u shape: {u.shape}\")\n\ndx: 0.006500000000000001 in meters\ndt: 1.0416666666666666e-05 in seconds\nnumber of points (n_gridpoints): (101,)\ntime in samples (nt): (9600,)\n\n\n\nn_samples_plot = 7000\nfig, ax = plt.subplots(1, 2, figsize=(5, 6))\nax[0].pcolormesh(solver.grid, t[-n_samples_plot:], u[-n_samples_plot:, :])\nax[0].set_title(\"u\")\nax[0].set_xlabel(\"x\")\nax[0].set_ylabel(\"t\")\nax[1].pcolormesh(solver.grid, t[-n_samples_plot:], v[-n_samples_plot:, :])\nax[1].set_title(\"v\")\nax[1].set_xlabel(\"x\")\nax[1].set_ylabel(\"t\")\nfig.tight_layout()\nplt.show()\n# plot the solution at the endpoints\nplt.figure(figsize=(10, 5))\nplt.plot(t, u[:, 0], label=\"left\")\nplt.plot(t, u[:, -1], label=\"right\", alpha=0.5)\nplt.legend()\nplt.show()\n\n# Plot FFT of the solution for a point on the string, in db scale\nplt.figure(figsize=(10, 5))\nfreq = np.fft.rfftfreq(u.shape[-1], d=solver.dt)\nplt.plot(freq, 20 * np.log10(np.abs(np.fft.rfft(u[17, :]))), label=\"fft\")\n# plt.figure(figsize=(10, 5))\n# freq = np.fft.rfftfreq(u.shape[0], d=solver.dt)\n# plt.plot(freq, np.abs(np.fft.rfft(u[:, 17])), label=\"fft\")\n# plt.xlim(3000, 8000)\nplt.xlim(100, 5000)\nplt.legend()\nplt.show()\n\n# Plot spectrogram of the solution for a point on the string\nplt.figure(figsize=(10, 5))\nplt.specgram(u[:, 17], Fs=solver.sampling_rate, NFFT=2048, noverlap=1024)\nplt.ylim(0, 20000)\nplt.show()\n\n# Plot FFT of the initial condition\nplt.figure(figsize=(10, 5))\nfreq = np.fft.rfftfreq(u.shape[-1], d=solver.dx)\n# plt.plot(freq, np.abs(np.fft.rfft(u0)), label=\"fft\")\nplt.plot(np.abs(np.fft.rfft(u0)), label=\"fft\")\n# plt.xlim(0, 1)\nplt.legend()\n\n# plot the initial conditions\nplt.figure(figsize=(10, 5))\nplt.plot(solver.grid, u0, label=\"u0\")\nplt.plot(solver.grid, u[0, :], label=\"u0_sol\", alpha=0.5)\nplt.legend()\nplt.show()\n\n# Plot the difference between the initial condition given and the one obtained from the solution\nplt.figure(figsize=(10, 5))\nplt.plot(solver.grid, u0 - u[0], label=\"u0 - u0_sol\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom IPython import display as ipd\n\n\n# Play the solution as audio\nipd.Audio(u[:, 27], rate=solver.sampling_rate)\n\n\n                \n                    \n                    Your browser does not support the audio element.",
    "crumbs": [
      "Solver",
      "Tension modulated string"
    ]
  },
  {
    "objectID": "scripts/train_rnn.html",
    "href": "scripts/train_rnn.html",
    "title": "Training an RNN",
    "section": "",
    "text": "source\n\ncreate_train_state\n\n create_train_state (model:flax.linen.module.Module, rng:jax.Array,\n                     x_shape:Tuple[int,int,int,int], num_steps:int,\n                     norm:str='layer', learning_rate:float=0.001, grad_cli\n                     p:optax._src.base.GradientTransformation=GradientTran\n                     sformation(init=&lt;function\n                     clip_by_global_norm.&lt;locals&gt;.init_fn at 0x15ec58c10&gt;,\n                     update=&lt;function\n                     clip_by_global_norm.&lt;locals&gt;.update_fn at\n                     0x15ec58ca0&gt;), components_to_freeze:List[str]=[],\n                     schedule_type:str='constant', debug:bool=False)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmodel\nModule\n\n\n\n\nrng\nArray\n\n\n\n\nx_shape\nTuple\n\n\n\n\nnum_steps\nint\n\nnumber of training steps\n\n\nnorm\nstr\nlayer\n“layer” or “batch”\n\n\nlearning_rate\nfloat\n0.001\n\n\n\ngrad_clip\nGradientTransformation\nGradientTransformation(init=&lt;function clip_by_global_norm..init_fn at 0x15ec58c10&gt;, update=&lt;function clip_by_global_norm..update_fn at 0x15ec58ca0&gt;)\n\n\n\ncomponents_to_freeze\nList\n[]\n\n\n\nschedule_type\nstr\nconstant\n“cosine” or “constant”\n\n\ndebug\nbool\nFalse\nprint debug information\n\n\nReturns\nTrainState\n\n\n\n\n\n\nsource\n\n\ntrain\n\n train (model_cls, datamodule, cfg:omegaconf.dictconfig.DictConfig,\n        checkpoint_manager:orbax.checkpoint.checkpoint_manager.CheckpointM\n        anager)\n\n\nsource\n\n\ntrain_rnn\n\n train_rnn (cfg:omegaconf.dictconfig.DictConfig)\n\nTrain RNN model\n\n# TODO: Make a ROOT_DIR global variable that can be used anywhere to run commands reproducibly. Maybe force hydra to always run there?\n!cd ../.. ; env HYDRA_FULL_ERROR=1 WANDB_MODE=disabled train_rnn +experiment=test\n\nmodel:\n  _target_: physmodjax.fno.rnn.BatchFNORNN\n  hidden_channels: 4\n  grid_size: 101\n  n_spectral_layers: 2\n  out_channels: 2\ndatamodule:\n  _target_: physmodjax.scripts.dataset_generation.DirectoryDataModule\n  batch_size: 1\n  data_directory: data/test\njax:\n  platform_name: cpu\n  preallocate_gpu_memory: false\noptimiser:\n  _target_: optax.adam\n  learning_rate: 0.001\ngradient_clip:\n  _target_: optax.clip_by_global_norm\n  max_norm: 1.0\nseed: 3407\nepochs: 1\nwandb:\n  project: physmodjax\n  entity: iir-modal\n  group: rnn-test\n  job_type: train\n  name: null\nproject: physmodjax\n\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1702859671.726977   71570 tfrt_cpu_pjrt_client.cc:349] TfrtCpuClient created.\n[2023-12-18 00:34:31,800][jax._src.xla_bridge][INFO] - Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: \"rocm\". Available platform names are: CUDA\n[2023-12-18 00:34:31,801][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\njax devices:  [CpuDevice(id=0)]\n100%|█████████████████████████████████████████████| 1/1 [00:33&lt;00:00, 33.96s/it]\n[2023-12-18 00:35:08,662][absl][INFO] - OCDBT is initialized successfully.\n[2023-12-18 00:35:08,662][absl][INFO] - Saving item to /home/carlos/projects/physmodjax/outputs/2023-12-18/00-34-31/checkpoints.\n[2023-12-18 00:35:08,687][absl][INFO] - Renaming /home/carlos/projects/physmodjax/outputs/2023-12-18/00-34-31/checkpoints.orbax-checkpoint-tmp-1702859708663140 to /home/carlos/projects/physmodjax/outputs/2023-12-18/00-34-31/checkpoints\n[2023-12-18 00:35:08,687][absl][INFO] - Finished saving checkpoint to `/home/carlos/projects/physmodjax/outputs/2023-12-18/00-34-31/checkpoints`.",
    "crumbs": [
      "Scripts",
      "Training an RNN"
    ]
  }
]